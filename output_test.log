nohup: les entrées sont ignorées
/home/alexandre-tonon/deep-learning/ClimSim_dataset/trainin_ssh.py:330: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.
  return self.ds.dims['sample']
Nouvelle forme pour le modèle : torch.Size([76800, 124])
Nouvelle forme inputs : torch.Size([76800, 124])
Test sur un batch de taille : 76800
Epoch [10/100], Loss: 226.05868530
Epoch [20/100], Loss: 122.54047394
Epoch [30/100], Loss: 20630.03320312
Epoch [40/100], Loss: 235667.06250000
Epoch [50/100], Loss: 704493.62500000
Epoch [60/100], Loss: 390730.53125000
Epoch [70/100], Loss: 22715.82617188
Epoch [80/100], Loss: 14836.76757812
Epoch [90/100], Loss: 1869.71179199
Epoch [100/100], Loss: 950.75634766
fin du test sur un batch unique.
Variable Index  | Mean       | Std       
----------------------------------------
Input Feature 0   |    -0.0891 |     1.0166
Input Feature 1   |    -0.0888 |     1.0193
Input Feature 2   |    -0.0682 |     1.0169
Input Feature 3   |    -0.0662 |     1.0319
Input Feature 4   |    -0.0820 |     0.9832
Input Feature 119 |    -0.0703 |     1.0075
Input Feature 120 |    -0.0891 |     0.9795
Input Feature 121 |    -0.0959 |     0.9897
Input Feature 122 |    -0.0607 |     1.0074
Input Feature 123 |    -0.0680 |     1.0070
Training:   0%|          | 0/211 [00:00<?, ?batch/s]Training:   0%|          | 0/211 [02:45<?, ?batch/s, loss=917.327759]Training:   0%|          | 1/211 [02:45<9:39:58, 165.71s/batch, loss=917.327759]Training:   0%|          | 1/211 [02:48<9:39:58, 165.71s/batch, loss=781.435181]Training:   1%|          | 2/211 [02:48<4:04:08, 70.09s/batch, loss=781.435181] Training:   1%|          | 2/211 [02:57<4:04:08, 70.09s/batch, loss=719.105286]Training:   1%|▏         | 3/211 [02:57<2:25:39, 42.02s/batch, loss=719.105286]Training:   1%|▏         | 3/211 [03:00<2:25:39, 42.02s/batch, loss=613.325012]Training:   2%|▏         | 4/211 [03:00<1:31:57, 26.65s/batch, loss=613.325012]Training:   2%|▏         | 4/211 [05:30<1:31:57, 26.65s/batch, loss=597.908203]Training:   2%|▏         | 5/211 [05:30<4:04:00, 71.07s/batch, loss=597.908203]Training:   2%|▏         | 5/211 [05:33<4:04:00, 71.07s/batch, loss=576.016113]Training:   3%|▎         | 6/211 [05:33<2:43:53, 47.97s/batch, loss=576.016113]Training:   3%|▎         | 6/211 [05:52<2:43:53, 47.97s/batch, loss=551.572083]Training:   3%|▎         | 7/211 [05:52<2:10:32, 38.40s/batch, loss=551.572083]Training:   3%|▎         | 7/211 [06:15<2:10:32, 38.40s/batch, loss=510.587952]Training:   4%|▍         | 8/211 [06:15<1:54:10, 33.74s/batch, loss=510.587952]Training:   4%|▍         | 8/211 [08:18<1:54:10, 33.74s/batch, loss=532.079041]Training:   4%|▍         | 9/211 [08:18<3:27:10, 61.54s/batch, loss=532.079041]Training:   4%|▍         | 9/211 [08:21<3:27:10, 61.54s/batch, loss=523.231140]Training:   5%|▍         | 10/211 [08:21<2:25:44, 43.51s/batch, loss=523.231140]Training:   5%|▍         | 10/211 [08:37<2:25:44, 43.51s/batch, loss=490.384216]Training:   5%|▌         | 11/211 [08:37<1:56:57, 35.09s/batch, loss=490.384216]Training:   5%|▌         | 11/211 [09:07<1:56:57, 35.09s/batch, loss=470.710999]Training:   6%|▌         | 12/211 [09:07<1:50:48, 33.41s/batch, loss=470.710999]Training:   6%|▌         | 12/211 [11:10<1:50:48, 33.41s/batch, loss=441.855713]Training:   6%|▌         | 13/211 [11:11<3:20:42, 60.82s/batch, loss=441.855713]Training:   6%|▌         | 13/211 [11:14<3:20:42, 60.82s/batch, loss=415.737549]Training:   7%|▋         | 14/211 [11:14<2:22:30, 43.40s/batch, loss=415.737549]Training:   7%|▋         | 14/211 [11:35<2:22:30, 43.40s/batch, loss=418.396210]Training:   7%|▋         | 15/211 [11:35<1:59:42, 36.64s/batch, loss=418.396210]Training:   7%|▋         | 15/211 [11:56<1:59:42, 36.64s/batch, loss=378.177948]Training:   8%|▊         | 16/211 [11:56<1:43:29, 31.84s/batch, loss=378.177948]Training:   8%|▊         | 16/211 [14:00<1:43:29, 31.84s/batch, loss=360.187683]Training:   8%|▊         | 17/211 [14:00<3:13:08, 59.73s/batch, loss=360.187683]Training:   8%|▊         | 17/211 [14:03<3:13:08, 59.73s/batch, loss=344.947510]Training:   9%|▊         | 18/211 [14:03<2:17:25, 42.72s/batch, loss=344.947510]Training:   9%|▊         | 18/211 [14:28<2:17:25, 42.72s/batch, loss=363.705261]Training:   9%|▉         | 19/211 [14:28<1:59:21, 37.30s/batch, loss=363.705261]Training:   9%|▉         | 19/211 [14:37<1:59:21, 37.30s/batch, loss=321.152771]Training:   9%|▉         | 20/211 [14:37<1:31:44, 28.82s/batch, loss=321.152771]Training:   9%|▉         | 20/211 [16:38<1:31:44, 28.82s/batch, loss=311.780182]Training:  10%|▉         | 21/211 [16:38<2:59:01, 56.53s/batch, loss=311.780182]Training:  10%|▉         | 21/211 [17:03<2:59:01, 56.53s/batch, loss=302.283997]Training:  10%|█         | 22/211 [17:03<2:27:48, 46.92s/batch, loss=302.283997]Training:  10%|█         | 22/211 [17:32<2:27:48, 46.92s/batch, loss=286.297516]Training:  11%|█         | 23/211 [17:32<2:10:33, 41.67s/batch, loss=286.297516]Training:  11%|█         | 23/211 [17:45<2:10:33, 41.67s/batch, loss=286.395844]Training:  11%|█▏        | 24/211 [17:45<1:43:12, 33.11s/batch, loss=286.395844]Training:  11%|█▏        | 24/211 [19:38<1:43:12, 33.11s/batch, loss=288.192291]Training:  12%|█▏        | 25/211 [19:38<2:56:43, 57.01s/batch, loss=288.192291]Training:  12%|█▏        | 25/211 [20:00<2:56:43, 57.01s/batch, loss=275.877106]Training:  12%|█▏        | 26/211 [20:00<2:23:41, 46.60s/batch, loss=275.877106]Training:  12%|█▏        | 26/211 [20:28<2:23:41, 46.60s/batch, loss=271.092926]Training:  13%|█▎        | 27/211 [20:28<2:05:56, 41.07s/batch, loss=271.092926]Training:  13%|█▎        | 27/211 [20:42<2:05:56, 41.07s/batch, loss=248.187943]Training:  13%|█▎        | 28/211 [20:42<1:40:25, 32.93s/batch, loss=248.187943]Training:  13%|█▎        | 28/211 [22:45<1:40:25, 32.93s/batch, loss=266.011017]Training:  14%|█▎        | 29/211 [22:46<3:02:09, 60.05s/batch, loss=266.011017]Training:  14%|█▎        | 29/211 [22:59<3:02:09, 60.05s/batch, loss=244.100922]Training:  14%|█▍        | 30/211 [22:59<2:18:35, 45.94s/batch, loss=244.100922]Training:  14%|█▍        | 30/211 [23:42<2:18:35, 45.94s/batch, loss=236.901031]Training:  15%|█▍        | 31/211 [23:42<2:15:14, 45.08s/batch, loss=236.901031]Training:  15%|█▍        | 31/211 [23:52<2:15:14, 45.08s/batch, loss=223.972046]Training:  15%|█▌        | 32/211 [23:52<1:42:51, 34.48s/batch, loss=223.972046]Training:  15%|█▌        | 32/211 [25:34<1:42:51, 34.48s/batch, loss=225.200912]Training:  16%|█▌        | 33/211 [25:35<2:43:16, 55.04s/batch, loss=225.200912]Training:  16%|█▌        | 33/211 [25:58<2:43:16, 55.04s/batch, loss=198.565109]Training:  16%|█▌        | 34/211 [25:58<2:14:18, 45.53s/batch, loss=198.565109]Training:  16%|█▌        | 34/211 [26:33<2:14:18, 45.53s/batch, loss=218.062271]Training:  17%|█▋        | 35/211 [26:33<2:03:56, 42.25s/batch, loss=218.062271]Training:  17%|█▋        | 35/211 [27:04<2:03:56, 42.25s/batch, loss=207.230347]Training:  17%|█▋        | 36/211 [27:04<1:53:41, 38.98s/batch, loss=207.230347]Training:  17%|█▋        | 36/211 [28:23<1:53:41, 38.98s/batch, loss=211.636581]Training:  18%|█▊        | 37/211 [28:23<2:27:57, 51.02s/batch, loss=211.636581]Training:  18%|█▊        | 37/211 [28:50<2:27:57, 51.02s/batch, loss=214.504333]Training:  18%|█▊        | 38/211 [28:50<2:06:20, 43.82s/batch, loss=214.504333]Training:  18%|█▊        | 38/211 [29:37<2:06:20, 43.82s/batch, loss=192.020889]Training:  18%|█▊        | 39/211 [29:37<2:08:13, 44.73s/batch, loss=192.020889]Training:  18%|█▊        | 39/211 [29:49<2:08:13, 44.73s/batch, loss=189.653381]Training:  19%|█▉        | 40/211 [29:49<1:39:29, 34.91s/batch, loss=189.653381]Training:  19%|█▉        | 40/211 [31:11<1:39:29, 34.91s/batch, loss=203.479004]Training:  19%|█▉        | 41/211 [31:11<2:19:10, 49.12s/batch, loss=203.479004]Training:  19%|█▉        | 41/211 [31:48<2:19:10, 49.12s/batch, loss=169.889786]Training:  20%|█▉        | 42/211 [31:48<2:07:55, 45.42s/batch, loss=169.889786]Training:  20%|█▉        | 42/211 [32:41<2:07:55, 45.42s/batch, loss=172.561798]Training:  20%|██        | 43/211 [32:41<2:13:26, 47.66s/batch, loss=172.561798]Training:  20%|██        | 43/211 [32:44<2:13:26, 47.66s/batch, loss=172.205887]Training:  21%|██        | 44/211 [32:44<1:35:38, 34.36s/batch, loss=172.205887]Training:  21%|██        | 44/211 [33:59<1:35:38, 34.36s/batch, loss=166.816620]Training:  21%|██▏       | 45/211 [33:59<2:09:01, 46.64s/batch, loss=166.816620]Training:  21%|██▏       | 45/211 [34:47<2:09:01, 46.64s/batch, loss=185.972687]Training:  22%|██▏       | 46/211 [34:47<2:09:26, 47.07s/batch, loss=185.972687]Training:  22%|██▏       | 46/211 [35:28<2:09:26, 47.07s/batch, loss=179.797150]Training:  22%|██▏       | 47/211 [35:28<2:03:06, 45.04s/batch, loss=179.797150]Training:  22%|██▏       | 47/211 [35:42<2:03:06, 45.04s/batch, loss=169.437119]Training:  23%|██▎       | 48/211 [35:42<1:37:31, 35.90s/batch, loss=169.437119]Training:  23%|██▎       | 48/211 [36:47<1:37:31, 35.90s/batch, loss=171.289703]Training:  23%|██▎       | 49/211 [36:47<1:59:57, 44.43s/batch, loss=171.289703]Training:  23%|██▎       | 49/211 [37:59<1:59:57, 44.43s/batch, loss=156.084976]Training:  24%|██▎       | 50/211 [37:59<2:21:31, 52.74s/batch, loss=156.084976]Training:  24%|██▎       | 50/211 [38:31<2:21:31, 52.74s/batch, loss=146.698105]Training:  24%|██▍       | 51/211 [38:31<2:04:33, 46.71s/batch, loss=146.698105]Training:  24%|██▍       | 51/211 [38:44<2:04:33, 46.71s/batch, loss=165.449539]Training:  25%|██▍       | 52/211 [38:44<1:36:49, 36.54s/batch, loss=165.449539]Training:  25%|██▍       | 52/211 [40:03<1:36:49, 36.54s/batch, loss=155.975189]Training:  25%|██▌       | 53/211 [40:03<2:09:37, 49.23s/batch, loss=155.975189]Training:  25%|██▌       | 53/211 [40:52<2:09:37, 49.23s/batch, loss=148.346146]Training:  26%|██▌       | 54/211 [40:52<2:08:38, 49.16s/batch, loss=148.346146]Training:  26%|██▌       | 54/211 [42:11<2:08:38, 49.16s/batch, loss=147.329224]Training:  26%|██▌       | 55/211 [42:11<2:30:56, 58.06s/batch, loss=147.329224]Training:  26%|██▌       | 55/211 [42:14<2:30:56, 58.06s/batch, loss=141.363998]Training:  27%|██▋       | 56/211 [42:14<1:47:19, 41.55s/batch, loss=141.363998]Training:  27%|██▋       | 56/211 [43:14<1:47:19, 41.55s/batch, loss=139.633835]Training:  27%|██▋       | 57/211 [43:14<2:01:02, 47.16s/batch, loss=139.633835]Training:  27%|██▋       | 57/211 [44:19<2:01:02, 47.16s/batch, loss=140.182343]Training:  27%|██▋       | 58/211 [44:19<2:13:59, 52.54s/batch, loss=140.182343]Training:  27%|██▋       | 58/211 [45:30<2:13:59, 52.54s/batch, loss=143.606369]Training:  28%|██▊       | 59/211 [45:31<2:27:55, 58.39s/batch, loss=143.606369]Training:  28%|██▊       | 59/211 [45:35<2:27:55, 58.39s/batch, loss=134.354248]Training:  28%|██▊       | 60/211 [45:35<1:45:14, 41.82s/batch, loss=134.354248]Training:  28%|██▊       | 60/211 [46:23<1:45:14, 41.82s/batch, loss=144.384109]Training:  29%|██▉       | 61/211 [46:23<1:49:51, 43.94s/batch, loss=144.384109]Training:  29%|██▉       | 61/211 [46:57<1:49:51, 43.94s/batch, loss=140.358200]Training:  29%|██▉       | 62/211 [46:57<1:41:47, 40.99s/batch, loss=140.358200]Training:  29%|██▉       | 62/211 [48:35<1:41:47, 40.99s/batch, loss=139.945267]Training:  30%|██▉       | 63/211 [48:35<2:22:59, 57.97s/batch, loss=139.945267]Training:  30%|██▉       | 63/211 [48:38<2:22:59, 57.97s/batch, loss=136.810883]Training:  30%|███       | 64/211 [48:38<1:41:41, 41.50s/batch, loss=136.810883]Training:  30%|███       | 64/211 [49:14<1:41:41, 41.50s/batch, loss=134.017303]Training:  31%|███       | 65/211 [49:14<1:37:09, 39.93s/batch, loss=134.017303]Training:  31%|███       | 65/211 [50:03<1:37:09, 39.93s/batch, loss=133.931000]Training:  31%|███▏      | 66/211 [50:04<1:43:14, 42.72s/batch, loss=133.931000]Training:  31%|███▏      | 66/211 [51:39<1:43:14, 42.72s/batch, loss=130.649536]Training:  32%|███▏      | 67/211 [51:40<2:20:57, 58.74s/batch, loss=130.649536]Training:  32%|███▏      | 67/211 [51:43<2:20:57, 58.74s/batch, loss=115.911224]Training:  32%|███▏      | 68/211 [51:43<1:40:11, 42.04s/batch, loss=115.911224]Training:  32%|███▏      | 68/211 [52:15<1:40:11, 42.04s/batch, loss=119.740761]Training:  33%|███▎      | 69/211 [52:15<1:32:19, 39.01s/batch, loss=119.740761]Training:  33%|███▎      | 69/211 [52:53<1:32:19, 39.01s/batch, loss=127.558289]Training:  33%|███▎      | 70/211 [52:53<1:30:48, 38.64s/batch, loss=127.558289]Training:  33%|███▎      | 70/211 [54:41<1:30:48, 38.64s/batch, loss=120.303917]Training:  34%|███▎      | 71/211 [54:41<2:18:57, 59.55s/batch, loss=120.303917]Training:  34%|███▎      | 71/211 [54:44<2:18:57, 59.55s/batch, loss=113.038490]Training:  34%|███▍      | 72/211 [54:44<1:38:45, 42.63s/batch, loss=113.038490]Training:  34%|███▍      | 72/211 [55:09<1:38:45, 42.63s/batch, loss=117.565651]Training:  35%|███▍      | 73/211 [55:09<1:26:10, 37.46s/batch, loss=117.565651]Training:  35%|███▍      | 73/211 [55:51<1:26:10, 37.46s/batch, loss=108.309776]Training:  35%|███▌      | 74/211 [55:51<1:28:14, 38.64s/batch, loss=108.309776]Training:  35%|███▌      | 74/211 [57:37<1:28:14, 38.64s/batch, loss=106.332047]Training:  36%|███▌      | 75/211 [57:37<2:13:33, 58.92s/batch, loss=106.332047]Training:  36%|███▌      | 75/211 [57:40<2:13:33, 58.92s/batch, loss=106.281219]Training:  36%|███▌      | 76/211 [57:40<1:34:50, 42.15s/batch, loss=106.281219]Training:  36%|███▌      | 76/211 [57:57<1:34:50, 42.15s/batch, loss=126.075996]Training:  36%|███▋      | 77/211 [57:57<1:17:00, 34.48s/batch, loss=126.075996]Training:  36%|███▋      | 77/211 [58:45<1:17:00, 34.48s/batch, loss=111.530632]Training:  37%|███▋      | 78/211 [58:45<1:25:36, 38.62s/batch, loss=111.530632]Training:  37%|███▋      | 78/211 [1:00:54<1:25:36, 38.62s/batch, loss=119.110817]Training:  37%|███▋      | 79/211 [1:00:54<2:24:29, 65.68s/batch, loss=119.110817]Training:  37%|███▋      | 79/211 [1:00:57<2:24:29, 65.68s/batch, loss=111.316765]Training:  38%|███▊      | 80/211 [1:00:57<1:42:21, 46.88s/batch, loss=111.316765]Training:  38%|███▊      | 80/211 [1:01:11<1:42:21, 46.88s/batch, loss=107.427055]Training:  38%|███▊      | 81/211 [1:01:11<1:20:05, 36.96s/batch, loss=107.427055]Training:  38%|███▊      | 81/211 [1:01:36<1:20:05, 36.96s/batch, loss=109.721642]Training:  39%|███▉      | 82/211 [1:01:36<1:11:46, 33.39s/batch, loss=109.721642]Training:  39%|███▉      | 82/211 [1:03:47<1:11:46, 33.39s/batch, loss=110.384529]Training:  39%|███▉      | 83/211 [1:03:47<2:14:06, 62.87s/batch, loss=110.384529]Training:  39%|███▉      | 83/211 [1:03:50<2:14:06, 62.87s/batch, loss=107.146774]Training:  40%|███▉      | 84/211 [1:03:50<1:35:04, 44.91s/batch, loss=107.146774]Training:  40%|███▉      | 84/211 [1:04:00<1:35:04, 44.91s/batch, loss=104.499451]Training:  40%|████      | 85/211 [1:04:00<1:11:56, 34.25s/batch, loss=104.499451]Training:  40%|████      | 85/211 [1:04:21<1:11:56, 34.25s/batch, loss=104.609291]Training:  41%|████      | 86/211 [1:04:21<1:03:18, 30.39s/batch, loss=104.609291]Training:  41%|████      | 86/211 [1:07:04<1:03:18, 30.39s/batch, loss=115.811607]Training:  41%|████      | 87/211 [1:07:05<2:25:24, 70.36s/batch, loss=115.811607]Training:  41%|████      | 87/211 [1:07:08<2:25:24, 70.36s/batch, loss=101.672607]Training:  42%|████▏     | 88/211 [1:07:08<1:42:52, 50.18s/batch, loss=101.672607]Training:  42%|████▏     | 88/211 [1:07:11<1:42:52, 50.18s/batch, loss=104.955391]Training:  42%|████▏     | 89/211 [1:07:11<1:13:18, 36.06s/batch, loss=104.955391]Training:  42%|████▏     | 89/211 [1:07:14<1:13:18, 36.06s/batch, loss=99.098274] Training:  43%|████▎     | 90/211 [1:07:14<52:46, 26.17s/batch, loss=99.098274]  Training:  43%|████▎     | 90/211 [1:10:20<52:46, 26.17s/batch, loss=102.301041]Training:  43%|████▎     | 91/211 [1:10:21<2:28:33, 74.28s/batch, loss=102.301041]Training:  43%|████▎     | 91/211 [1:10:24<2:28:33, 74.28s/batch, loss=94.266563] Training:  44%|████▎     | 92/211 [1:10:24<1:44:58, 52.93s/batch, loss=94.266563]Training:  44%|████▎     | 92/211 [1:10:27<1:44:58, 52.93s/batch, loss=92.749886]Training:  44%|████▍     | 93/211 [1:10:27<1:14:39, 37.97s/batch, loss=92.749886]Training:  44%|████▍     | 93/211 [1:10:30<1:14:39, 37.97s/batch, loss=92.235901]Training:  45%|████▍     | 94/211 [1:10:30<53:36, 27.50s/batch, loss=92.235901]  Training:  45%|████▍     | 94/211 [1:13:20<53:36, 27.50s/batch, loss=97.004234]Training:  45%|████▌     | 95/211 [1:13:20<2:16:09, 70.43s/batch, loss=97.004234]Training:  45%|████▌     | 95/211 [1:13:23<2:16:09, 70.43s/batch, loss=99.140152]Training:  45%|████▌     | 96/211 [1:13:23<1:36:14, 50.21s/batch, loss=99.140152]Training:  45%|████▌     | 96/211 [1:13:26<1:36:14, 50.21s/batch, loss=95.033279]Training:  46%|████▌     | 97/211 [1:13:26<1:08:30, 36.06s/batch, loss=95.033279]Training:  46%|████▌     | 97/211 [1:13:30<1:08:30, 36.06s/batch, loss=98.026253]Training:  46%|████▋     | 98/211 [1:13:30<49:15, 26.15s/batch, loss=98.026253]  Training:  46%|████▋     | 98/211 [1:16:15<49:15, 26.15s/batch, loss=104.600998]Training:  47%|████▋     | 99/211 [1:16:16<2:07:17, 68.20s/batch, loss=104.600998]Training:  47%|████▋     | 99/211 [1:16:19<2:07:17, 68.20s/batch, loss=86.555069] Training:  47%|████▋     | 100/211 [1:16:19<1:30:01, 48.66s/batch, loss=86.555069]Training:  47%|████▋     | 100/211 [1:16:22<1:30:01, 48.66s/batch, loss=84.249001]Training:  48%|████▊     | 101/211 [1:16:22<1:04:08, 34.99s/batch, loss=84.249001]Training:  48%|████▊     | 101/211 [1:16:25<1:04:08, 34.99s/batch, loss=88.867226]Training:  48%|████▊     | 102/211 [1:16:25<46:09, 25.41s/batch, loss=88.867226]  Training:  48%|████▊     | 102/211 [1:19:12<46:09, 25.41s/batch, loss=90.207375]Training:  49%|████▉     | 103/211 [1:19:12<2:02:13, 67.90s/batch, loss=90.207375]Training:  49%|████▉     | 103/211 [1:19:15<2:02:13, 67.90s/batch, loss=93.098541]Training:  49%|████▉     | 104/211 [1:19:15<1:26:24, 48.46s/batch, loss=93.098541]Training:  49%|████▉     | 104/211 [1:19:18<1:26:24, 48.46s/batch, loss=94.524437]Training:  50%|████▉     | 105/211 [1:19:18<1:01:32, 34.83s/batch, loss=94.524437]Training:  50%|████▉     | 105/211 [1:19:21<1:01:32, 34.83s/batch, loss=81.637421]Training:  50%|█████     | 106/211 [1:19:21<44:18, 25.32s/batch, loss=81.637421]  Training:  50%|█████     | 106/211 [1:22:06<44:18, 25.32s/batch, loss=86.904083]Training:  51%|█████     | 107/211 [1:22:06<1:56:29, 67.21s/batch, loss=86.904083]Training:  51%|█████     | 107/211 [1:22:09<1:56:29, 67.21s/batch, loss=89.142242]Training:  51%|█████     | 108/211 [1:22:09<1:22:22, 47.98s/batch, loss=89.142242]Training:  51%|█████     | 108/211 [1:22:12<1:22:22, 47.98s/batch, loss=84.754982]Training:  52%|█████▏    | 109/211 [1:22:12<58:39, 34.50s/batch, loss=84.754982]  Training:  52%|█████▏    | 109/211 [1:22:15<58:39, 34.50s/batch, loss=86.327164]Training:  52%|█████▏    | 110/211 [1:22:15<42:10, 25.05s/batch, loss=86.327164]Training:  52%|█████▏    | 110/211 [1:25:02<42:10, 25.05s/batch, loss=85.555870]Training:  53%|█████▎    | 111/211 [1:25:03<1:52:51, 67.71s/batch, loss=85.555870]Training:  53%|█████▎    | 111/211 [1:25:06<1:52:51, 67.71s/batch, loss=85.106377]Training:  53%|█████▎    | 112/211 [1:25:06<1:19:42, 48.31s/batch, loss=85.106377]Training:  53%|█████▎    | 112/211 [1:25:09<1:19:42, 48.31s/batch, loss=88.439857]Training:  54%|█████▎    | 113/211 [1:25:09<56:45, 34.75s/batch, loss=88.439857]  Training:  54%|█████▎    | 113/211 [1:25:12<56:45, 34.75s/batch, loss=89.546143]Training:  54%|█████▍    | 114/211 [1:25:12<40:48, 25.24s/batch, loss=89.546143]Training:  54%|█████▍    | 114/211 [1:27:53<40:48, 25.24s/batch, loss=82.223763]Training:  55%|█████▍    | 115/211 [1:27:53<1:45:22, 65.86s/batch, loss=82.223763]Training:  55%|█████▍    | 115/211 [1:27:56<1:45:22, 65.86s/batch, loss=82.879776]Training:  55%|█████▍    | 116/211 [1:27:56<1:14:25, 47.01s/batch, loss=82.879776]Training:  55%|█████▍    | 116/211 [1:27:59<1:14:25, 47.01s/batch, loss=75.988930]Training:  55%|█████▌    | 117/211 [1:27:59<53:00, 33.83s/batch, loss=75.988930]  Training:  55%|█████▌    | 117/211 [1:28:02<53:00, 33.83s/batch, loss=76.567245]Training:  56%|█████▌    | 118/211 [1:28:02<38:07, 24.60s/batch, loss=76.567245]Training:  56%|█████▌    | 118/211 [1:30:52<38:07, 24.60s/batch, loss=70.418732]Training:  56%|█████▋    | 119/211 [1:30:52<1:44:45, 68.32s/batch, loss=70.418732]Training:  56%|█████▋    | 119/211 [1:30:55<1:44:45, 68.32s/batch, loss=81.675804]Training:  57%|█████▋    | 120/211 [1:30:55<1:13:56, 48.76s/batch, loss=81.675804]Training:  57%|█████▋    | 120/211 [1:30:58<1:13:56, 48.76s/batch, loss=74.925369]Training:  57%|█████▋    | 121/211 [1:30:58<52:35, 35.06s/batch, loss=74.925369]  Training:  57%|█████▋    | 121/211 [1:31:01<52:35, 35.06s/batch, loss=79.140022]Training:  58%|█████▊    | 122/211 [1:31:01<37:45, 25.45s/batch, loss=79.140022]Training:  58%|█████▊    | 122/211 [1:34:03<37:45, 25.45s/batch, loss=73.192963]Training:  58%|█████▊    | 123/211 [1:34:03<1:46:06, 72.34s/batch, loss=73.192963]Training:  58%|█████▊    | 123/211 [1:34:06<1:46:06, 72.34s/batch, loss=75.419823]Training:  59%|█████▉    | 124/211 [1:34:06<1:14:44, 51.55s/batch, loss=75.419823]Training:  59%|█████▉    | 124/211 [1:34:09<1:14:44, 51.55s/batch, loss=76.561668]Training:  59%|█████▉    | 125/211 [1:34:09<53:01, 37.00s/batch, loss=76.561668]  Training:  59%|█████▉    | 125/211 [1:34:12<53:01, 37.00s/batch, loss=84.062172]Training:  60%|█████▉    | 126/211 [1:34:12<38:00, 26.82s/batch, loss=84.062172]Training:  60%|█████▉    | 126/211 [1:37:14<38:00, 26.82s/batch, loss=79.200897]Training:  60%|██████    | 127/211 [1:37:14<1:42:50, 73.46s/batch, loss=79.200897]Training:  60%|██████    | 127/211 [1:37:18<1:42:50, 73.46s/batch, loss=69.832314]Training:  61%|██████    | 128/211 [1:37:18<1:12:25, 52.35s/batch, loss=69.832314]Training:  61%|██████    | 128/211 [1:37:21<1:12:25, 52.35s/batch, loss=76.256958]Training:  61%|██████    | 129/211 [1:37:21<51:19, 37.56s/batch, loss=76.256958]  Training:  61%|██████    | 129/211 [1:37:24<51:19, 37.56s/batch, loss=76.372871]Training:  62%|██████▏   | 130/211 [1:37:24<36:45, 27.23s/batch, loss=76.372871]Training:  62%|██████▏   | 130/211 [1:40:10<36:45, 27.23s/batch, loss=75.536758]Training:  62%|██████▏   | 131/211 [1:40:10<1:31:52, 68.91s/batch, loss=75.536758]Training:  62%|██████▏   | 131/211 [1:40:13<1:31:52, 68.91s/batch, loss=70.814476]Training:  63%|██████▎   | 132/211 [1:40:13<1:04:42, 49.15s/batch, loss=70.814476]Training:  63%|██████▎   | 132/211 [1:40:16<1:04:42, 49.15s/batch, loss=74.024986]Training:  63%|██████▎   | 133/211 [1:40:16<45:54, 35.32s/batch, loss=74.024986]  Training:  63%|██████▎   | 133/211 [1:40:19<45:54, 35.32s/batch, loss=73.927612]Training:  64%|██████▎   | 134/211 [1:40:19<32:53, 25.64s/batch, loss=73.927612]Training:  64%|██████▎   | 134/211 [1:43:10<32:53, 25.64s/batch, loss=70.762878]Training:  64%|██████▍   | 135/211 [1:43:10<1:27:36, 69.16s/batch, loss=70.762878]Training:  64%|██████▍   | 135/211 [1:43:13<1:27:36, 69.16s/batch, loss=75.491684]Training:  64%|██████▍   | 136/211 [1:43:13<1:01:40, 49.34s/batch, loss=75.491684]Training:  64%|██████▍   | 136/211 [1:43:16<1:01:40, 49.34s/batch, loss=65.944664]Training:  65%|██████▍   | 137/211 [1:43:16<43:43, 35.45s/batch, loss=65.944664]  Training:  65%|██████▍   | 137/211 [1:43:19<43:43, 35.45s/batch, loss=68.379677]Training:  65%|██████▌   | 138/211 [1:43:19<31:17, 25.72s/batch, loss=68.379677]Training:  65%|██████▌   | 138/211 [1:46:00<31:17, 25.72s/batch, loss=69.211319]Training:  66%|██████▌   | 139/211 [1:46:00<1:19:37, 66.35s/batch, loss=69.211319]Training:  66%|██████▌   | 139/211 [1:46:03<1:19:37, 66.35s/batch, loss=69.734482]Training:  66%|██████▋   | 140/211 [1:46:03<56:01, 47.35s/batch, loss=69.734482]  Training:  66%|██████▋   | 140/211 [1:46:06<56:01, 47.35s/batch, loss=72.335205]Training:  67%|██████▋   | 141/211 [1:46:06<39:44, 34.06s/batch, loss=72.335205]Training:  67%|██████▋   | 141/211 [1:46:09<39:44, 34.06s/batch, loss=65.663109]Training:  67%|██████▋   | 142/211 [1:46:09<28:29, 24.77s/batch, loss=65.663109]Training:  67%|██████▋   | 142/211 [1:49:01<28:29, 24.77s/batch, loss=72.374573]Training:  68%|██████▊   | 143/211 [1:49:02<1:18:18, 69.10s/batch, loss=72.374573]Training:  68%|██████▊   | 143/211 [1:49:05<1:18:18, 69.10s/batch, loss=62.637043]Training:  68%|██████▊   | 144/211 [1:49:05<55:01, 49.28s/batch, loss=62.637043]  Training:  68%|██████▊   | 144/211 [1:49:08<55:01, 49.28s/batch, loss=64.862297]Training:  69%|██████▊   | 145/211 [1:49:08<38:59, 35.44s/batch, loss=64.862297]Training:  69%|██████▊   | 145/211 [1:49:11<38:59, 35.44s/batch, loss=67.895348]Training:  69%|██████▉   | 146/211 [1:49:11<27:52, 25.73s/batch, loss=67.895348]Training:  69%|██████▉   | 146/211 [1:51:45<27:52, 25.73s/batch, loss=64.513451]Training:  70%|██████▉   | 147/211 [1:51:46<1:08:41, 64.40s/batch, loss=64.513451]Training:  70%|██████▉   | 147/211 [1:51:49<1:08:41, 64.40s/batch, loss=71.839264]Training:  70%|███████   | 148/211 [1:51:49<48:17, 45.99s/batch, loss=71.839264]  Training:  70%|███████   | 148/211 [1:51:52<48:17, 45.99s/batch, loss=69.889664]Training:  71%|███████   | 149/211 [1:51:52<34:12, 33.10s/batch, loss=69.889664]Training:  71%|███████   | 149/211 [1:51:55<34:12, 33.10s/batch, loss=66.367294]Training:  71%|███████   | 150/211 [1:51:55<24:29, 24.08s/batch, loss=66.367294]Training:  71%|███████   | 150/211 [1:54:42<24:29, 24.08s/batch, loss=61.495403]Training:  72%|███████▏  | 151/211 [1:54:42<1:06:59, 66.99s/batch, loss=61.495403]Training:  72%|███████▏  | 151/211 [1:54:45<1:06:59, 66.99s/batch, loss=74.411484]Training:  72%|███████▏  | 152/211 [1:54:45<47:00, 47.80s/batch, loss=74.411484]  Training:  72%|███████▏  | 152/211 [1:54:48<47:00, 47.80s/batch, loss=65.902336]Training:  73%|███████▎  | 153/211 [1:54:48<33:14, 34.38s/batch, loss=65.902336]Training:  73%|███████▎  | 153/211 [1:54:51<33:14, 34.38s/batch, loss=64.566391]Training:  73%|███████▎  | 154/211 [1:54:51<23:45, 25.01s/batch, loss=64.566391]Training:  73%|███████▎  | 154/211 [1:57:53<23:45, 25.01s/batch, loss=66.310585]Training:  73%|███████▎  | 155/211 [1:57:54<1:07:27, 72.28s/batch, loss=66.310585]Training:  73%|███████▎  | 155/211 [1:57:57<1:07:27, 72.28s/batch, loss=63.106346]Training:  74%|███████▍  | 156/211 [1:57:57<47:13, 51.52s/batch, loss=63.106346]  Training:  74%|███████▍  | 156/211 [1:58:00<47:13, 51.52s/batch, loss=65.414284]Training:  74%|███████▍  | 157/211 [1:58:00<33:17, 36.99s/batch, loss=65.414284]Training:  74%|███████▍  | 157/211 [1:58:03<33:17, 36.99s/batch, loss=60.157238]Training:  75%|███████▍  | 158/211 [1:58:03<23:40, 26.80s/batch, loss=60.157238]Training:  75%|███████▍  | 158/211 [2:00:49<23:40, 26.80s/batch, loss=65.143456]Training:  75%|███████▌  | 159/211 [2:00:49<59:24, 68.56s/batch, loss=65.143456]Training:  75%|███████▌  | 159/211 [2:00:52<59:24, 68.56s/batch, loss=61.940784]Training:  76%|███████▌  | 160/211 [2:00:52<41:33, 48.90s/batch, loss=61.940784]Training:  76%|███████▌  | 160/211 [2:00:55<41:33, 48.90s/batch, loss=59.310909]Training:  76%|███████▋  | 161/211 [2:00:55<29:17, 35.15s/batch, loss=59.310909]Training:  76%|███████▋  | 161/211 [2:00:58<29:17, 35.15s/batch, loss=57.566113]Training:  77%|███████▋  | 162/211 [2:00:58<20:50, 25.52s/batch, loss=57.566113]Training:  77%|███████▋  | 162/211 [2:03:44<20:50, 25.52s/batch, loss=60.917912]Training:  77%|███████▋  | 163/211 [2:03:45<54:28, 68.09s/batch, loss=60.917912]Training:  77%|███████▋  | 163/211 [2:03:48<54:28, 68.09s/batch, loss=61.818195]Training:  78%|███████▊  | 164/211 [2:03:48<38:02, 48.57s/batch, loss=61.818195]Training:  78%|███████▊  | 164/211 [2:03:51<38:02, 48.57s/batch, loss=65.835243]Training:  78%|███████▊  | 165/211 [2:03:51<26:46, 34.92s/batch, loss=65.835243]Training:  78%|███████▊  | 165/211 [2:03:55<26:46, 34.92s/batch, loss=58.417938]Training:  79%|███████▊  | 166/211 [2:03:55<19:01, 25.36s/batch, loss=58.417938]Training:  79%|███████▊  | 166/211 [2:06:35<19:01, 25.36s/batch, loss=59.458946]Training:  79%|███████▉  | 167/211 [2:06:35<48:22, 65.97s/batch, loss=59.458946]Training:  79%|███████▉  | 167/211 [2:06:38<48:22, 65.97s/batch, loss=58.895271]Training:  80%|███████▉  | 168/211 [2:06:38<33:46, 47.12s/batch, loss=58.895271]Training:  80%|███████▉  | 168/211 [2:06:41<33:46, 47.12s/batch, loss=57.955997]Training:  80%|████████  | 169/211 [2:06:41<23:44, 33.91s/batch, loss=57.955997]Training:  80%|████████  | 169/211 [2:06:44<23:44, 33.91s/batch, loss=57.680210]Training:  81%|████████  | 170/211 [2:06:44<16:50, 24.64s/batch, loss=57.680210]Training:  81%|████████  | 170/211 [2:09:40<16:50, 24.64s/batch, loss=56.622147]Training:  81%|████████  | 171/211 [2:09:40<46:41, 70.03s/batch, loss=56.622147]Training:  81%|████████  | 171/211 [2:09:43<46:41, 70.03s/batch, loss=61.977695]Training:  82%|████████▏ | 172/211 [2:09:43<32:27, 49.93s/batch, loss=61.977695]Training:  82%|████████▏ | 172/211 [2:09:46<32:27, 49.93s/batch, loss=52.218227]Training:  82%|████████▏ | 173/211 [2:09:46<22:42, 35.86s/batch, loss=52.218227]Training:  82%|████████▏ | 173/211 [2:09:50<22:42, 35.86s/batch, loss=65.873093]Training:  82%|████████▏ | 174/211 [2:09:50<16:02, 26.02s/batch, loss=65.873093]Training:  82%|████████▏ | 174/211 [2:12:29<16:02, 26.02s/batch, loss=52.797050]Training:  83%|████████▎ | 175/211 [2:12:29<39:40, 66.13s/batch, loss=52.797050]Training:  83%|████████▎ | 175/211 [2:12:32<39:40, 66.13s/batch, loss=53.391239]Training:  83%|████████▎ | 176/211 [2:12:32<27:32, 47.21s/batch, loss=53.391239]Training:  83%|████████▎ | 176/211 [2:12:35<27:32, 47.21s/batch, loss=50.820702]Training:  84%|████████▍ | 177/211 [2:12:35<19:14, 33.95s/batch, loss=50.820702]Training:  84%|████████▍ | 177/211 [2:12:39<19:14, 33.95s/batch, loss=54.092632]Training:  84%|████████▍ | 178/211 [2:12:39<13:38, 24.81s/batch, loss=54.092632]Training:  84%|████████▍ | 178/211 [2:15:27<13:38, 24.81s/batch, loss=51.092709]Training:  85%|████████▍ | 179/211 [2:15:28<36:16, 68.01s/batch, loss=51.092709]Training:  85%|████████▍ | 179/211 [2:15:31<36:16, 68.01s/batch, loss=55.473167]Training:  85%|████████▌ | 180/211 [2:15:31<25:03, 48.51s/batch, loss=55.473167]Training:  85%|████████▌ | 180/211 [2:15:34<25:03, 48.51s/batch, loss=53.370663]Training:  86%|████████▌ | 181/211 [2:15:34<17:26, 34.87s/batch, loss=53.370663]Training:  86%|████████▌ | 181/211 [2:15:39<17:26, 34.87s/batch, loss=52.739090]Training:  86%|████████▋ | 182/211 [2:15:39<12:33, 26.00s/batch, loss=52.739090]Training:  86%|████████▋ | 182/211 [2:18:16<12:33, 26.00s/batch, loss=54.499226]Training:  87%|████████▋ | 183/211 [2:18:16<30:28, 65.29s/batch, loss=54.499226]Training:  87%|████████▋ | 183/211 [2:18:19<30:28, 65.29s/batch, loss=58.088783]Training:  87%|████████▋ | 184/211 [2:18:19<20:58, 46.62s/batch, loss=58.088783]Training:  87%|████████▋ | 184/211 [2:18:22<20:58, 46.62s/batch, loss=55.822720]Training:  88%|████████▊ | 185/211 [2:18:22<14:32, 33.56s/batch, loss=55.822720]Training:  88%|████████▊ | 185/211 [2:18:51<14:32, 33.56s/batch, loss=56.454071]Training:  88%|████████▊ | 186/211 [2:18:51<13:22, 32.10s/batch, loss=56.454071]Training:  88%|████████▊ | 186/211 [2:21:12<13:22, 32.10s/batch, loss=55.539669]Training:  89%|████████▊ | 187/211 [2:21:13<26:00, 65.02s/batch, loss=55.539669]Training:  89%|████████▊ | 187/211 [2:21:16<26:00, 65.02s/batch, loss=51.885994]Training:  89%|████████▉ | 188/211 [2:21:16<17:47, 46.43s/batch, loss=51.885994]Training:  89%|████████▉ | 188/211 [2:21:19<17:47, 46.43s/batch, loss=51.076385]Training:  90%|████████▉ | 189/211 [2:21:19<12:15, 33.43s/batch, loss=51.076385]Training:  90%|████████▉ | 189/211 [2:21:50<12:15, 33.43s/batch, loss=53.542847]Training:  90%|█████████ | 190/211 [2:21:50<11:29, 32.83s/batch, loss=53.542847]Training:  90%|█████████ | 190/211 [2:24:14<11:29, 32.83s/batch, loss=52.016041]Training:  91%|█████████ | 191/211 [2:24:14<22:05, 66.26s/batch, loss=52.016041]Training:  91%|█████████ | 191/211 [2:24:17<22:05, 66.26s/batch, loss=47.914917]Training:  91%|█████████ | 192/211 [2:24:17<14:58, 47.29s/batch, loss=47.914917]Training:  91%|█████████ | 192/211 [2:24:21<14:58, 47.29s/batch, loss=50.501354]Training:  91%|█████████▏| 193/211 [2:24:21<10:12, 34.03s/batch, loss=50.501354]Training:  91%|█████████▏| 193/211 [2:25:00<10:12, 34.03s/batch, loss=49.429302]Training:  92%|█████████▏| 194/211 [2:25:00<10:08, 35.79s/batch, loss=49.429302]Training:  92%|█████████▏| 194/211 [2:27:13<10:08, 35.79s/batch, loss=55.456921]Training:  92%|█████████▏| 195/211 [2:27:13<17:15, 64.73s/batch, loss=55.456921]Training:  92%|█████████▏| 195/211 [2:27:16<17:15, 64.73s/batch, loss=49.627068]Training:  93%|█████████▎| 196/211 [2:27:16<11:33, 46.23s/batch, loss=49.627068]Training:  93%|█████████▎| 196/211 [2:27:19<11:33, 46.23s/batch, loss=51.723625]Training:  93%|█████████▎| 197/211 [2:27:19<07:46, 33.29s/batch, loss=51.723625]Training:  93%|█████████▎| 197/211 [2:27:46<07:46, 33.29s/batch, loss=49.648125]Training:  94%|█████████▍| 198/211 [2:27:46<06:48, 31.43s/batch, loss=49.648125]Training:  94%|█████████▍| 198/211 [2:30:14<06:48, 31.43s/batch, loss=50.891941]Training:  94%|█████████▍| 199/211 [2:30:14<13:18, 66.53s/batch, loss=50.891941]Training:  94%|█████████▍| 199/211 [2:30:17<13:18, 66.53s/batch, loss=51.740360]Training:  95%|█████████▍| 200/211 [2:30:17<08:42, 47.48s/batch, loss=51.740360]Training:  95%|█████████▍| 200/211 [2:30:21<08:42, 47.48s/batch, loss=51.238014]Training:  95%|█████████▌| 201/211 [2:30:21<05:41, 34.15s/batch, loss=51.238014]Training:  95%|█████████▌| 201/211 [2:30:56<05:41, 34.15s/batch, loss=46.055756]Training:  96%|█████████▌| 202/211 [2:30:56<05:11, 34.59s/batch, loss=46.055756]Training:  96%|█████████▌| 202/211 [2:33:05<05:11, 34.59s/batch, loss=48.238396]Training:  96%|█████████▌| 203/211 [2:33:05<08:23, 62.88s/batch, loss=48.238396]Training:  96%|█████████▌| 203/211 [2:33:08<08:23, 62.88s/batch, loss=50.613232]Training:  97%|█████████▋| 204/211 [2:33:08<05:14, 44.95s/batch, loss=50.613232]Training:  97%|█████████▋| 204/211 [2:33:11<05:14, 44.95s/batch, loss=48.755424]Training:  97%|█████████▋| 205/211 [2:33:11<03:14, 32.37s/batch, loss=48.755424]Training:  97%|█████████▋| 205/211 [2:33:45<03:14, 32.37s/batch, loss=47.828560]Training:  98%|█████████▊| 206/211 [2:33:45<02:44, 32.88s/batch, loss=47.828560]Training:  98%|█████████▊| 206/211 [2:35:43<02:44, 32.88s/batch, loss=45.559158]Training:  98%|█████████▊| 207/211 [2:35:43<03:53, 58.32s/batch, loss=45.559158]Training:  98%|█████████▊| 207/211 [2:35:46<03:53, 58.32s/batch, loss=50.808273]Training:  99%|█████████▊| 208/211 [2:35:46<02:05, 41.74s/batch, loss=50.808273]Training:  99%|█████████▊| 208/211 [2:35:49<02:05, 41.74s/batch, loss=52.422359]Training:  99%|█████████▉| 209/211 [2:35:49<01:00, 30.14s/batch, loss=52.422359]Training:  99%|█████████▉| 209/211 [2:36:07<01:00, 30.14s/batch, loss=48.294632]Training: 100%|█████████▉| 210/211 [2:36:07<00:26, 26.42s/batch, loss=48.294632]Training: 100%|█████████▉| 210/211 [2:36:07<00:26, 26.42s/batch, loss=48.623482]Training: 100%|██████████| 211/211 [2:36:07<00:00, 18.71s/batch, loss=48.623482]Training: 100%|██████████| 211/211 [2:36:08<00:00, 44.40s/batch, loss=48.623482]
/home/alexandre-tonon/anaconda3/envs/pie_env/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
Epoch 1, Train Loss: 143.3414, Val Loss: 47.1213
Training:   0%|          | 0/211 [00:00<?, ?batch/s]Training:   0%|          | 0/211 [02:12<?, ?batch/s, loss=48.402916]Training:   0%|          | 1/211 [02:12<7:43:41, 132.48s/batch, loss=48.402916]Training:   0%|          | 1/211 [02:34<7:43:41, 132.48s/batch, loss=47.655216]Training:   1%|          | 2/211 [02:34<3:55:03, 67.48s/batch, loss=47.655216] Training:   1%|          | 2/211 [02:37<3:55:03, 67.48s/batch, loss=44.014915]Training:   1%|▏         | 3/211 [02:37<2:12:03, 38.09s/batch, loss=44.014915]Training:   1%|▏         | 3/211 [02:40<2:12:03, 38.09s/batch, loss=45.693008]Training:   2%|▏         | 4/211 [02:40<1:23:43, 24.27s/batch, loss=45.693008]Training:   2%|▏         | 4/211 [04:15<1:23:43, 24.27s/batch, loss=45.280754]Training:   2%|▏         | 5/211 [04:15<2:51:15, 49.88s/batch, loss=45.280754]Training:   2%|▏         | 5/211 [04:58<2:51:15, 49.88s/batch, loss=46.835552]Training:   3%|▎         | 6/211 [04:58<2:41:43, 47.33s/batch, loss=46.835552]Training:   3%|▎         | 6/211 [05:01<2:41:43, 47.33s/batch, loss=45.957325]Training:   3%|▎         | 7/211 [05:01<1:51:45, 32.87s/batch, loss=45.957325]Training:   3%|▎         | 7/211 [05:04<1:51:45, 32.87s/batch, loss=42.254005]Training:   4%|▍         | 8/211 [05:04<1:19:11, 23.40s/batch, loss=42.254005]Training:   4%|▍         | 8/211 [06:40<1:19:11, 23.40s/batch, loss=49.694378]Training:   4%|▍         | 9/211 [06:40<2:35:13, 46.10s/batch, loss=49.694378]Training:   4%|▍         | 9/211 [07:32<2:35:13, 46.10s/batch, loss=42.020016]Training:   5%|▍         | 10/211 [07:32<2:40:25, 47.89s/batch, loss=42.020016]Training:   5%|▍         | 10/211 [07:35<2:40:25, 47.89s/batch, loss=46.389717]Training:   5%|▌         | 11/211 [07:35<1:53:54, 34.17s/batch, loss=46.389717]Training:   5%|▌         | 11/211 [07:38<1:53:54, 34.17s/batch, loss=48.906048]Training:   6%|▌         | 12/211 [07:38<1:21:57, 24.71s/batch, loss=48.906048]Training:   6%|▌         | 12/211 [09:14<1:21:57, 24.71s/batch, loss=46.403618]Training:   6%|▌         | 13/211 [09:14<2:33:02, 46.38s/batch, loss=46.403618]Training:   6%|▌         | 13/211 [10:03<2:33:02, 46.38s/batch, loss=45.351673]Training:   7%|▋         | 14/211 [10:03<2:34:47, 47.14s/batch, loss=45.351673]Training:   7%|▋         | 14/211 [10:06<2:34:47, 47.14s/batch, loss=41.152325]Training:   7%|▋         | 15/211 [10:06<1:50:40, 33.88s/batch, loss=41.152325]Training:   7%|▋         | 15/211 [10:09<1:50:40, 33.88s/batch, loss=43.245659]Training:   8%|▊         | 16/211 [10:09<1:19:59, 24.62s/batch, loss=43.245659]Training:   8%|▊         | 16/211 [11:46<1:19:59, 24.62s/batch, loss=46.454529]Training:   8%|▊         | 17/211 [11:47<2:30:05, 46.42s/batch, loss=46.454529]Training:   8%|▊         | 17/211 [12:32<2:30:05, 46.42s/batch, loss=47.267033]Training:   9%|▊         | 18/211 [12:32<2:28:04, 46.04s/batch, loss=47.267033]Training:   9%|▊         | 18/211 [12:35<2:28:04, 46.04s/batch, loss=40.637177]Training:   9%|▉         | 19/211 [12:35<1:46:01, 33.13s/batch, loss=40.637177]Training:   9%|▉         | 19/211 [12:38<1:46:01, 33.13s/batch, loss=43.115913]Training:   9%|▉         | 20/211 [12:38<1:16:46, 24.12s/batch, loss=43.115913]Training:   9%|▉         | 20/211 [14:15<1:16:46, 24.12s/batch, loss=43.123272]Training:  10%|▉         | 21/211 [14:15<2:25:25, 45.92s/batch, loss=43.123272]Training:  10%|▉         | 21/211 [15:23<2:25:25, 45.92s/batch, loss=45.418396]Training:  10%|█         | 22/211 [15:23<2:45:52, 52.66s/batch, loss=45.418396]Training:  10%|█         | 22/211 [15:26<2:45:52, 52.66s/batch, loss=39.196804]Training:  11%|█         | 23/211 [15:26<1:58:24, 37.79s/batch, loss=39.196804]Training:  11%|█         | 23/211 [15:29<1:58:24, 37.79s/batch, loss=42.229786]Training:  11%|█▏        | 24/211 [15:29<1:25:21, 27.39s/batch, loss=42.229786]Training:  11%|█▏        | 24/211 [16:48<1:25:21, 27.39s/batch, loss=41.907707]Training:  12%|█▏        | 25/211 [16:48<2:12:55, 42.88s/batch, loss=41.907707]Training:  12%|█▏        | 25/211 [17:45<2:12:55, 42.88s/batch, loss=41.070408]Training:  12%|█▏        | 26/211 [17:45<2:25:14, 47.10s/batch, loss=41.070408]Training:  12%|█▏        | 26/211 [17:48<2:25:14, 47.10s/batch, loss=41.851986]Training:  13%|█▎        | 27/211 [17:48<1:43:57, 33.90s/batch, loss=41.851986]Training:  13%|█▎        | 27/211 [17:52<1:43:57, 33.90s/batch, loss=39.397129]Training:  13%|█▎        | 28/211 [17:52<1:15:18, 24.69s/batch, loss=39.397129]Training:  13%|█▎        | 28/211 [19:12<1:15:18, 24.69s/batch, loss=47.364429]Training:  14%|█▎        | 29/211 [19:12<2:05:29, 41.37s/batch, loss=47.364429]Training:  14%|█▎        | 29/211 [19:56<2:05:29, 41.37s/batch, loss=43.663723]Training:  14%|█▍        | 30/211 [19:56<2:06:57, 42.09s/batch, loss=43.663723]Training:  14%|█▍        | 30/211 [19:59<2:06:57, 42.09s/batch, loss=42.107803]Training:  15%|█▍        | 31/211 [19:59<1:31:09, 30.39s/batch, loss=42.107803]Training:  15%|█▍        | 31/211 [20:02<1:31:09, 30.39s/batch, loss=42.582165]Training:  15%|█▌        | 32/211 [20:02<1:06:11, 22.19s/batch, loss=42.582165]Training:  15%|█▌        | 32/211 [21:32<1:06:11, 22.19s/batch, loss=42.447136]Training:  16%|█▌        | 33/211 [21:33<2:07:08, 42.86s/batch, loss=42.447136]Training:  16%|█▌        | 33/211 [22:13<2:07:08, 42.86s/batch, loss=41.541367]Training:  16%|█▌        | 34/211 [22:13<2:03:49, 41.97s/batch, loss=41.541367]Training:  16%|█▌        | 34/211 [22:16<2:03:49, 41.97s/batch, loss=40.501949]Training:  17%|█▋        | 35/211 [22:16<1:28:55, 30.31s/batch, loss=40.501949]Training:  17%|█▋        | 35/211 [22:19<1:28:55, 30.31s/batch, loss=41.245457]Training:  17%|█▋        | 36/211 [22:19<1:04:34, 22.14s/batch, loss=41.245457]Training:  17%|█▋        | 36/211 [24:07<1:04:34, 22.14s/batch, loss=47.383514]Training:  18%|█▊        | 37/211 [24:07<2:19:01, 47.94s/batch, loss=47.383514]Training:  18%|█▊        | 37/211 [24:40<2:19:01, 47.94s/batch, loss=39.180798]Training:  18%|█▊        | 38/211 [24:40<2:05:11, 43.42s/batch, loss=39.180798]Training:  18%|█▊        | 38/211 [24:43<2:05:11, 43.42s/batch, loss=40.781788]Training:  18%|█▊        | 39/211 [24:43<1:29:47, 31.32s/batch, loss=40.781788]Training:  18%|█▊        | 39/211 [24:46<1:29:47, 31.32s/batch, loss=41.492767]Training:  19%|█▉        | 40/211 [24:46<1:05:07, 22.85s/batch, loss=41.492767]Training:  19%|█▉        | 40/211 [26:13<1:05:07, 22.85s/batch, loss=39.825153]Training:  19%|█▉        | 41/211 [26:13<1:59:02, 42.01s/batch, loss=39.825153]Training:  19%|█▉        | 41/211 [27:00<1:59:02, 42.01s/batch, loss=41.337650]Training:  20%|█▉        | 42/211 [27:00<2:02:32, 43.51s/batch, loss=41.337650]Training:  20%|█▉        | 42/211 [27:03<2:02:32, 43.51s/batch, loss=40.564762]Training:  20%|██        | 43/211 [27:03<1:27:56, 31.41s/batch, loss=40.564762]Training:  20%|██        | 43/211 [27:06<1:27:56, 31.41s/batch, loss=42.182705]Training:  21%|██        | 44/211 [27:06<1:03:46, 22.91s/batch, loss=42.182705]Training:  21%|██        | 44/211 [28:30<1:03:46, 22.91s/batch, loss=37.089863]Training:  21%|██▏       | 45/211 [28:30<1:54:16, 41.31s/batch, loss=37.089863]Training:  21%|██▏       | 45/211 [29:27<1:54:16, 41.31s/batch, loss=38.260715]Training:  22%|██▏       | 46/211 [29:27<2:06:09, 45.87s/batch, loss=38.260715]Training:  22%|██▏       | 46/211 [29:30<2:06:09, 45.87s/batch, loss=38.430016]Training:  22%|██▏       | 47/211 [29:30<1:30:18, 33.04s/batch, loss=38.430016]Training:  22%|██▏       | 47/211 [29:33<1:30:18, 33.04s/batch, loss=36.799866]Training:  23%|██▎       | 48/211 [29:33<1:05:26, 24.09s/batch, loss=36.799866]Training:  23%|██▎       | 48/211 [30:58<1:05:26, 24.09s/batch, loss=42.920891]Training:  23%|██▎       | 49/211 [30:58<1:54:25, 42.38s/batch, loss=42.920891]Training:  23%|██▎       | 49/211 [31:47<1:54:25, 42.38s/batch, loss=40.721970]Training:  24%|██▎       | 50/211 [31:47<1:59:11, 44.42s/batch, loss=40.721970]Training:  24%|██▎       | 50/211 [31:51<1:59:11, 44.42s/batch, loss=38.220264]Training:  24%|██▍       | 51/211 [31:51<1:25:25, 32.04s/batch, loss=38.220264]Training:  24%|██▍       | 51/211 [31:54<1:25:25, 32.04s/batch, loss=39.445183]Training:  25%|██▍       | 52/211 [31:54<1:01:51, 23.34s/batch, loss=39.445183]Training:  25%|██▍       | 52/211 [33:34<1:01:51, 23.34s/batch, loss=37.366989]Training:  25%|██▌       | 53/211 [33:34<2:02:17, 46.44s/batch, loss=37.366989]Training:  25%|██▌       | 53/211 [34:26<2:02:17, 46.44s/batch, loss=39.119102]Training:  26%|██▌       | 54/211 [34:26<2:06:15, 48.25s/batch, loss=39.119102]Training:  26%|██▌       | 54/211 [34:29<2:06:15, 48.25s/batch, loss=43.067860]Training:  26%|██▌       | 55/211 [34:29<1:30:12, 34.69s/batch, loss=43.067860]Training:  26%|██▌       | 55/211 [34:33<1:30:12, 34.69s/batch, loss=36.517818]Training:  27%|██▋       | 56/211 [34:33<1:05:11, 25.24s/batch, loss=36.517818]Training:  27%|██▋       | 56/211 [35:46<1:05:11, 25.24s/batch, loss=39.629829]Training:  27%|██▋       | 57/211 [35:46<1:41:44, 39.64s/batch, loss=39.629829]Training:  27%|██▋       | 57/211 [36:50<1:41:44, 39.64s/batch, loss=38.526386]Training:  27%|██▋       | 58/211 [36:50<1:59:56, 47.04s/batch, loss=38.526386]Training:  27%|██▋       | 58/211 [36:53<1:59:56, 47.04s/batch, loss=42.118507]Training:  28%|██▊       | 59/211 [36:53<1:25:46, 33.86s/batch, loss=42.118507]Training:  28%|██▊       | 59/211 [36:56<1:25:46, 33.86s/batch, loss=37.337944]Training:  28%|██▊       | 60/211 [36:56<1:01:58, 24.62s/batch, loss=37.337944]Training:  28%|██▊       | 60/211 [37:59<1:01:58, 24.62s/batch, loss=38.454151]Training:  29%|██▉       | 61/211 [38:00<1:30:29, 36.20s/batch, loss=38.454151]Training:  29%|██▉       | 61/211 [39:01<1:30:29, 36.20s/batch, loss=35.975555]Training:  29%|██▉       | 62/211 [39:01<1:48:25, 43.66s/batch, loss=35.975555]Training:  29%|██▉       | 62/211 [39:04<1:48:25, 43.66s/batch, loss=37.896847]Training:  30%|██▉       | 63/211 [39:04<1:17:41, 31.49s/batch, loss=37.896847]Training:  30%|██▉       | 63/211 [39:07<1:17:41, 31.49s/batch, loss=35.415630]Training:  30%|███       | 64/211 [39:07<56:15, 22.97s/batch, loss=35.415630]  Training:  30%|███       | 64/211 [40:23<56:15, 22.97s/batch, loss=39.728867]Training:  31%|███       | 65/211 [40:24<1:35:05, 39.08s/batch, loss=39.728867]Training:  31%|███       | 65/211 [41:40<1:35:05, 39.08s/batch, loss=38.097210]Training:  31%|███▏      | 66/211 [41:40<2:01:31, 50.28s/batch, loss=38.097210]Training:  31%|███▏      | 66/211 [41:43<2:01:31, 50.28s/batch, loss=37.844223]Training:  32%|███▏      | 67/211 [41:43<1:26:42, 36.13s/batch, loss=37.844223]Training:  32%|███▏      | 67/211 [41:46<1:26:42, 36.13s/batch, loss=38.204994]Training:  32%|███▏      | 68/211 [41:46<1:02:32, 26.24s/batch, loss=38.204994]Training:  32%|███▏      | 68/211 [42:28<1:02:32, 26.24s/batch, loss=39.282135]Training:  33%|███▎      | 69/211 [42:29<1:13:35, 31.09s/batch, loss=39.282135]Training:  33%|███▎      | 69/211 [44:04<1:13:35, 31.09s/batch, loss=37.729786]Training:  33%|███▎      | 70/211 [44:04<1:58:03, 50.24s/batch, loss=37.729786]Training:  33%|███▎      | 70/211 [44:07<1:58:03, 50.24s/batch, loss=35.775967]Training:  34%|███▎      | 71/211 [44:07<1:24:16, 36.12s/batch, loss=35.775967]Training:  34%|███▎      | 71/211 [44:10<1:24:16, 36.12s/batch, loss=36.906834]Training:  34%|███▍      | 72/211 [44:10<1:00:43, 26.21s/batch, loss=36.906834]Training:  34%|███▍      | 72/211 [44:59<1:00:43, 26.21s/batch, loss=36.261238]Training:  35%|███▍      | 73/211 [44:59<1:16:26, 33.23s/batch, loss=36.261238]Training:  35%|███▍      | 73/211 [46:15<1:16:26, 33.23s/batch, loss=36.791985]Training:  35%|███▌      | 74/211 [46:15<1:44:59, 45.98s/batch, loss=36.791985]Training:  35%|███▌      | 74/211 [46:22<1:44:59, 45.98s/batch, loss=36.038464]Training:  36%|███▌      | 75/211 [46:22<1:17:47, 34.32s/batch, loss=36.038464]Training:  36%|███▌      | 75/211 [46:25<1:17:47, 34.32s/batch, loss=35.629971]Training:  36%|███▌      | 76/211 [46:25<56:09, 24.96s/batch, loss=35.629971]  Training:  36%|███▌      | 76/211 [47:24<56:09, 24.96s/batch, loss=36.282589]Training:  36%|███▋      | 77/211 [47:24<1:18:22, 35.09s/batch, loss=36.282589]Training:  36%|███▋      | 77/211 [48:41<1:18:22, 35.09s/batch, loss=34.380779]Training:  37%|███▋      | 78/211 [48:41<1:45:38, 47.65s/batch, loss=34.380779]Training:  37%|███▋      | 78/211 [48:44<1:45:38, 47.65s/batch, loss=35.556313]Training:  37%|███▋      | 79/211 [48:44<1:15:23, 34.27s/batch, loss=35.556313]Training:  37%|███▋      | 79/211 [48:47<1:15:23, 34.27s/batch, loss=36.179459]Training:  38%|███▊      | 80/211 [48:47<54:22, 24.90s/batch, loss=36.179459]  Training:  38%|███▊      | 80/211 [50:02<54:22, 24.90s/batch, loss=36.297226]Training:  38%|███▊      | 81/211 [50:02<1:26:21, 39.85s/batch, loss=36.297226]Training:  38%|███▊      | 81/211 [51:08<1:26:21, 39.85s/batch, loss=36.279732]Training:  39%|███▉      | 82/211 [51:08<1:42:20, 47.60s/batch, loss=36.279732]Training:  39%|███▉      | 82/211 [51:15<1:42:20, 47.60s/batch, loss=37.483765]Training:  39%|███▉      | 83/211 [51:15<1:15:33, 35.42s/batch, loss=37.483765]Training:  39%|███▉      | 83/211 [51:18<1:15:33, 35.42s/batch, loss=33.992054]Training:  40%|███▉      | 84/211 [51:18<54:25, 25.72s/batch, loss=33.992054]  Training:  40%|███▉      | 84/211 [52:36<54:25, 25.72s/batch, loss=35.259804]Training:  40%|████      | 85/211 [52:37<1:27:35, 41.71s/batch, loss=35.259804]Training:  40%|████      | 85/211 [53:42<1:27:35, 41.71s/batch, loss=32.286083]Training:  41%|████      | 86/211 [53:42<1:41:42, 48.82s/batch, loss=32.286083]Training:  41%|████      | 86/211 [53:54<1:41:42, 48.82s/batch, loss=34.647282]Training:  41%|████      | 87/211 [53:54<1:18:09, 37.82s/batch, loss=34.647282]Training:  41%|████      | 87/211 [53:57<1:18:09, 37.82s/batch, loss=36.502300]Training:  42%|████▏     | 88/211 [53:57<56:09, 27.40s/batch, loss=36.502300]  Training:  42%|████▏     | 88/211 [55:06<56:09, 27.40s/batch, loss=33.768772]Training:  42%|████▏     | 89/211 [55:06<1:21:02, 39.86s/batch, loss=33.768772]Training:  42%|████▏     | 89/211 [56:12<1:21:02, 39.86s/batch, loss=36.235386]Training:  43%|████▎     | 90/211 [56:12<1:35:50, 47.53s/batch, loss=36.235386]Training:  43%|████▎     | 90/211 [56:15<1:35:50, 47.53s/batch, loss=33.925007]Training:  43%|████▎     | 91/211 [56:15<1:08:23, 34.19s/batch, loss=33.925007]Training:  43%|████▎     | 91/211 [56:18<1:08:23, 34.19s/batch, loss=34.251259]Training:  44%|████▎     | 92/211 [56:18<49:22, 24.90s/batch, loss=34.251259]  Training:  44%|████▎     | 92/211 [57:31<49:22, 24.90s/batch, loss=32.415604]Training:  44%|████▍     | 93/211 [57:32<1:17:42, 39.51s/batch, loss=32.415604]Training:  44%|████▍     | 93/211 [58:40<1:17:42, 39.51s/batch, loss=35.447575]Training:  45%|████▍     | 94/211 [58:40<1:33:45, 48.08s/batch, loss=35.447575]Training:  45%|████▍     | 94/211 [58:43<1:33:45, 48.08s/batch, loss=35.730968]Training:  45%|████▌     | 95/211 [58:43<1:06:51, 34.58s/batch, loss=35.730968]Training:  45%|████▌     | 95/211 [58:46<1:06:51, 34.58s/batch, loss=32.824585]Training:  45%|████▌     | 96/211 [58:46<48:08, 25.12s/batch, loss=32.824585]  Training:  45%|████▌     | 96/211 [59:58<48:08, 25.12s/batch, loss=34.965950]Training:  46%|████▌     | 97/211 [59:58<1:14:31, 39.22s/batch, loss=34.965950]Training:  46%|████▌     | 97/211 [1:01:15<1:14:31, 39.22s/batch, loss=35.659061]Training:  46%|████▋     | 98/211 [1:01:15<1:35:26, 50.68s/batch, loss=35.659061]Training:  46%|████▋     | 98/211 [1:01:18<1:35:26, 50.68s/batch, loss=35.352890]Training:  47%|████▋     | 99/211 [1:01:18<1:07:56, 36.40s/batch, loss=35.352890]Training:  47%|████▋     | 99/211 [1:01:22<1:07:56, 36.40s/batch, loss=35.537403]Training:  47%|████▋     | 100/211 [1:01:22<48:52, 26.42s/batch, loss=35.537403] Training:  47%|████▋     | 100/211 [1:02:16<48:52, 26.42s/batch, loss=35.502205]Training:  48%|████▊     | 101/211 [1:02:16<1:03:52, 34.85s/batch, loss=35.502205]Training:  48%|████▊     | 101/211 [1:03:48<1:03:52, 34.85s/batch, loss=33.014805]Training:  48%|████▊     | 102/211 [1:03:49<1:35:09, 52.39s/batch, loss=33.014805]Training:  48%|████▊     | 102/211 [1:03:52<1:35:09, 52.39s/batch, loss=32.014103]Training:  49%|████▉     | 103/211 [1:03:52<1:07:40, 37.60s/batch, loss=32.014103]Training:  49%|████▉     | 103/211 [1:03:56<1:07:40, 37.60s/batch, loss=35.903679]Training:  49%|████▉     | 104/211 [1:03:56<48:35, 27.25s/batch, loss=35.903679]  Training:  49%|████▉     | 104/211 [1:04:43<48:35, 27.25s/batch, loss=31.605639]Training:  50%|████▉     | 105/211 [1:04:43<58:44, 33.25s/batch, loss=31.605639]Training:  50%|████▉     | 105/211 [1:06:21<58:44, 33.25s/batch, loss=31.361105]Training:  50%|█████     | 106/211 [1:06:21<1:32:24, 52.81s/batch, loss=31.361105]Training:  50%|█████     | 106/211 [1:06:24<1:32:24, 52.81s/batch, loss=30.410803]Training:  51%|█████     | 107/211 [1:06:24<1:05:44, 37.93s/batch, loss=30.410803]Training:  51%|█████     | 107/211 [1:06:28<1:05:44, 37.93s/batch, loss=33.129166]Training:  51%|█████     | 108/211 [1:06:28<47:17, 27.55s/batch, loss=33.129166]  Training:  51%|█████     | 108/211 [1:07:04<47:17, 27.55s/batch, loss=31.620722]Training:  52%|█████▏    | 109/211 [1:07:04<51:09, 30.09s/batch, loss=31.620722]Training:  52%|█████▏    | 109/211 [1:08:33<51:09, 30.09s/batch, loss=30.791021]Training:  52%|█████▏    | 110/211 [1:08:33<1:20:16, 47.69s/batch, loss=30.791021]Training:  52%|█████▏    | 110/211 [1:08:36<1:20:16, 47.69s/batch, loss=28.725069]Training:  53%|█████▎    | 111/211 [1:08:36<57:10, 34.31s/batch, loss=28.725069]  Training:  53%|█████▎    | 111/211 [1:08:39<57:10, 34.31s/batch, loss=32.476967]Training:  53%|█████▎    | 112/211 [1:08:39<41:10, 24.95s/batch, loss=32.476967]Training:  53%|█████▎    | 112/211 [1:09:13<41:10, 24.95s/batch, loss=31.472546]Training:  54%|█████▎    | 113/211 [1:09:13<45:11, 27.67s/batch, loss=31.472546]Training:  54%|█████▎    | 113/211 [1:10:58<45:11, 27.67s/batch, loss=31.395992]Training:  54%|█████▍    | 114/211 [1:10:58<1:22:31, 51.05s/batch, loss=31.395992]Training:  54%|█████▍    | 114/211 [1:11:08<1:22:31, 51.05s/batch, loss=33.514099]Training:  55%|█████▍    | 115/211 [1:11:08<1:01:58, 38.74s/batch, loss=33.514099]Training:  55%|█████▍    | 115/211 [1:11:12<1:01:58, 38.74s/batch, loss=32.095238]Training:  55%|█████▍    | 116/211 [1:11:12<44:25, 28.06s/batch, loss=32.095238]  Training:  55%|█████▍    | 116/211 [1:11:29<44:25, 28.06s/batch, loss=35.673832]Training:  55%|█████▌    | 117/211 [1:11:29<38:57, 24.87s/batch, loss=35.673832]Training:  55%|█████▌    | 117/211 [1:13:22<38:57, 24.87s/batch, loss=32.818680]Training:  56%|█████▌    | 118/211 [1:13:23<1:19:54, 51.55s/batch, loss=32.818680]Training:  56%|█████▌    | 118/211 [1:13:42<1:19:54, 51.55s/batch, loss=32.807404]Training:  56%|█████▋    | 119/211 [1:13:42<1:04:09, 41.84s/batch, loss=32.807404]Training:  56%|█████▋    | 119/211 [1:13:45<1:04:09, 41.84s/batch, loss=29.153893]Training:  57%|█████▋    | 120/211 [1:13:45<45:50, 30.22s/batch, loss=29.153893]  Training:  57%|█████▋    | 120/211 [1:13:56<45:50, 30.22s/batch, loss=31.133989]Training:  57%|█████▋    | 121/211 [1:13:56<36:27, 24.31s/batch, loss=31.133989]Training:  57%|█████▋    | 121/211 [1:15:47<36:27, 24.31s/batch, loss=30.920237]Training:  58%|█████▊    | 122/211 [1:15:48<1:15:11, 50.69s/batch, loss=30.920237]Training:  58%|█████▊    | 122/211 [1:15:51<1:15:11, 50.69s/batch, loss=32.127834]Training:  58%|█████▊    | 123/211 [1:15:51<53:23, 36.40s/batch, loss=32.127834]  Training:  58%|█████▊    | 123/211 [1:15:54<53:23, 36.40s/batch, loss=30.363743]Training:  59%|█████▉    | 124/211 [1:15:54<38:15, 26.39s/batch, loss=30.363743]Training:  59%|█████▉    | 124/211 [1:16:24<38:15, 26.39s/batch, loss=31.630743]Training:  59%|█████▉    | 125/211 [1:16:24<39:26, 27.51s/batch, loss=31.630743]Training:  59%|█████▉    | 125/211 [1:18:20<39:26, 27.51s/batch, loss=30.015486]Training:  60%|█████▉    | 126/211 [1:18:20<1:16:25, 53.94s/batch, loss=30.015486]Training:  60%|█████▉    | 126/211 [1:18:24<1:16:25, 53.94s/batch, loss=31.859510]Training:  60%|██████    | 127/211 [1:18:24<54:46, 39.12s/batch, loss=31.859510]  Training:  60%|██████    | 127/211 [1:18:27<54:46, 39.12s/batch, loss=28.239552]Training:  61%|██████    | 128/211 [1:18:27<39:12, 28.35s/batch, loss=28.239552]Training:  61%|██████    | 128/211 [1:18:57<39:12, 28.35s/batch, loss=30.243132]Training:  61%|██████    | 129/211 [1:18:57<39:09, 28.65s/batch, loss=30.243132]Training:  61%|██████    | 129/211 [1:20:57<39:09, 28.65s/batch, loss=30.216110]Training:  62%|██████▏   | 130/211 [1:20:57<1:15:54, 56.23s/batch, loss=30.216110]Training:  62%|██████▏   | 130/211 [1:21:00<1:15:54, 56.23s/batch, loss=30.898911]Training:  62%|██████▏   | 131/211 [1:21:00<53:43, 40.29s/batch, loss=30.898911]  Training:  62%|██████▏   | 131/211 [1:21:04<53:43, 40.29s/batch, loss=27.985975]Training:  63%|██████▎   | 132/211 [1:21:04<38:22, 29.14s/batch, loss=27.985975]Training:  63%|██████▎   | 132/211 [1:21:09<38:22, 29.14s/batch, loss=30.974146]Training:  63%|██████▎   | 133/211 [1:21:09<28:44, 22.11s/batch, loss=30.974146]Training:  63%|██████▎   | 133/211 [1:23:06<28:44, 22.11s/batch, loss=30.735153]Training:  64%|██████▎   | 134/211 [1:23:06<1:04:43, 50.44s/batch, loss=30.735153]Training:  64%|██████▎   | 134/211 [1:23:13<1:04:43, 50.44s/batch, loss=28.788198]Training:  64%|██████▍   | 135/211 [1:23:13<47:24, 37.43s/batch, loss=28.788198]  Training:  64%|██████▍   | 135/211 [1:23:16<47:24, 37.43s/batch, loss=29.643396]Training:  64%|██████▍   | 136/211 [1:23:16<33:54, 27.13s/batch, loss=29.643396]Training:  64%|██████▍   | 136/211 [1:23:57<33:54, 27.13s/batch, loss=30.836779]Training:  65%|██████▍   | 137/211 [1:23:57<38:45, 31.42s/batch, loss=30.836779]Training:  65%|██████▍   | 137/211 [1:25:29<38:45, 31.42s/batch, loss=29.786871]Training:  65%|██████▌   | 138/211 [1:25:29<1:00:07, 49.42s/batch, loss=29.786871]Training:  65%|██████▌   | 138/211 [1:25:45<1:00:07, 49.42s/batch, loss=32.479763]Training:  66%|██████▌   | 139/211 [1:25:45<47:20, 39.45s/batch, loss=32.479763]  Training:  66%|██████▌   | 139/211 [1:25:48<47:20, 39.45s/batch, loss=29.421846]Training:  66%|██████▋   | 140/211 [1:25:48<33:45, 28.53s/batch, loss=29.421846]Training:  66%|██████▋   | 140/211 [1:26:31<33:45, 28.53s/batch, loss=29.404596]Training:  67%|██████▋   | 141/211 [1:26:31<38:09, 32.71s/batch, loss=29.404596]Training:  67%|██████▋   | 141/211 [1:27:46<38:09, 32.71s/batch, loss=27.697592]Training:  67%|██████▋   | 142/211 [1:27:46<52:29, 45.64s/batch, loss=27.697592]Training:  67%|██████▋   | 142/211 [1:28:10<52:29, 45.64s/batch, loss=31.380264]Training:  68%|██████▊   | 143/211 [1:28:10<44:16, 39.06s/batch, loss=31.380264]Training:  68%|██████▊   | 143/211 [1:28:13<44:16, 39.06s/batch, loss=30.930552]Training:  68%|██████▊   | 144/211 [1:28:13<31:36, 28.30s/batch, loss=30.930552]Training:  68%|██████▊   | 144/211 [1:28:44<31:36, 28.30s/batch, loss=29.124874]Training:  69%|██████▊   | 145/211 [1:28:44<31:54, 29.00s/batch, loss=29.124874]Training:  69%|██████▊   | 145/211 [1:30:11<31:54, 29.00s/batch, loss=30.633223]Training:  69%|██████▉   | 146/211 [1:30:12<50:36, 46.72s/batch, loss=30.633223]Training:  69%|██████▉   | 146/211 [1:30:26<50:36, 46.72s/batch, loss=28.711803]Training:  70%|██████▉   | 147/211 [1:30:26<39:15, 36.81s/batch, loss=28.711803]Training:  70%|██████▉   | 147/211 [1:30:29<39:15, 36.81s/batch, loss=29.251215]Training:  70%|███████   | 148/211 [1:30:29<28:00, 26.67s/batch, loss=29.251215]Training:  70%|███████   | 148/211 [1:30:55<28:00, 26.67s/batch, loss=28.737858]Training:  71%|███████   | 149/211 [1:30:55<27:23, 26.51s/batch, loss=28.737858]Training:  71%|███████   | 149/211 [1:32:28<27:23, 26.51s/batch, loss=29.199659]Training:  71%|███████   | 150/211 [1:32:28<47:25, 46.65s/batch, loss=29.199659]Training:  71%|███████   | 150/211 [1:32:53<47:25, 46.65s/batch, loss=28.772118]Training:  72%|███████▏  | 151/211 [1:32:53<39:55, 39.92s/batch, loss=28.772118]Training:  72%|███████▏  | 151/211 [1:32:56<39:55, 39.92s/batch, loss=31.652052]Training:  72%|███████▏  | 152/211 [1:32:56<28:23, 28.86s/batch, loss=31.652052]Training:  72%|███████▏  | 152/211 [1:33:01<28:23, 28.86s/batch, loss=27.758572]Training:  73%|███████▎  | 153/211 [1:33:01<20:56, 21.67s/batch, loss=27.758572]Training:  73%|███████▎  | 153/211 [1:35:00<20:56, 21.67s/batch, loss=29.409021]Training:  73%|███████▎  | 154/211 [1:35:00<48:33, 51.11s/batch, loss=29.409021]Training:  73%|███████▎  | 154/211 [1:35:36<48:33, 51.11s/batch, loss=30.332119]Training:  73%|███████▎  | 155/211 [1:35:36<43:29, 46.59s/batch, loss=30.332119]Training:  73%|███████▎  | 155/211 [1:35:40<43:29, 46.59s/batch, loss=28.894882]Training:  74%|███████▍  | 156/211 [1:35:40<30:44, 33.54s/batch, loss=28.894882]Training:  74%|███████▍  | 156/211 [1:35:43<30:44, 33.54s/batch, loss=29.717018]Training:  74%|███████▍  | 157/211 [1:35:43<21:57, 24.40s/batch, loss=29.717018]Training:  74%|███████▍  | 157/211 [1:37:28<21:57, 24.40s/batch, loss=27.639168]Training:  75%|███████▍  | 158/211 [1:37:28<42:56, 48.62s/batch, loss=27.639168]Training:  75%|███████▍  | 158/211 [1:38:00<42:56, 48.62s/batch, loss=29.172104]Training:  75%|███████▌  | 159/211 [1:38:00<37:55, 43.77s/batch, loss=29.172104]Training:  75%|███████▌  | 159/211 [1:38:03<37:55, 43.77s/batch, loss=28.456078]Training:  76%|███████▌  | 160/211 [1:38:03<26:48, 31.54s/batch, loss=28.456078]Training:  76%|███████▌  | 160/211 [1:38:11<26:48, 31.54s/batch, loss=28.902327]Training:  76%|███████▋  | 161/211 [1:38:11<20:21, 24.44s/batch, loss=28.902327]Training:  76%|███████▋  | 161/211 [1:40:01<20:21, 24.44s/batch, loss=27.928885]Training:  77%|███████▋  | 162/211 [1:40:01<40:52, 50.05s/batch, loss=27.928885]Training:  77%|███████▋  | 162/211 [1:40:33<40:52, 50.05s/batch, loss=29.775709]Training:  77%|███████▋  | 163/211 [1:40:33<35:48, 44.76s/batch, loss=29.775709]Training:  77%|███████▋  | 163/211 [1:40:36<35:48, 44.76s/batch, loss=28.215122]Training:  78%|███████▊  | 164/211 [1:40:36<25:14, 32.23s/batch, loss=28.215122]Training:  78%|███████▊  | 164/211 [1:40:47<25:14, 32.23s/batch, loss=29.560215]Training:  78%|███████▊  | 165/211 [1:40:47<19:43, 25.72s/batch, loss=29.560215]Training:  78%|███████▊  | 165/211 [1:42:21<19:43, 25.72s/batch, loss=29.531864]Training:  79%|███████▊  | 166/211 [1:42:22<34:52, 46.51s/batch, loss=29.531864]Training:  79%|███████▊  | 166/211 [1:42:54<34:52, 46.51s/batch, loss=26.391155]Training:  79%|███████▉  | 167/211 [1:42:54<30:52, 42.10s/batch, loss=26.391155]Training:  79%|███████▉  | 167/211 [1:42:57<30:52, 42.10s/batch, loss=26.487572]Training:  80%|███████▉  | 168/211 [1:42:57<21:46, 30.38s/batch, loss=26.487572]Training:  80%|███████▉  | 168/211 [1:43:12<21:46, 30.38s/batch, loss=26.968233]Training:  80%|████████  | 169/211 [1:43:12<18:08, 25.91s/batch, loss=26.968233]Training:  80%|████████  | 169/211 [1:44:46<18:08, 25.91s/batch, loss=26.327583]Training:  81%|████████  | 170/211 [1:44:47<31:45, 46.47s/batch, loss=26.327583]Training:  81%|████████  | 170/211 [1:45:03<31:45, 46.47s/batch, loss=27.506712]Training:  81%|████████  | 171/211 [1:45:03<24:55, 37.38s/batch, loss=27.506712]Training:  81%|████████  | 171/211 [1:45:06<24:55, 37.38s/batch, loss=28.202503]Training:  82%|████████▏ | 172/211 [1:45:06<17:35, 27.07s/batch, loss=28.202503]Training:  82%|████████▏ | 172/211 [1:45:28<17:35, 27.07s/batch, loss=28.997286]Training:  82%|████████▏ | 173/211 [1:45:28<16:08, 25.49s/batch, loss=28.997286]Training:  82%|████████▏ | 173/211 [1:47:07<16:08, 25.49s/batch, loss=28.667715]Training:  82%|████████▏ | 174/211 [1:47:07<29:27, 47.78s/batch, loss=28.667715]Training:  82%|████████▏ | 174/211 [1:47:36<29:27, 47.78s/batch, loss=27.418415]Training:  83%|████████▎ | 175/211 [1:47:36<25:09, 41.92s/batch, loss=27.418415]Training:  83%|████████▎ | 175/211 [1:47:39<25:09, 41.92s/batch, loss=29.389364]Training:  83%|████████▎ | 176/211 [1:47:39<17:40, 30.30s/batch, loss=29.389364]Training:  83%|████████▎ | 176/211 [1:47:51<17:40, 30.30s/batch, loss=26.102230]Training:  84%|████████▍ | 177/211 [1:47:51<14:09, 24.98s/batch, loss=26.102230]Training:  84%|████████▍ | 177/211 [1:49:33<14:09, 24.98s/batch, loss=26.432425]Training:  84%|████████▍ | 178/211 [1:49:33<26:26, 48.06s/batch, loss=26.432425]Training:  84%|████████▍ | 178/211 [1:50:02<26:26, 48.06s/batch, loss=27.050896]Training:  85%|████████▍ | 179/211 [1:50:02<22:31, 42.24s/batch, loss=27.050896]Training:  85%|████████▍ | 179/211 [1:50:05<22:31, 42.24s/batch, loss=25.862312]Training:  85%|████████▌ | 180/211 [1:50:05<15:46, 30.53s/batch, loss=25.862312]Training:  85%|████████▌ | 180/211 [1:50:25<15:46, 30.53s/batch, loss=28.344227]Training:  86%|████████▌ | 181/211 [1:50:25<13:38, 27.29s/batch, loss=28.344227]Training:  86%|████████▌ | 181/211 [1:51:53<13:38, 27.29s/batch, loss=25.954750]Training:  86%|████████▋ | 182/211 [1:51:53<22:04, 45.68s/batch, loss=25.954750]Training:  86%|████████▋ | 182/211 [1:52:22<22:04, 45.68s/batch, loss=26.348454]Training:  87%|████████▋ | 183/211 [1:52:22<18:55, 40.56s/batch, loss=26.348454]Training:  87%|████████▋ | 183/211 [1:52:25<18:55, 40.56s/batch, loss=26.854376]Training:  87%|████████▋ | 184/211 [1:52:25<13:11, 29.30s/batch, loss=26.854376]Training:  87%|████████▋ | 184/211 [1:52:57<13:11, 29.30s/batch, loss=27.216593]Training:  88%|████████▊ | 185/211 [1:52:57<13:05, 30.22s/batch, loss=27.216593]Training:  88%|████████▊ | 185/211 [1:54:30<13:05, 30.22s/batch, loss=25.244741]Training:  88%|████████▊ | 186/211 [1:54:31<20:26, 49.07s/batch, loss=25.244741]Training:  88%|████████▊ | 186/211 [1:54:44<20:26, 49.07s/batch, loss=25.397829]Training:  89%|████████▊ | 187/211 [1:54:44<15:24, 38.50s/batch, loss=25.397829]Training:  89%|████████▊ | 187/211 [1:54:47<15:24, 38.50s/batch, loss=26.380676]Training:  89%|████████▉ | 188/211 [1:54:47<10:40, 27.86s/batch, loss=26.380676]Training:  89%|████████▉ | 188/211 [1:55:33<10:40, 27.86s/batch, loss=24.848291]Training:  90%|████████▉ | 189/211 [1:55:33<12:11, 33.23s/batch, loss=24.848291]Training:  90%|████████▉ | 189/211 [1:56:59<12:11, 33.23s/batch, loss=28.565046]Training:  90%|█████████ | 190/211 [1:57:00<17:12, 49.19s/batch, loss=28.565046]Training:  90%|█████████ | 190/211 [1:57:10<17:12, 49.19s/batch, loss=24.822004]Training:  91%|█████████ | 191/211 [1:57:10<12:33, 37.66s/batch, loss=24.822004]Training:  91%|█████████ | 191/211 [1:57:13<12:33, 37.66s/batch, loss=27.063879]Training:  91%|█████████ | 192/211 [1:57:13<08:38, 27.28s/batch, loss=27.063879]Training:  91%|█████████ | 192/211 [1:57:53<08:38, 27.28s/batch, loss=26.149588]Training:  91%|█████████▏| 193/211 [1:57:53<09:16, 30.92s/batch, loss=26.149588]Training:  91%|█████████▏| 193/211 [1:59:33<09:16, 30.92s/batch, loss=26.759415]Training:  92%|█████████▏| 194/211 [1:59:33<14:37, 51.62s/batch, loss=26.759415]Training:  92%|█████████▏| 194/211 [1:59:36<14:37, 51.62s/batch, loss=26.322113]Training:  92%|█████████▏| 195/211 [1:59:36<09:53, 37.09s/batch, loss=26.322113]Training:  92%|█████████▏| 195/211 [1:59:39<09:53, 37.09s/batch, loss=25.414265]Training:  93%|█████████▎| 196/211 [1:59:39<06:43, 26.89s/batch, loss=25.414265]Training:  93%|█████████▎| 196/211 [2:00:25<06:43, 26.89s/batch, loss=26.450785]Training:  93%|█████████▎| 197/211 [2:00:25<07:38, 32.75s/batch, loss=26.450785]Training:  93%|█████████▎| 197/211 [2:01:46<07:38, 32.75s/batch, loss=26.309978]Training:  94%|█████████▍| 198/211 [2:01:46<10:11, 47.07s/batch, loss=26.309978]Training:  94%|█████████▍| 198/211 [2:01:49<10:11, 47.07s/batch, loss=24.810837]Training:  94%|█████████▍| 199/211 [2:01:49<06:46, 33.89s/batch, loss=24.810837]Training:  94%|█████████▍| 199/211 [2:01:52<06:46, 33.89s/batch, loss=26.872288]Training:  95%|█████████▍| 200/211 [2:01:52<04:31, 24.67s/batch, loss=26.872288]Training:  95%|█████████▍| 200/211 [2:03:00<04:31, 24.67s/batch, loss=26.380442]Training:  95%|█████████▌| 201/211 [2:03:00<06:16, 37.70s/batch, loss=26.380442]Training:  95%|█████████▌| 201/211 [2:04:04<06:16, 37.70s/batch, loss=25.399786]Training:  96%|█████████▌| 202/211 [2:04:04<06:48, 45.36s/batch, loss=25.399786]Training:  96%|█████████▌| 202/211 [2:04:10<06:48, 45.36s/batch, loss=26.217733]Training:  96%|█████████▌| 203/211 [2:04:10<04:28, 33.57s/batch, loss=26.217733]Training:  96%|█████████▌| 203/211 [2:04:13<04:28, 33.57s/batch, loss=24.061350]Training:  97%|█████████▋| 204/211 [2:04:13<02:50, 24.42s/batch, loss=24.061350]Training:  97%|█████████▋| 204/211 [2:05:29<02:50, 24.42s/batch, loss=28.730822]Training:  97%|█████████▋| 205/211 [2:05:29<04:00, 40.09s/batch, loss=28.730822]Training:  97%|█████████▋| 205/211 [2:06:11<04:00, 40.09s/batch, loss=26.886871]Training:  98%|█████████▊| 206/211 [2:06:11<03:22, 40.54s/batch, loss=26.886871]Training:  98%|█████████▊| 206/211 [2:06:23<03:22, 40.54s/batch, loss=26.393738]Training:  98%|█████████▊| 207/211 [2:06:23<02:07, 31.96s/batch, loss=26.393738]Training:  98%|█████████▊| 207/211 [2:06:26<02:07, 31.96s/batch, loss=26.146126]Training:  99%|█████████▊| 208/211 [2:06:26<01:09, 23.30s/batch, loss=26.146126]Training:  99%|█████████▊| 208/211 [2:07:12<01:09, 23.30s/batch, loss=26.176088]Training:  99%|█████████▉| 209/211 [2:07:12<01:00, 30.12s/batch, loss=26.176088]Training:  99%|█████████▉| 209/211 [2:07:27<01:00, 30.12s/batch, loss=25.311531]Training: 100%|█████████▉| 210/211 [2:07:27<00:25, 25.63s/batch, loss=25.311531]Training: 100%|█████████▉| 210/211 [2:07:28<00:25, 25.63s/batch, loss=25.259384]Training: 100%|██████████| 211/211 [2:07:28<00:00, 18.15s/batch, loss=25.259384]Training: 100%|██████████| 211/211 [2:07:28<00:00, 36.25s/batch, loss=25.259384]
Epoch 2, Train Loss: 34.0957, Val Loss: 24.9544
Training:   0%|          | 0/211 [00:00<?, ?batch/s]Training:   0%|          | 0/211 [02:04<?, ?batch/s, loss=26.681097]Training:   0%|          | 1/211 [02:05<7:17:42, 125.06s/batch, loss=26.681097]Training:   0%|          | 1/211 [02:12<7:17:42, 125.06s/batch, loss=24.763737]Training:   1%|          | 2/211 [02:12<3:14:50, 55.93s/batch, loss=24.763737] Training:   1%|          | 2/211 [02:15<3:14:50, 55.93s/batch, loss=25.627045]Training:   1%|▏         | 3/211 [02:15<1:50:16, 31.81s/batch, loss=25.627045]Training:   1%|▏         | 3/211 [02:18<1:50:16, 31.81s/batch, loss=24.319664]Training:   2%|▏         | 4/211 [02:18<1:10:34, 20.45s/batch, loss=24.319664]Training:   2%|▏         | 4/211 [04:15<1:10:34, 20.45s/batch, loss=23.824320]Training:   2%|▏         | 5/211 [04:15<3:09:48, 55.28s/batch, loss=23.824320]Training:   2%|▏         | 5/211 [04:34<3:09:48, 55.28s/batch, loss=26.179466]Training:   3%|▎         | 6/211 [04:34<2:26:50, 42.98s/batch, loss=26.179466]Training:   3%|▎         | 6/211 [04:37<2:26:50, 42.98s/batch, loss=24.866045]Training:   3%|▎         | 7/211 [04:37<1:41:41, 29.91s/batch, loss=24.866045]Training:   3%|▎         | 7/211 [04:40<1:41:41, 29.91s/batch, loss=25.893242]Training:   4%|▍         | 8/211 [04:40<1:12:17, 21.37s/batch, loss=25.893242]Training:   4%|▍         | 8/211 [06:25<1:12:17, 21.37s/batch, loss=24.315298]Training:   4%|▍         | 9/211 [06:25<2:39:32, 47.39s/batch, loss=24.315298]Training:   4%|▍         | 9/211 [06:55<2:39:32, 47.39s/batch, loss=25.574829]Training:   5%|▍         | 10/211 [06:55<2:20:16, 41.87s/batch, loss=25.574829]Training:   5%|▍         | 10/211 [06:58<2:20:16, 41.87s/batch, loss=24.748642]Training:   5%|▌         | 11/211 [06:58<1:40:09, 30.05s/batch, loss=24.748642]Training:   5%|▌         | 11/211 [07:01<1:40:09, 30.05s/batch, loss=23.343327]Training:   6%|▌         | 12/211 [07:01<1:12:28, 21.85s/batch, loss=23.343327]Training:   6%|▌         | 12/211 [08:39<1:12:28, 21.85s/batch, loss=24.217588]Training:   6%|▌         | 13/211 [08:39<2:28:40, 45.05s/batch, loss=24.217588]Training:   6%|▌         | 13/211 [09:19<2:28:40, 45.05s/batch, loss=27.609442]Training:   7%|▋         | 14/211 [09:19<2:22:52, 43.52s/batch, loss=27.609442]Training:   7%|▋         | 14/211 [09:22<2:22:52, 43.52s/batch, loss=22.198978]Training:   7%|▋         | 15/211 [09:22<1:42:21, 31.33s/batch, loss=22.198978]Training:   7%|▋         | 15/211 [09:26<1:42:21, 31.33s/batch, loss=23.206293]Training:   8%|▊         | 16/211 [09:26<1:14:13, 22.84s/batch, loss=23.206293]Training:   8%|▊         | 16/211 [10:55<1:14:13, 22.84s/batch, loss=23.421837]Training:   8%|▊         | 17/211 [10:56<2:19:33, 43.16s/batch, loss=23.421837]Training:   8%|▊         | 17/211 [11:35<2:19:33, 43.16s/batch, loss=23.494476]Training:   9%|▊         | 18/211 [11:35<2:14:36, 41.85s/batch, loss=23.494476]Training:   9%|▊         | 18/211 [11:38<2:14:36, 41.85s/batch, loss=24.653793]Training:   9%|▉         | 19/211 [11:38<1:36:36, 30.19s/batch, loss=24.653793]Training:   9%|▉         | 19/211 [11:41<1:36:36, 30.19s/batch, loss=23.251347]Training:   9%|▉         | 20/211 [11:41<1:10:10, 22.05s/batch, loss=23.251347]Training:   9%|▉         | 20/211 [13:39<1:10:10, 22.05s/batch, loss=24.322603]Training:  10%|▉         | 21/211 [13:40<2:41:45, 51.08s/batch, loss=24.322603]Training:  10%|▉         | 21/211 [13:59<2:41:45, 51.08s/batch, loss=25.560305]Training:  10%|█         | 22/211 [13:59<2:10:39, 41.48s/batch, loss=25.560305]Training:  10%|█         | 22/211 [14:02<2:10:39, 41.48s/batch, loss=24.477903]Training:  11%|█         | 23/211 [14:02<1:33:54, 29.97s/batch, loss=24.477903]Training:  11%|█         | 23/211 [14:05<1:33:54, 29.97s/batch, loss=26.046654]Training:  11%|█▏        | 24/211 [14:05<1:08:17, 21.91s/batch, loss=26.046654]Training:  11%|█▏        | 24/211 [16:03<1:08:17, 21.91s/batch, loss=23.417091]Training:  12%|█▏        | 25/211 [16:04<2:38:41, 51.19s/batch, loss=23.417091]Training:  12%|█▏        | 25/211 [16:20<2:38:41, 51.19s/batch, loss=23.075970]Training:  12%|█▏        | 26/211 [16:20<2:04:29, 40.38s/batch, loss=23.075970]Training:  12%|█▏        | 26/211 [16:23<2:04:29, 40.38s/batch, loss=24.065805]Training:  13%|█▎        | 27/211 [16:23<1:29:34, 29.21s/batch, loss=24.065805]Training:  13%|█▎        | 27/211 [16:26<1:29:34, 29.21s/batch, loss=23.711391]Training:  13%|█▎        | 28/211 [16:26<1:05:13, 21.38s/batch, loss=23.711391]Training:  13%|█▎        | 28/211 [18:24<1:05:13, 21.38s/batch, loss=24.389915]Training:  14%|█▎        | 29/211 [18:25<2:33:35, 50.63s/batch, loss=24.389915]Training:  14%|█▎        | 29/211 [18:42<2:33:35, 50.63s/batch, loss=24.066563]Training:  14%|█▍        | 30/211 [18:42<2:02:28, 40.60s/batch, loss=24.066563]Training:  14%|█▍        | 30/211 [18:45<2:02:28, 40.60s/batch, loss=23.021118]Training:  15%|█▍        | 31/211 [18:45<1:28:00, 29.34s/batch, loss=23.021118]Training:  15%|█▍        | 31/211 [18:48<1:28:00, 29.34s/batch, loss=22.844301]Training:  15%|█▌        | 32/211 [18:48<1:03:59, 21.45s/batch, loss=22.844301]Training:  15%|█▌        | 32/211 [20:47<1:03:59, 21.45s/batch, loss=22.359045]Training:  16%|█▌        | 33/211 [20:48<2:31:27, 51.05s/batch, loss=22.359045]Training:  16%|█▌        | 33/211 [20:56<2:31:27, 51.05s/batch, loss=23.643728]Training:  16%|█▌        | 34/211 [20:56<1:52:03, 37.99s/batch, loss=23.643728]Training:  16%|█▌        | 34/211 [20:59<1:52:03, 37.99s/batch, loss=25.514858]Training:  17%|█▋        | 35/211 [20:59<1:20:46, 27.54s/batch, loss=25.514858]Training:  17%|█▋        | 35/211 [21:02<1:20:46, 27.54s/batch, loss=22.012386]Training:  17%|█▋        | 36/211 [21:02<58:55, 20.20s/batch, loss=22.012386]  Training:  17%|█▋        | 36/211 [23:10<58:55, 20.20s/batch, loss=21.904316]Training:  18%|█▊        | 37/211 [23:11<2:33:08, 52.81s/batch, loss=21.904316]Training:  18%|█▊        | 37/211 [23:17<2:33:08, 52.81s/batch, loss=21.817854]Training:  18%|█▊        | 38/211 [23:17<1:51:35, 38.70s/batch, loss=21.817854]Training:  18%|█▊        | 38/211 [23:20<1:51:35, 38.70s/batch, loss=22.287930]Training:  18%|█▊        | 39/211 [23:20<1:20:19, 28.02s/batch, loss=22.287930]Training:  18%|█▊        | 39/211 [23:23<1:20:19, 28.02s/batch, loss=23.716181]Training:  19%|█▉        | 40/211 [23:23<58:30, 20.53s/batch, loss=23.716181]  Training:  19%|█▉        | 40/211 [25:14<58:30, 20.53s/batch, loss=23.892998]Training:  19%|█▉        | 41/211 [25:14<2:15:21, 47.77s/batch, loss=23.892998]Training:  19%|█▉        | 41/211 [25:24<2:15:21, 47.77s/batch, loss=23.680645]Training:  20%|█▉        | 42/211 [25:24<1:42:17, 36.31s/batch, loss=23.680645]Training:  20%|█▉        | 42/211 [25:27<1:42:17, 36.31s/batch, loss=25.060381]Training:  20%|██        | 43/211 [25:27<1:13:45, 26.34s/batch, loss=25.060381]Training:  20%|██        | 43/211 [25:41<1:13:45, 26.34s/batch, loss=23.298859]Training:  21%|██        | 44/211 [25:41<1:03:19, 22.75s/batch, loss=23.298859]Training:  21%|██        | 44/211 [27:31<1:03:19, 22.75s/batch, loss=24.632723]Training:  21%|██▏       | 45/211 [27:31<2:15:36, 49.02s/batch, loss=24.632723]Training:  21%|██▏       | 45/211 [27:49<2:15:36, 49.02s/batch, loss=22.494085]Training:  22%|██▏       | 46/211 [27:49<1:49:06, 39.67s/batch, loss=22.494085]Training:  22%|██▏       | 46/211 [27:52<1:49:06, 39.67s/batch, loss=23.090628]Training:  22%|██▏       | 47/211 [27:52<1:18:27, 28.71s/batch, loss=23.090628]Training:  22%|██▏       | 47/211 [28:06<1:18:27, 28.71s/batch, loss=23.081882]Training:  23%|██▎       | 48/211 [28:06<1:05:28, 24.10s/batch, loss=23.081882]Training:  23%|██▎       | 48/211 [29:42<1:05:28, 24.10s/batch, loss=23.355104]Training:  23%|██▎       | 49/211 [29:42<2:03:44, 45.83s/batch, loss=23.355104]Training:  23%|██▎       | 49/211 [30:14<2:03:44, 45.83s/batch, loss=23.328194]Training:  24%|██▎       | 50/211 [30:14<1:51:45, 41.65s/batch, loss=23.328194]Training:  24%|██▎       | 50/211 [30:17<1:51:45, 41.65s/batch, loss=23.954079]Training:  24%|██▍       | 51/211 [30:17<1:20:11, 30.07s/batch, loss=23.954079]Training:  24%|██▍       | 51/211 [30:20<1:20:11, 30.07s/batch, loss=23.579258]Training:  25%|██▍       | 52/211 [30:20<58:19, 22.01s/batch, loss=23.579258]  Training:  25%|██▍       | 52/211 [32:10<58:19, 22.01s/batch, loss=21.327902]Training:  25%|██▌       | 53/211 [32:11<2:07:34, 48.45s/batch, loss=21.327902]Training:  25%|██▌       | 53/211 [32:57<2:07:34, 48.45s/batch, loss=23.782497]Training:  26%|██▌       | 54/211 [32:57<2:05:18, 47.89s/batch, loss=23.782497]Training:  26%|██▌       | 54/211 [33:00<2:05:18, 47.89s/batch, loss=20.901711]Training:  26%|██▌       | 55/211 [33:00<1:29:34, 34.45s/batch, loss=20.901711]Training:  26%|██▌       | 55/211 [33:03<1:29:34, 34.45s/batch, loss=23.388838]Training:  27%|██▋       | 56/211 [33:03<1:04:41, 25.04s/batch, loss=23.388838]Training:  27%|██▋       | 56/211 [34:27<1:04:41, 25.04s/batch, loss=21.437386]Training:  27%|██▋       | 57/211 [34:27<1:49:03, 42.49s/batch, loss=21.437386]Training:  27%|██▋       | 57/211 [35:23<1:49:03, 42.49s/batch, loss=20.962963]Training:  27%|██▋       | 58/211 [35:23<1:58:59, 46.66s/batch, loss=20.962963]Training:  27%|██▋       | 58/211 [35:26<1:58:59, 46.66s/batch, loss=22.893803]Training:  28%|██▊       | 59/211 [35:26<1:25:06, 33.60s/batch, loss=22.893803]Training:  28%|██▊       | 59/211 [35:29<1:25:06, 33.60s/batch, loss=21.765968]Training:  28%|██▊       | 60/211 [35:29<1:01:31, 24.45s/batch, loss=21.765968]Training:  28%|██▊       | 60/211 [36:54<1:01:31, 24.45s/batch, loss=22.817764]Training:  29%|██▉       | 61/211 [36:55<1:47:03, 42.82s/batch, loss=22.817764]Training:  29%|██▉       | 61/211 [37:49<1:47:03, 42.82s/batch, loss=23.181055]Training:  29%|██▉       | 62/211 [37:49<1:54:25, 46.07s/batch, loss=23.181055]Training:  29%|██▉       | 62/211 [37:52<1:54:25, 46.07s/batch, loss=22.535921]Training:  30%|██▉       | 63/211 [37:52<1:21:50, 33.18s/batch, loss=22.535921]Training:  30%|██▉       | 63/211 [37:55<1:21:50, 33.18s/batch, loss=23.466312]Training:  30%|███       | 64/211 [37:55<59:09, 24.15s/batch, loss=23.466312]  Training:  30%|███       | 64/211 [39:04<59:09, 24.15s/batch, loss=22.816725]Training:  31%|███       | 65/211 [39:04<1:32:02, 37.82s/batch, loss=22.816725]Training:  31%|███       | 65/211 [40:24<1:32:02, 37.82s/batch, loss=23.794716]Training:  31%|███▏      | 66/211 [40:24<2:01:24, 50.24s/batch, loss=23.794716]Training:  31%|███▏      | 66/211 [40:27<2:01:24, 50.24s/batch, loss=21.134066]Training:  32%|███▏      | 67/211 [40:27<1:26:39, 36.11s/batch, loss=21.134066]Training:  32%|███▏      | 67/211 [40:30<1:26:39, 36.11s/batch, loss=22.136538]Training:  32%|███▏      | 68/211 [40:30<1:02:24, 26.19s/batch, loss=22.136538]Training:  32%|███▏      | 68/211 [41:35<1:02:24, 26.19s/batch, loss=22.120527]Training:  33%|███▎      | 69/211 [41:35<1:29:44, 37.92s/batch, loss=22.120527]Training:  33%|███▎      | 69/211 [42:54<1:29:44, 37.92s/batch, loss=22.574703]Training:  33%|███▎      | 70/211 [42:54<1:58:20, 50.36s/batch, loss=22.574703]Training:  33%|███▎      | 70/211 [42:58<1:58:20, 50.36s/batch, loss=20.397861]Training:  34%|███▎      | 71/211 [42:58<1:24:26, 36.19s/batch, loss=20.397861]Training:  34%|███▎      | 71/211 [43:01<1:24:26, 36.19s/batch, loss=21.616617]Training:  34%|███▍      | 72/211 [43:01<1:00:49, 26.26s/batch, loss=21.616617]Training:  34%|███▍      | 72/211 [43:55<1:00:49, 26.26s/batch, loss=22.249792]Training:  35%|███▍      | 73/211 [43:56<1:20:43, 35.10s/batch, loss=22.249792]Training:  35%|███▍      | 73/211 [45:24<1:20:43, 35.10s/batch, loss=21.122261]Training:  35%|███▌      | 74/211 [45:25<1:56:39, 51.09s/batch, loss=21.122261]Training:  35%|███▌      | 74/211 [45:28<1:56:39, 51.09s/batch, loss=21.335329]Training:  36%|███▌      | 75/211 [45:28<1:23:11, 36.70s/batch, loss=21.335329]Training:  36%|███▌      | 75/211 [45:31<1:23:11, 36.70s/batch, loss=21.805792]Training:  36%|███▌      | 76/211 [45:31<59:54, 26.62s/batch, loss=21.805792]  Training:  36%|███▌      | 76/211 [46:16<59:54, 26.62s/batch, loss=20.040308]Training:  36%|███▋      | 77/211 [46:16<1:11:39, 32.09s/batch, loss=20.040308]Training:  36%|███▋      | 77/211 [47:31<1:11:39, 32.09s/batch, loss=22.101282]Training:  37%|███▋      | 78/211 [47:32<1:40:07, 45.17s/batch, loss=22.101282]Training:  37%|███▋      | 78/211 [47:35<1:40:07, 45.17s/batch, loss=22.305283]Training:  37%|███▋      | 79/211 [47:35<1:11:35, 32.54s/batch, loss=22.305283]Training:  37%|███▋      | 79/211 [47:38<1:11:35, 32.54s/batch, loss=21.404598]Training:  38%|███▊      | 80/211 [47:38<51:47, 23.72s/batch, loss=21.404598]  Training:  38%|███▊      | 80/211 [48:32<51:47, 23.72s/batch, loss=22.393427]Training:  38%|███▊      | 81/211 [48:32<1:11:25, 32.96s/batch, loss=22.393427]Training:  38%|███▊      | 81/211 [49:55<1:11:25, 32.96s/batch, loss=21.123556]Training:  39%|███▉      | 82/211 [49:56<1:43:21, 48.07s/batch, loss=21.123556]Training:  39%|███▉      | 82/211 [49:59<1:43:21, 48.07s/batch, loss=20.622986]Training:  39%|███▉      | 83/211 [49:59<1:13:44, 34.56s/batch, loss=20.622986]Training:  39%|███▉      | 83/211 [50:02<1:13:44, 34.56s/batch, loss=21.515249]Training:  40%|███▉      | 84/211 [50:02<53:12, 25.14s/batch, loss=21.515249]  Training:  40%|███▉      | 84/211 [50:59<53:12, 25.14s/batch, loss=21.982651]Training:  40%|████      | 85/211 [51:00<1:13:38, 35.07s/batch, loss=21.982651]Training:  40%|████      | 85/211 [52:43<1:13:38, 35.07s/batch, loss=21.716614]Training:  41%|████      | 86/211 [52:43<1:55:15, 55.32s/batch, loss=21.716614]Training:  41%|████      | 86/211 [52:46<1:55:15, 55.32s/batch, loss=21.201937]Training:  41%|████      | 87/211 [52:46<1:21:56, 39.65s/batch, loss=21.201937]Training:  41%|████      | 87/211 [52:49<1:21:56, 39.65s/batch, loss=20.696220]Training:  42%|████▏     | 88/211 [52:49<58:48, 28.69s/batch, loss=20.696220]  Training:  42%|████▏     | 88/211 [53:15<58:48, 28.69s/batch, loss=20.676268]Training:  42%|████▏     | 89/211 [53:15<56:57, 28.01s/batch, loss=20.676268]Training:  42%|████▏     | 89/211 [55:03<56:57, 28.01s/batch, loss=22.265324]Training:  43%|████▎     | 90/211 [55:03<1:44:46, 51.96s/batch, loss=22.265324]Training:  43%|████▎     | 90/211 [55:06<1:44:46, 51.96s/batch, loss=21.184752]Training:  43%|████▎     | 91/211 [55:06<1:14:36, 37.30s/batch, loss=21.184752]Training:  43%|████▎     | 91/211 [55:09<1:14:36, 37.30s/batch, loss=20.863768]Training:  44%|████▎     | 92/211 [55:09<53:39, 27.05s/batch, loss=20.863768]  Training:  44%|████▎     | 92/211 [55:39<53:39, 27.05s/batch, loss=20.912441]Training:  44%|████▍     | 93/211 [55:39<54:56, 27.94s/batch, loss=20.912441]Training:  44%|████▍     | 93/211 [57:25<54:56, 27.94s/batch, loss=20.249563]Training:  45%|████▍     | 94/211 [57:26<1:40:24, 51.49s/batch, loss=20.249563]Training:  45%|████▍     | 94/211 [57:29<1:40:24, 51.49s/batch, loss=19.851112]Training:  45%|████▌     | 95/211 [57:29<1:11:30, 36.99s/batch, loss=19.851112]Training:  45%|████▌     | 95/211 [57:32<1:11:30, 36.99s/batch, loss=21.539896]Training:  45%|████▌     | 96/211 [57:32<51:23, 26.81s/batch, loss=21.539896]  Training:  45%|████▌     | 96/211 [57:47<51:23, 26.81s/batch, loss=20.352871]Training:  46%|████▌     | 97/211 [57:47<44:26, 23.39s/batch, loss=20.352871]Training:  46%|████▌     | 97/211 [59:39<44:26, 23.39s/batch, loss=20.521271]Training:  46%|████▋     | 98/211 [59:39<1:33:56, 49.88s/batch, loss=20.521271]Training:  46%|████▋     | 98/211 [59:42<1:33:56, 49.88s/batch, loss=21.215313]Training:  47%|████▋     | 99/211 [59:42<1:06:55, 35.86s/batch, loss=21.215313]Training:  47%|████▋     | 99/211 [59:45<1:06:55, 35.86s/batch, loss=20.806227]Training:  47%|████▋     | 100/211 [59:45<48:10, 26.04s/batch, loss=20.806227] Training:  47%|████▋     | 100/211 [1:00:11<48:10, 26.04s/batch, loss=20.853903]Training:  48%|████▊     | 101/211 [1:00:11<47:30, 25.91s/batch, loss=20.853903]Training:  48%|████▊     | 101/211 [1:01:47<47:30, 25.91s/batch, loss=20.651226]Training:  48%|████▊     | 102/211 [1:01:47<1:25:29, 47.06s/batch, loss=20.651226]Training:  48%|████▊     | 102/211 [1:01:51<1:25:29, 47.06s/batch, loss=21.788273]Training:  49%|████▉     | 103/211 [1:01:51<1:00:57, 33.87s/batch, loss=21.788273]Training:  49%|████▉     | 103/211 [1:01:54<1:00:57, 33.87s/batch, loss=20.123188]Training:  49%|████▉     | 104/211 [1:01:54<43:55, 24.63s/batch, loss=20.123188]  Training:  49%|████▉     | 104/211 [1:02:41<43:55, 24.63s/batch, loss=20.673300]Training:  50%|████▉     | 105/211 [1:02:42<56:15, 31.84s/batch, loss=20.673300]Training:  50%|████▉     | 105/211 [1:04:17<56:15, 31.84s/batch, loss=20.188440]Training:  50%|█████     | 106/211 [1:04:17<1:28:46, 50.73s/batch, loss=20.188440]Training:  50%|█████     | 106/211 [1:04:20<1:28:46, 50.73s/batch, loss=18.684814]Training:  51%|█████     | 107/211 [1:04:20<1:03:09, 36.44s/batch, loss=18.684814]Training:  51%|█████     | 107/211 [1:04:23<1:03:09, 36.44s/batch, loss=21.793583]Training:  51%|█████     | 108/211 [1:04:23<45:20, 26.42s/batch, loss=21.793583]  Training:  51%|█████     | 108/211 [1:04:54<45:20, 26.42s/batch, loss=20.528723]Training:  52%|█████▏    | 109/211 [1:04:54<47:23, 27.88s/batch, loss=20.528723]Training:  52%|█████▏    | 109/211 [1:06:33<47:23, 27.88s/batch, loss=19.647394]Training:  52%|█████▏    | 110/211 [1:06:34<1:23:00, 49.32s/batch, loss=19.647394]Training:  52%|█████▏    | 110/211 [1:06:37<1:23:00, 49.32s/batch, loss=20.242331]Training:  53%|█████▎    | 111/211 [1:06:37<59:03, 35.43s/batch, loss=20.242331]  Training:  53%|█████▎    | 111/211 [1:06:40<59:03, 35.43s/batch, loss=21.734108]Training:  53%|█████▎    | 112/211 [1:06:40<42:27, 25.74s/batch, loss=21.734108]Training:  53%|█████▎    | 112/211 [1:07:15<42:27, 25.74s/batch, loss=19.215616]Training:  54%|█████▎    | 113/211 [1:07:15<46:26, 28.44s/batch, loss=19.215616]Training:  54%|█████▎    | 113/211 [1:08:51<46:26, 28.44s/batch, loss=21.693853]Training:  54%|█████▍    | 114/211 [1:08:51<1:19:06, 48.93s/batch, loss=21.693853]Training:  54%|█████▍    | 114/211 [1:08:55<1:19:06, 48.93s/batch, loss=19.231310]Training:  55%|█████▍    | 115/211 [1:08:55<56:18, 35.20s/batch, loss=19.231310]  Training:  55%|█████▍    | 115/211 [1:08:58<56:18, 35.20s/batch, loss=21.864769]Training:  55%|█████▍    | 116/211 [1:08:58<40:30, 25.59s/batch, loss=21.864769]Training:  55%|█████▍    | 116/211 [1:09:32<40:30, 25.59s/batch, loss=21.211582]Training:  55%|█████▌    | 117/211 [1:09:32<44:17, 28.27s/batch, loss=21.211582]Training:  55%|█████▌    | 117/211 [1:11:06<44:17, 28.27s/batch, loss=19.350704]Training:  56%|█████▌    | 118/211 [1:11:06<1:14:10, 47.86s/batch, loss=19.350704]Training:  56%|█████▌    | 118/211 [1:11:09<1:14:10, 47.86s/batch, loss=21.015381]Training:  56%|█████▋    | 119/211 [1:11:09<52:47, 34.43s/batch, loss=21.015381]  Training:  56%|█████▋    | 119/211 [1:11:28<52:47, 34.43s/batch, loss=20.441404]Training:  57%|█████▋    | 120/211 [1:11:28<45:24, 29.94s/batch, loss=20.441404]Training:  57%|█████▋    | 120/211 [1:11:56<45:24, 29.94s/batch, loss=19.944864]Training:  57%|█████▋    | 121/211 [1:11:56<43:48, 29.21s/batch, loss=19.944864]Training:  57%|█████▋    | 121/211 [1:13:33<43:48, 29.21s/batch, loss=19.444469]Training:  58%|█████▊    | 122/211 [1:13:34<1:14:07, 49.97s/batch, loss=19.444469]Training:  58%|█████▊    | 122/211 [1:13:37<1:14:07, 49.97s/batch, loss=19.828606]Training:  58%|█████▊    | 123/211 [1:13:37<52:40, 35.91s/batch, loss=19.828606]  Training:  58%|█████▊    | 123/211 [1:13:49<52:40, 35.91s/batch, loss=21.159567]Training:  59%|█████▉    | 124/211 [1:13:49<41:24, 28.56s/batch, loss=21.159567]Training:  59%|█████▉    | 124/211 [1:14:32<41:24, 28.56s/batch, loss=21.241568]Training:  59%|█████▉    | 125/211 [1:14:32<47:06, 32.87s/batch, loss=21.241568]Training:  59%|█████▉    | 125/211 [1:15:57<47:06, 32.87s/batch, loss=20.319527]Training:  60%|█████▉    | 126/211 [1:15:58<1:09:20, 48.95s/batch, loss=20.319527]Training:  60%|█████▉    | 126/211 [1:16:01<1:09:20, 48.95s/batch, loss=18.766941]Training:  60%|██████    | 127/211 [1:16:01<49:15, 35.18s/batch, loss=18.766941]  Training:  60%|██████    | 127/211 [1:16:09<49:15, 35.18s/batch, loss=19.524475]Training:  61%|██████    | 128/211 [1:16:09<37:04, 26.81s/batch, loss=19.524475]Training:  61%|██████    | 128/211 [1:17:15<37:04, 26.81s/batch, loss=18.505459]Training:  61%|██████    | 129/211 [1:17:15<52:53, 38.70s/batch, loss=18.505459]Training:  61%|██████    | 129/211 [1:18:22<52:53, 38.70s/batch, loss=20.622999]Training:  62%|██████▏   | 130/211 [1:18:22<1:03:52, 47.31s/batch, loss=20.622999]Training:  62%|██████▏   | 130/211 [1:18:26<1:03:52, 47.31s/batch, loss=19.891518]Training:  62%|██████▏   | 131/211 [1:18:26<45:24, 34.06s/batch, loss=19.891518]  Training:  62%|██████▏   | 131/211 [1:18:29<45:24, 34.06s/batch, loss=19.588417]Training:  63%|██████▎   | 132/211 [1:18:29<32:35, 24.76s/batch, loss=19.588417]Training:  63%|██████▎   | 132/211 [1:19:33<32:35, 24.76s/batch, loss=20.515373]Training:  63%|██████▎   | 133/211 [1:19:34<47:52, 36.82s/batch, loss=20.515373]Training:  63%|██████▎   | 133/211 [1:20:40<47:52, 36.82s/batch, loss=20.426191]Training:  64%|██████▎   | 134/211 [1:20:41<58:59, 45.97s/batch, loss=20.426191]Training:  64%|██████▎   | 134/211 [1:20:44<58:59, 45.97s/batch, loss=18.983871]Training:  64%|██████▍   | 135/211 [1:20:44<41:54, 33.09s/batch, loss=18.983871]Training:  64%|██████▍   | 135/211 [1:20:47<41:54, 33.09s/batch, loss=20.121101]Training:  64%|██████▍   | 136/211 [1:20:47<30:06, 24.08s/batch, loss=20.121101]Training:  64%|██████▍   | 136/211 [1:22:00<30:06, 24.08s/batch, loss=19.446020]Training:  65%|██████▍   | 137/211 [1:22:00<47:50, 38.80s/batch, loss=19.446020]Training:  65%|██████▍   | 137/211 [1:22:59<47:50, 38.80s/batch, loss=20.267607]Training:  65%|██████▌   | 138/211 [1:22:59<54:27, 44.75s/batch, loss=20.267607]Training:  65%|██████▌   | 138/211 [1:23:02<54:27, 44.75s/batch, loss=20.082092]Training:  66%|██████▌   | 139/211 [1:23:02<38:41, 32.24s/batch, loss=20.082092]Training:  66%|██████▌   | 139/211 [1:23:13<38:41, 32.24s/batch, loss=19.860851]Training:  66%|██████▋   | 140/211 [1:23:13<30:45, 26.00s/batch, loss=19.860851]Training:  66%|██████▋   | 140/211 [1:24:29<30:45, 26.00s/batch, loss=20.473154]Training:  67%|██████▋   | 141/211 [1:24:29<47:43, 40.90s/batch, loss=20.473154]Training:  67%|██████▋   | 141/211 [1:25:23<47:43, 40.90s/batch, loss=18.371698]Training:  67%|██████▋   | 142/211 [1:25:23<51:42, 44.96s/batch, loss=18.371698]Training:  67%|██████▋   | 142/211 [1:25:26<51:42, 44.96s/batch, loss=19.535166]Training:  68%|██████▊   | 143/211 [1:25:26<36:43, 32.40s/batch, loss=19.535166]Training:  68%|██████▊   | 143/211 [1:25:58<36:43, 32.40s/batch, loss=19.338827]Training:  68%|██████▊   | 144/211 [1:25:58<36:02, 32.27s/batch, loss=19.338827]Training:  68%|██████▊   | 144/211 [1:26:58<36:02, 32.27s/batch, loss=19.057352]Training:  69%|██████▊   | 145/211 [1:26:58<44:38, 40.58s/batch, loss=19.057352]Training:  69%|██████▊   | 145/211 [1:27:37<44:38, 40.58s/batch, loss=19.489902]Training:  69%|██████▉   | 146/211 [1:27:37<43:14, 39.91s/batch, loss=19.489902]Training:  69%|██████▉   | 146/211 [1:27:40<43:14, 39.91s/batch, loss=19.441072]Training:  70%|██████▉   | 147/211 [1:27:40<30:46, 28.85s/batch, loss=19.441072]Training:  70%|██████▉   | 147/211 [1:28:44<30:46, 28.85s/batch, loss=17.876692]Training:  70%|███████   | 148/211 [1:28:44<41:27, 39.48s/batch, loss=17.876692]Training:  70%|███████   | 148/211 [1:29:35<41:27, 39.48s/batch, loss=19.623886]Training:  71%|███████   | 149/211 [1:29:35<44:18, 42.88s/batch, loss=19.623886]Training:  71%|███████   | 149/211 [1:29:56<44:18, 42.88s/batch, loss=19.248260]Training:  71%|███████   | 150/211 [1:29:56<37:01, 36.43s/batch, loss=19.248260]Training:  71%|███████   | 150/211 [1:29:59<37:01, 36.43s/batch, loss=19.746542]Training:  72%|███████▏  | 151/211 [1:29:59<26:24, 26.41s/batch, loss=19.746542]Training:  72%|███████▏  | 151/211 [1:31:24<26:24, 26.41s/batch, loss=19.020992]Training:  72%|███████▏  | 152/211 [1:31:25<43:28, 44.22s/batch, loss=19.020992]Training:  72%|███████▏  | 152/211 [1:32:16<43:28, 44.22s/batch, loss=18.756540]Training:  73%|███████▎  | 153/211 [1:32:16<44:36, 46.15s/batch, loss=18.756540]Training:  73%|███████▎  | 153/211 [1:32:29<44:36, 46.15s/batch, loss=19.335945]Training:  73%|███████▎  | 154/211 [1:32:29<34:21, 36.16s/batch, loss=19.335945]Training:  73%|███████▎  | 154/211 [1:32:32<34:21, 36.16s/batch, loss=19.321823]Training:  73%|███████▎  | 155/211 [1:32:32<24:28, 26.22s/batch, loss=19.321823]Training:  73%|███████▎  | 155/211 [1:33:58<24:28, 26.22s/batch, loss=19.920361]Training:  74%|███████▍  | 156/211 [1:33:59<40:43, 44.42s/batch, loss=19.920361]Training:  74%|███████▍  | 156/211 [1:34:29<40:43, 44.42s/batch, loss=19.217524]Training:  74%|███████▍  | 157/211 [1:34:29<36:17, 40.33s/batch, loss=19.217524]Training:  74%|███████▍  | 157/211 [1:34:49<36:17, 40.33s/batch, loss=19.232695]Training:  75%|███████▍  | 158/211 [1:34:49<30:15, 34.25s/batch, loss=19.232695]Training:  75%|███████▍  | 158/211 [1:34:52<30:15, 34.25s/batch, loss=18.582184]Training:  75%|███████▌  | 159/211 [1:34:52<21:34, 24.90s/batch, loss=18.582184]Training:  75%|███████▌  | 159/211 [1:36:18<21:34, 24.90s/batch, loss=19.232586]Training:  76%|███████▌  | 160/211 [1:36:18<36:34, 43.04s/batch, loss=19.232586]Training:  76%|███████▌  | 160/211 [1:37:01<36:34, 43.04s/batch, loss=19.552526]Training:  76%|███████▋  | 161/211 [1:37:01<35:56, 43.13s/batch, loss=19.552526]Training:  76%|███████▋  | 161/211 [1:37:30<35:56, 43.13s/batch, loss=18.549376]Training:  77%|███████▋  | 162/211 [1:37:30<31:50, 38.98s/batch, loss=18.549376]Training:  77%|███████▋  | 162/211 [1:37:34<31:50, 38.98s/batch, loss=18.328959]Training:  77%|███████▋  | 163/211 [1:37:34<22:34, 28.22s/batch, loss=18.328959]Training:  77%|███████▋  | 163/211 [1:38:47<22:34, 28.22s/batch, loss=18.422892]Training:  78%|███████▊  | 164/211 [1:38:48<32:58, 42.10s/batch, loss=18.422892]Training:  78%|███████▊  | 164/211 [1:39:22<32:58, 42.10s/batch, loss=18.637760]Training:  78%|███████▊  | 165/211 [1:39:22<30:25, 39.69s/batch, loss=18.637760]Training:  78%|███████▊  | 165/211 [1:39:45<30:25, 39.69s/batch, loss=19.108477]Training:  79%|███████▊  | 166/211 [1:39:45<25:58, 34.63s/batch, loss=19.108477]Training:  79%|███████▊  | 166/211 [1:39:48<25:58, 34.63s/batch, loss=18.727884]Training:  79%|███████▉  | 167/211 [1:39:48<18:26, 25.16s/batch, loss=18.727884]Training:  79%|███████▉  | 167/211 [1:41:23<18:26, 25.16s/batch, loss=18.166256]Training:  80%|███████▉  | 168/211 [1:41:24<33:10, 46.29s/batch, loss=18.166256]Training:  80%|███████▉  | 168/211 [1:41:49<33:10, 46.29s/batch, loss=18.165531]Training:  80%|████████  | 169/211 [1:41:49<28:00, 40.01s/batch, loss=18.165531]Training:  80%|████████  | 169/211 [1:42:11<28:00, 40.01s/batch, loss=20.229141]Training:  81%|████████  | 170/211 [1:42:11<23:45, 34.77s/batch, loss=20.229141]Training:  81%|████████  | 170/211 [1:42:15<23:45, 34.77s/batch, loss=17.197737]Training:  81%|████████  | 171/211 [1:42:15<16:50, 25.26s/batch, loss=17.197737]Training:  81%|████████  | 171/211 [1:43:58<16:50, 25.26s/batch, loss=19.115961]Training:  82%|████████▏ | 172/211 [1:43:58<31:36, 48.64s/batch, loss=19.115961]Training:  82%|████████▏ | 172/211 [1:44:01<31:36, 48.64s/batch, loss=20.556871]Training:  82%|████████▏ | 173/211 [1:44:01<22:08, 34.97s/batch, loss=20.556871]Training:  82%|████████▏ | 173/211 [1:44:33<22:08, 34.97s/batch, loss=18.236492]Training:  82%|████████▏ | 174/211 [1:44:33<21:06, 34.22s/batch, loss=18.236492]Training:  82%|████████▏ | 174/211 [1:44:36<21:06, 34.22s/batch, loss=19.097372]Training:  83%|████████▎ | 175/211 [1:44:36<14:55, 24.89s/batch, loss=19.097372]Training:  83%|████████▎ | 175/211 [1:46:15<14:55, 24.89s/batch, loss=18.448015]Training:  83%|████████▎ | 176/211 [1:46:15<27:24, 46.98s/batch, loss=18.448015]Training:  83%|████████▎ | 176/211 [1:46:18<27:24, 46.98s/batch, loss=17.913673]Training:  84%|████████▍ | 177/211 [1:46:18<19:09, 33.80s/batch, loss=17.913673]Training:  84%|████████▍ | 177/211 [1:47:08<19:09, 33.80s/batch, loss=18.167910]Training:  84%|████████▍ | 178/211 [1:47:08<21:12, 38.57s/batch, loss=18.167910]Training:  84%|████████▍ | 178/211 [1:47:11<21:12, 38.57s/batch, loss=17.952322]Training:  85%|████████▍ | 179/211 [1:47:11<14:53, 27.92s/batch, loss=17.952322]Training:  85%|████████▍ | 179/211 [1:48:38<14:53, 27.92s/batch, loss=18.626186]Training:  85%|████████▌ | 180/211 [1:48:39<23:42, 45.88s/batch, loss=18.626186]Training:  85%|████████▌ | 180/211 [1:48:42<23:42, 45.88s/batch, loss=19.119215]Training:  86%|████████▌ | 181/211 [1:48:42<16:31, 33.06s/batch, loss=19.119215]Training:  86%|████████▌ | 181/211 [1:49:22<16:31, 33.06s/batch, loss=17.474285]Training:  86%|████████▋ | 182/211 [1:49:22<17:04, 35.33s/batch, loss=17.474285]Training:  86%|████████▋ | 182/211 [1:49:25<17:04, 35.33s/batch, loss=19.335924]Training:  87%|████████▋ | 183/211 [1:49:25<11:58, 25.65s/batch, loss=19.335924]Training:  87%|████████▋ | 183/211 [1:51:08<11:58, 25.65s/batch, loss=18.498497]Training:  87%|████████▋ | 184/211 [1:51:08<21:58, 48.82s/batch, loss=18.498497]Training:  87%|████████▋ | 184/211 [1:51:11<21:58, 48.82s/batch, loss=17.219959]Training:  88%|████████▊ | 185/211 [1:51:11<15:12, 35.10s/batch, loss=17.219959]Training:  88%|████████▊ | 185/211 [1:51:43<15:12, 35.10s/batch, loss=17.532600]Training:  88%|████████▊ | 186/211 [1:51:43<14:09, 33.99s/batch, loss=17.532600]Training:  88%|████████▊ | 186/211 [1:51:46<14:09, 33.99s/batch, loss=17.413118]Training:  89%|████████▊ | 187/211 [1:51:46<09:53, 24.73s/batch, loss=17.413118]Training:  89%|████████▊ | 187/211 [1:53:31<09:53, 24.73s/batch, loss=19.077070]Training:  89%|████████▉ | 188/211 [1:53:32<18:48, 49.06s/batch, loss=19.077070]Training:  89%|████████▉ | 188/211 [1:53:35<18:48, 49.06s/batch, loss=18.655827]Training:  90%|████████▉ | 189/211 [1:53:35<12:56, 35.28s/batch, loss=18.655827]Training:  90%|████████▉ | 189/211 [1:53:58<12:56, 35.28s/batch, loss=17.773407]Training:  90%|█████████ | 190/211 [1:53:58<11:01, 31.52s/batch, loss=17.773407]Training:  90%|█████████ | 190/211 [1:54:01<11:01, 31.52s/batch, loss=18.711586]Training:  91%|█████████ | 191/211 [1:54:01<07:40, 23.01s/batch, loss=18.711586]Training:  91%|█████████ | 191/211 [1:55:53<07:40, 23.01s/batch, loss=17.260645]Training:  91%|█████████ | 192/211 [1:55:53<15:47, 49.89s/batch, loss=17.260645]Training:  91%|█████████ | 192/211 [1:55:56<15:47, 49.89s/batch, loss=18.163986]Training:  91%|█████████▏| 193/211 [1:55:56<10:44, 35.83s/batch, loss=18.163986]Training:  91%|█████████▏| 193/211 [1:56:26<10:44, 35.83s/batch, loss=17.813782]Training:  92%|█████████▏| 194/211 [1:56:26<09:35, 33.84s/batch, loss=17.813782]Training:  92%|█████████▏| 194/211 [1:56:29<09:35, 33.84s/batch, loss=19.177357]Training:  92%|█████████▏| 195/211 [1:56:29<06:33, 24.62s/batch, loss=19.177357]Training:  92%|█████████▏| 195/211 [1:58:24<06:33, 24.62s/batch, loss=18.593605]Training:  93%|█████████▎| 196/211 [1:58:24<12:58, 51.88s/batch, loss=18.593605]Training:  93%|█████████▎| 196/211 [1:58:27<12:58, 51.88s/batch, loss=17.775747]Training:  93%|█████████▎| 197/211 [1:58:27<08:41, 37.28s/batch, loss=17.775747]Training:  93%|█████████▎| 197/211 [1:59:05<08:41, 37.28s/batch, loss=17.283632]Training:  94%|█████████▍| 198/211 [1:59:05<08:06, 37.45s/batch, loss=17.283632]Training:  94%|█████████▍| 198/211 [1:59:08<08:06, 37.45s/batch, loss=18.027472]Training:  94%|█████████▍| 199/211 [1:59:08<05:25, 27.15s/batch, loss=18.027472]Training:  94%|█████████▍| 199/211 [2:00:55<05:25, 27.15s/batch, loss=18.234394]Training:  95%|█████████▍| 200/211 [2:00:56<09:22, 51.16s/batch, loss=18.234394]Training:  95%|█████████▍| 200/211 [2:00:59<09:22, 51.16s/batch, loss=18.262096]Training:  95%|█████████▌| 201/211 [2:00:59<06:07, 36.74s/batch, loss=18.262096]Training:  95%|█████████▌| 201/211 [2:01:43<06:07, 36.74s/batch, loss=17.284086]Training:  96%|█████████▌| 202/211 [2:01:43<05:52, 39.14s/batch, loss=17.284086]Training:  96%|█████████▌| 202/211 [2:01:46<05:52, 39.14s/batch, loss=16.608814]Training:  96%|█████████▌| 203/211 [2:01:46<03:46, 28.32s/batch, loss=16.608814]Training:  96%|█████████▌| 203/211 [2:03:26<03:46, 28.32s/batch, loss=17.542423]Training:  97%|█████████▋| 204/211 [2:03:26<05:48, 49.84s/batch, loss=17.542423]Training:  97%|█████████▋| 204/211 [2:03:30<05:48, 49.84s/batch, loss=18.027283]Training:  97%|█████████▋| 205/211 [2:03:30<03:34, 35.82s/batch, loss=18.027283]Training:  97%|█████████▋| 205/211 [2:04:02<03:34, 35.82s/batch, loss=18.165213]Training:  98%|█████████▊| 206/211 [2:04:02<02:53, 34.71s/batch, loss=18.165213]Training:  98%|█████████▊| 206/211 [2:04:05<02:53, 34.71s/batch, loss=17.314907]Training:  98%|█████████▊| 207/211 [2:04:05<01:40, 25.21s/batch, loss=17.314907]Training:  98%|█████████▊| 207/211 [2:05:15<01:40, 25.21s/batch, loss=18.063601]Training:  99%|█████████▊| 208/211 [2:05:15<01:56, 38.77s/batch, loss=18.063601]Training:  99%|█████████▊| 208/211 [2:05:18<01:56, 38.77s/batch, loss=17.650938]Training:  99%|█████████▉| 209/211 [2:05:18<00:56, 28.07s/batch, loss=17.650938]Training:  99%|█████████▉| 209/211 [2:05:26<00:56, 28.07s/batch, loss=17.069725]Training: 100%|█████████▉| 210/211 [2:05:26<00:21, 21.84s/batch, loss=17.069725]Training: 100%|█████████▉| 210/211 [2:05:26<00:21, 21.84s/batch, loss=18.077532]Training: 100%|██████████| 211/211 [2:05:26<00:00, 15.50s/batch, loss=18.077532]Training: 100%|██████████| 211/211 [2:05:26<00:00, 35.67s/batch, loss=18.077532]
Epoch 3, Train Loss: 20.9188, Val Loss: 17.4862
Training:   0%|          | 0/211 [00:00<?, ?batch/s]Training:   0%|          | 0/211 [02:23<?, ?batch/s, loss=18.050829]Training:   0%|          | 1/211 [02:23<8:23:10, 143.76s/batch, loss=18.050829]Training:   0%|          | 1/211 [02:26<8:23:10, 143.76s/batch, loss=18.157171]Training:   1%|          | 2/211 [02:26<3:32:38, 61.05s/batch, loss=18.157171] Training:   1%|          | 2/211 [02:30<3:32:38, 61.05s/batch, loss=17.852690]Training:   1%|▏         | 3/211 [02:30<1:59:54, 34.59s/batch, loss=17.852690]Training:   1%|▏         | 3/211 [02:33<1:59:54, 34.59s/batch, loss=17.114162]Training:   2%|▏         | 4/211 [02:33<1:16:24, 22.15s/batch, loss=17.114162]Training:   2%|▏         | 4/211 [04:35<1:16:24, 22.15s/batch, loss=17.763695]Training:   2%|▏         | 5/211 [04:35<3:20:19, 58.35s/batch, loss=17.763695]Training:   2%|▏         | 5/211 [04:38<3:20:19, 58.35s/batch, loss=17.489180]Training:   3%|▎         | 6/211 [04:38<2:15:11, 39.57s/batch, loss=17.489180]Training:   3%|▎         | 6/211 [04:41<2:15:11, 39.57s/batch, loss=16.816736]Training:   3%|▎         | 7/211 [04:41<1:33:57, 27.63s/batch, loss=16.816736]Training:   3%|▎         | 7/211 [04:44<1:33:57, 27.63s/batch, loss=16.813192]Training:   4%|▍         | 8/211 [04:44<1:07:05, 19.83s/batch, loss=16.813192]Training:   4%|▍         | 8/211 [06:44<1:07:05, 19.83s/batch, loss=17.981077]Training:   4%|▍         | 9/211 [06:45<2:52:18, 51.18s/batch, loss=17.981077]Training:   4%|▍         | 9/211 [06:48<2:52:18, 51.18s/batch, loss=17.792498]Training:   5%|▍         | 10/211 [06:48<2:01:45, 36.34s/batch, loss=17.792498]Training:   5%|▍         | 10/211 [06:51<2:01:45, 36.34s/batch, loss=18.077316]Training:   5%|▌         | 11/211 [06:51<1:27:15, 26.18s/batch, loss=18.077316]Training:   5%|▌         | 11/211 [06:54<1:27:15, 26.18s/batch, loss=17.134233]Training:   6%|▌         | 12/211 [06:54<1:03:32, 19.16s/batch, loss=17.134233]Training:   6%|▌         | 12/211 [08:47<1:03:32, 19.16s/batch, loss=17.170452]Training:   6%|▌         | 13/211 [08:48<2:38:02, 47.89s/batch, loss=17.170452]Training:   6%|▌         | 13/211 [08:51<2:38:02, 47.89s/batch, loss=17.642916]Training:   7%|▋         | 14/211 [08:51<1:52:52, 34.38s/batch, loss=17.642916]Training:   7%|▋         | 14/211 [08:54<1:52:52, 34.38s/batch, loss=17.970442]Training:   7%|▋         | 15/211 [08:54<1:21:34, 24.97s/batch, loss=17.970442]Training:   7%|▋         | 15/211 [08:57<1:21:34, 24.97s/batch, loss=16.861395]Training:   8%|▊         | 16/211 [08:57<59:43, 18.38s/batch, loss=16.861395]  Training:   8%|▊         | 16/211 [11:07<59:43, 18.38s/batch, loss=17.012247]Training:   8%|▊         | 17/211 [11:07<2:47:59, 51.95s/batch, loss=17.012247]Training:   8%|▊         | 17/211 [11:10<2:47:59, 51.95s/batch, loss=17.519756]Training:   9%|▊         | 18/211 [11:10<1:59:55, 37.28s/batch, loss=17.519756]Training:   9%|▊         | 18/211 [11:14<1:59:55, 37.28s/batch, loss=17.231842]Training:   9%|▉         | 19/211 [11:14<1:26:26, 27.01s/batch, loss=17.231842]Training:   9%|▉         | 19/211 [11:17<1:26:26, 27.01s/batch, loss=17.519352]Training:   9%|▉         | 20/211 [11:17<1:03:13, 19.86s/batch, loss=17.519352]Training:   9%|▉         | 20/211 [13:19<1:03:13, 19.86s/batch, loss=16.533443]Training:  10%|▉         | 21/211 [13:19<2:40:32, 50.70s/batch, loss=16.533443]Training:  10%|▉         | 21/211 [13:22<2:40:32, 50.70s/batch, loss=16.448816]Training:  10%|█         | 22/211 [13:22<1:54:38, 36.39s/batch, loss=16.448816]Training:  10%|█         | 22/211 [13:38<1:54:38, 36.39s/batch, loss=17.907469]Training:  11%|█         | 23/211 [13:38<1:34:34, 30.18s/batch, loss=17.907469]Training:  11%|█         | 23/211 [13:41<1:34:34, 30.18s/batch, loss=17.054283]Training:  11%|█▏        | 24/211 [13:41<1:08:43, 22.05s/batch, loss=17.054283]Training:  11%|█▏        | 24/211 [15:39<1:08:43, 22.05s/batch, loss=16.622971]Training:  12%|█▏        | 25/211 [15:39<2:37:37, 50.85s/batch, loss=16.622971]Training:  12%|█▏        | 25/211 [15:42<2:37:37, 50.85s/batch, loss=16.799896]Training:  12%|█▏        | 26/211 [15:42<1:52:34, 36.51s/batch, loss=16.799896]Training:  12%|█▏        | 26/211 [15:56<1:52:34, 36.51s/batch, loss=17.336489]Training:  13%|█▎        | 27/211 [15:56<1:31:24, 29.81s/batch, loss=17.336489]Training:  13%|█▎        | 27/211 [15:59<1:31:24, 29.81s/batch, loss=17.176859]Training:  13%|█▎        | 28/211 [15:59<1:06:27, 21.79s/batch, loss=17.176859]Training:  13%|█▎        | 28/211 [17:57<1:06:27, 21.79s/batch, loss=18.008926]Training:  14%|█▎        | 29/211 [17:57<2:33:27, 50.59s/batch, loss=18.008926]Training:  14%|█▎        | 29/211 [18:00<2:33:27, 50.59s/batch, loss=18.076921]Training:  14%|█▍        | 30/211 [18:00<1:49:39, 36.35s/batch, loss=18.076921]Training:  14%|█▍        | 30/211 [18:19<1:49:39, 36.35s/batch, loss=17.947271]Training:  15%|█▍        | 31/211 [18:19<1:32:45, 30.92s/batch, loss=17.947271]Training:  15%|█▍        | 31/211 [18:22<1:32:45, 30.92s/batch, loss=17.404039]Training:  15%|█▌        | 32/211 [18:22<1:07:20, 22.57s/batch, loss=17.404039]Training:  15%|█▌        | 32/211 [20:18<1:07:20, 22.57s/batch, loss=17.072039]Training:  16%|█▌        | 33/211 [20:18<2:30:10, 50.62s/batch, loss=17.072039]Training:  16%|█▌        | 33/211 [20:21<2:30:10, 50.62s/batch, loss=16.534437]Training:  16%|█▌        | 34/211 [20:21<1:47:13, 36.35s/batch, loss=16.534437]Training:  16%|█▌        | 34/211 [20:45<1:47:13, 36.35s/batch, loss=16.885174]Training:  17%|█▋        | 35/211 [20:45<1:36:12, 32.80s/batch, loss=16.885174]Training:  17%|█▋        | 35/211 [20:49<1:36:12, 32.80s/batch, loss=16.868668]Training:  17%|█▋        | 36/211 [20:49<1:09:45, 23.92s/batch, loss=16.868668]Training:  17%|█▋        | 36/211 [22:47<1:09:45, 23.92s/batch, loss=16.540821]Training:  18%|█▊        | 37/211 [22:47<2:31:47, 52.34s/batch, loss=16.540821]Training:  18%|█▊        | 37/211 [22:50<2:31:47, 52.34s/batch, loss=17.328485]Training:  18%|█▊        | 38/211 [22:50<1:48:21, 37.58s/batch, loss=17.328485]Training:  18%|█▊        | 38/211 [23:08<1:48:21, 37.58s/batch, loss=16.189497]Training:  18%|█▊        | 39/211 [23:08<1:30:20, 31.52s/batch, loss=16.189497]Training:  18%|█▊        | 39/211 [23:11<1:30:20, 31.52s/batch, loss=16.275490]Training:  19%|█▉        | 40/211 [23:11<1:05:28, 22.97s/batch, loss=16.275490]Training:  19%|█▉        | 40/211 [24:57<1:05:28, 22.97s/batch, loss=16.607929]Training:  19%|█▉        | 41/211 [24:57<2:15:58, 47.99s/batch, loss=16.607929]Training:  19%|█▉        | 41/211 [25:00<2:15:58, 47.99s/batch, loss=17.000744]Training:  20%|█▉        | 42/211 [25:00<1:37:16, 34.53s/batch, loss=17.000744]Training:  20%|█▉        | 42/211 [25:38<1:37:16, 34.53s/batch, loss=16.660328]Training:  20%|██        | 43/211 [25:38<1:39:17, 35.46s/batch, loss=16.660328]Training:  20%|██        | 43/211 [25:41<1:39:17, 35.46s/batch, loss=16.638390]Training:  21%|██        | 44/211 [25:41<1:11:38, 25.74s/batch, loss=16.638390]Training:  21%|██        | 44/211 [27:22<1:11:38, 25.74s/batch, loss=16.644085]Training:  21%|██▏       | 45/211 [27:23<2:14:13, 48.51s/batch, loss=16.644085]Training:  21%|██▏       | 45/211 [27:33<2:14:13, 48.51s/batch, loss=16.481180]Training:  22%|██▏       | 46/211 [27:33<1:41:50, 37.03s/batch, loss=16.481180]Training:  22%|██▏       | 46/211 [27:57<1:41:50, 37.03s/batch, loss=16.633469]Training:  22%|██▏       | 47/211 [27:57<1:31:02, 33.31s/batch, loss=16.633469]Training:  22%|██▏       | 47/211 [28:01<1:31:02, 33.31s/batch, loss=16.871742]Training:  23%|██▎       | 48/211 [28:01<1:05:51, 24.24s/batch, loss=16.871742]Training:  23%|██▎       | 48/211 [29:34<1:05:51, 24.24s/batch, loss=16.471771]Training:  23%|██▎       | 49/211 [29:34<2:01:40, 45.06s/batch, loss=16.471771]Training:  23%|██▎       | 49/211 [29:56<2:01:40, 45.06s/batch, loss=16.599417]Training:  24%|██▎       | 50/211 [29:56<1:42:13, 38.09s/batch, loss=16.599417]Training:  24%|██▎       | 50/211 [30:28<1:42:13, 38.09s/batch, loss=17.291374]Training:  24%|██▍       | 51/211 [30:28<1:36:34, 36.21s/batch, loss=17.291374]Training:  24%|██▍       | 51/211 [30:31<1:36:34, 36.21s/batch, loss=16.643997]Training:  25%|██▍       | 52/211 [30:31<1:09:42, 26.31s/batch, loss=16.643997]Training:  25%|██▍       | 52/211 [31:52<1:09:42, 26.31s/batch, loss=17.456154]Training:  25%|██▌       | 53/211 [31:53<1:53:10, 42.98s/batch, loss=17.456154]Training:  25%|██▌       | 53/211 [32:13<1:53:10, 42.98s/batch, loss=15.784026]Training:  26%|██▌       | 54/211 [32:13<1:34:33, 36.13s/batch, loss=15.784026]Training:  26%|██▌       | 54/211 [32:44<1:34:33, 36.13s/batch, loss=15.968741]Training:  26%|██▌       | 55/211 [32:44<1:29:37, 34.47s/batch, loss=15.968741]Training:  26%|██▌       | 55/211 [32:47<1:29:37, 34.47s/batch, loss=15.886234]Training:  27%|██▋       | 56/211 [32:47<1:04:45, 25.07s/batch, loss=15.886234]Training:  27%|██▋       | 56/211 [34:26<1:04:45, 25.07s/batch, loss=16.121981]Training:  27%|██▋       | 57/211 [34:26<2:01:45, 47.44s/batch, loss=16.121981]Training:  27%|██▋       | 57/211 [34:47<2:01:45, 47.44s/batch, loss=16.371395]Training:  27%|██▋       | 58/211 [34:47<1:40:13, 39.31s/batch, loss=16.371395]Training:  27%|██▋       | 58/211 [35:10<1:40:13, 39.31s/batch, loss=16.202499]Training:  28%|██▊       | 59/211 [35:10<1:27:12, 34.43s/batch, loss=16.202499]Training:  28%|██▊       | 59/211 [35:13<1:27:12, 34.43s/batch, loss=15.494149]Training:  28%|██▊       | 60/211 [35:13<1:02:58, 25.02s/batch, loss=15.494149]Training:  28%|██▊       | 60/211 [36:49<1:02:58, 25.02s/batch, loss=17.189888]Training:  29%|██▉       | 61/211 [36:49<1:55:58, 46.39s/batch, loss=17.189888]Training:  29%|██▉       | 61/211 [37:20<1:55:58, 46.39s/batch, loss=15.600513]Training:  29%|██▉       | 62/211 [37:20<1:43:45, 41.78s/batch, loss=15.600513]Training:  29%|██▉       | 62/211 [37:30<1:43:45, 41.78s/batch, loss=16.444809]Training:  30%|██▉       | 63/211 [37:30<1:19:43, 32.32s/batch, loss=16.444809]Training:  30%|██▉       | 63/211 [37:34<1:19:43, 32.32s/batch, loss=15.694856]Training:  30%|███       | 64/211 [37:34<57:41, 23.55s/batch, loss=15.694856]  Training:  30%|███       | 64/211 [39:07<57:41, 23.55s/batch, loss=15.787007]Training:  31%|███       | 65/211 [39:08<1:49:09, 44.86s/batch, loss=15.787007]Training:  31%|███       | 65/211 [39:57<1:49:09, 44.86s/batch, loss=17.371914]Training:  31%|███▏      | 66/211 [39:57<1:51:15, 46.04s/batch, loss=17.371914]Training:  31%|███▏      | 66/211 [40:00<1:51:15, 46.04s/batch, loss=16.528008]Training:  32%|███▏      | 67/211 [40:00<1:19:37, 33.18s/batch, loss=16.528008]Training:  32%|███▏      | 67/211 [40:03<1:19:37, 33.18s/batch, loss=16.515795]Training:  32%|███▏      | 68/211 [40:03<57:32, 24.14s/batch, loss=16.515795]  Training:  32%|███▏      | 68/211 [41:30<57:32, 24.14s/batch, loss=16.059324]Training:  33%|███▎      | 69/211 [41:30<1:41:37, 42.94s/batch, loss=16.059324]Training:  33%|███▎      | 69/211 [42:21<1:41:37, 42.94s/batch, loss=16.376383]Training:  33%|███▎      | 70/211 [42:21<1:46:43, 45.42s/batch, loss=16.376383]Training:  33%|███▎      | 70/211 [42:24<1:46:43, 45.42s/batch, loss=15.756831]Training:  34%|███▎      | 71/211 [42:24<1:16:23, 32.74s/batch, loss=15.756831]Training:  34%|███▎      | 71/211 [42:27<1:16:23, 32.74s/batch, loss=16.763784]Training:  34%|███▍      | 72/211 [42:27<55:15, 23.85s/batch, loss=16.763784]  Training:  34%|███▍      | 72/211 [43:31<55:15, 23.85s/batch, loss=16.574003]Training:  35%|███▍      | 73/211 [43:31<1:22:26, 35.85s/batch, loss=16.574003]Training:  35%|███▍      | 73/211 [44:50<1:22:26, 35.85s/batch, loss=16.319403]Training:  35%|███▌      | 74/211 [44:51<1:51:50, 48.98s/batch, loss=16.319403]Training:  35%|███▌      | 74/211 [44:54<1:51:50, 48.98s/batch, loss=16.463041]Training:  36%|███▌      | 75/211 [44:54<1:19:50, 35.22s/batch, loss=16.463041]Training:  36%|███▌      | 75/211 [44:57<1:19:50, 35.22s/batch, loss=16.323288]Training:  36%|███▌      | 76/211 [44:57<57:32, 25.57s/batch, loss=16.323288]  Training:  36%|███▌      | 76/211 [45:44<57:32, 25.57s/batch, loss=15.824302]Training:  36%|███▋      | 77/211 [45:44<1:11:26, 31.99s/batch, loss=15.824302]Training:  36%|███▋      | 77/211 [47:12<1:11:26, 31.99s/batch, loss=16.447641]Training:  37%|███▋      | 78/211 [47:13<1:48:58, 49.16s/batch, loss=16.447641]Training:  37%|███▋      | 78/211 [47:16<1:48:58, 49.16s/batch, loss=16.588942]Training:  37%|███▋      | 79/211 [47:16<1:17:45, 35.34s/batch, loss=16.588942]Training:  37%|███▋      | 79/211 [47:19<1:17:45, 35.34s/batch, loss=16.597525]Training:  38%|███▊      | 80/211 [47:19<55:59, 25.65s/batch, loss=16.597525]  Training:  38%|███▊      | 80/211 [47:50<55:59, 25.65s/batch, loss=15.311431]Training:  38%|███▊      | 81/211 [47:50<59:08, 27.29s/batch, loss=15.311431]Training:  38%|███▊      | 81/211 [49:46<59:08, 27.29s/batch, loss=15.248755]Training:  39%|███▉      | 82/211 [49:47<1:55:59, 53.95s/batch, loss=15.248755]Training:  39%|███▉      | 82/211 [49:50<1:55:59, 53.95s/batch, loss=15.946157]Training:  39%|███▉      | 83/211 [49:50<1:22:33, 38.70s/batch, loss=15.946157]Training:  39%|███▉      | 83/211 [49:53<1:22:33, 38.70s/batch, loss=16.076788]Training:  40%|███▉      | 84/211 [49:53<59:19, 28.02s/batch, loss=16.076788]  Training:  40%|███▉      | 84/211 [50:06<59:19, 28.02s/batch, loss=15.761205]Training:  40%|████      | 85/211 [50:06<49:46, 23.70s/batch, loss=15.761205]Training:  40%|████      | 85/211 [52:18<49:46, 23.70s/batch, loss=15.212762]Training:  41%|████      | 86/211 [52:18<1:56:49, 56.08s/batch, loss=15.212762]Training:  41%|████      | 86/211 [52:21<1:56:49, 56.08s/batch, loss=15.794827]Training:  41%|████      | 87/211 [52:21<1:23:01, 40.18s/batch, loss=15.794827]Training:  41%|████      | 87/211 [52:24<1:23:01, 40.18s/batch, loss=16.266735]Training:  42%|████▏     | 88/211 [52:24<59:32, 29.04s/batch, loss=16.266735]  Training:  42%|████▏     | 88/211 [52:48<59:32, 29.04s/batch, loss=15.724885]Training:  42%|████▏     | 89/211 [52:48<55:35, 27.34s/batch, loss=15.724885]Training:  42%|████▏     | 89/211 [54:45<55:35, 27.34s/batch, loss=16.482597]Training:  43%|████▎     | 90/211 [54:45<1:49:50, 54.47s/batch, loss=16.482597]Training:  43%|████▎     | 90/211 [54:49<1:49:50, 54.47s/batch, loss=15.975217]Training:  43%|████▎     | 91/211 [54:49<1:18:10, 39.08s/batch, loss=15.975217]Training:  43%|████▎     | 91/211 [54:52<1:18:10, 39.08s/batch, loss=16.085096]Training:  44%|████▎     | 92/211 [54:52<56:05, 28.28s/batch, loss=16.085096]  Training:  44%|████▎     | 92/211 [55:11<56:05, 28.28s/batch, loss=15.315674]Training:  44%|████▍     | 93/211 [55:11<50:04, 25.47s/batch, loss=15.315674]Training:  44%|████▍     | 93/211 [57:04<50:04, 25.47s/batch, loss=15.775577]Training:  45%|████▍     | 94/211 [57:05<1:41:28, 52.04s/batch, loss=15.775577]Training:  45%|████▍     | 94/211 [57:08<1:41:28, 52.04s/batch, loss=15.792370]Training:  45%|████▌     | 95/211 [57:08<1:12:14, 37.36s/batch, loss=15.792370]Training:  45%|████▌     | 95/211 [57:11<1:12:14, 37.36s/batch, loss=16.025574]Training:  45%|████▌     | 96/211 [57:11<51:54, 27.09s/batch, loss=16.025574]  Training:  45%|████▌     | 96/211 [57:20<51:54, 27.09s/batch, loss=16.137451]Training:  46%|████▌     | 97/211 [57:20<41:10, 21.68s/batch, loss=16.137451]Training:  46%|████▌     | 97/211 [59:25<41:10, 21.68s/batch, loss=15.579090]Training:  46%|████▋     | 98/211 [59:25<1:39:33, 52.86s/batch, loss=15.579090]Training:  46%|████▋     | 98/211 [59:29<1:39:33, 52.86s/batch, loss=15.730687]Training:  47%|████▋     | 99/211 [59:29<1:10:50, 37.95s/batch, loss=15.730687]Training:  47%|████▋     | 99/211 [59:32<1:10:50, 37.95s/batch, loss=16.003956]Training:  47%|████▋     | 100/211 [59:32<50:54, 27.52s/batch, loss=16.003956] Training:  47%|████▋     | 100/211 [59:53<50:54, 27.52s/batch, loss=15.581043]Training:  48%|████▊     | 101/211 [59:53<46:53, 25.58s/batch, loss=15.581043]Training:  48%|████▊     | 101/211 [1:01:40<46:53, 25.58s/batch, loss=15.823078]Training:  48%|████▊     | 102/211 [1:01:40<1:31:06, 50.16s/batch, loss=15.823078]Training:  48%|████▊     | 102/211 [1:01:43<1:31:06, 50.16s/batch, loss=15.669492]Training:  49%|████▉     | 103/211 [1:01:43<1:04:53, 36.05s/batch, loss=15.669492]Training:  49%|████▉     | 103/211 [1:01:47<1:04:53, 36.05s/batch, loss=14.565774]Training:  49%|████▉     | 104/211 [1:01:47<46:39, 26.17s/batch, loss=14.565774]  Training:  49%|████▉     | 104/211 [1:02:15<46:39, 26.17s/batch, loss=15.441082]Training:  50%|████▉     | 105/211 [1:02:15<47:38, 26.97s/batch, loss=15.441082]Training:  50%|████▉     | 105/211 [1:04:07<47:38, 26.97s/batch, loss=15.303128]Training:  50%|█████     | 106/211 [1:04:07<1:31:43, 52.42s/batch, loss=15.303128]Training:  50%|█████     | 106/211 [1:04:10<1:31:43, 52.42s/batch, loss=14.995847]Training:  51%|█████     | 107/211 [1:04:10<1:05:12, 37.62s/batch, loss=14.995847]Training:  51%|█████     | 107/211 [1:04:13<1:05:12, 37.62s/batch, loss=16.702845]Training:  51%|█████     | 108/211 [1:04:13<46:46, 27.25s/batch, loss=16.702845]  Training:  51%|█████     | 108/211 [1:04:44<46:46, 27.25s/batch, loss=16.247013]Training:  52%|█████▏    | 109/211 [1:04:44<47:59, 28.23s/batch, loss=16.247013]Training:  52%|█████▏    | 109/211 [1:06:30<47:59, 28.23s/batch, loss=14.616528]Training:  52%|█████▏    | 110/211 [1:06:31<1:27:12, 51.81s/batch, loss=14.616528]Training:  52%|█████▏    | 110/211 [1:06:34<1:27:12, 51.81s/batch, loss=14.968306]Training:  53%|█████▎    | 111/211 [1:06:34<1:01:59, 37.19s/batch, loss=14.968306]Training:  53%|█████▎    | 111/211 [1:06:37<1:01:59, 37.19s/batch, loss=14.915672]Training:  53%|█████▎    | 112/211 [1:06:37<44:30, 26.98s/batch, loss=14.915672]  Training:  53%|█████▎    | 112/211 [1:06:52<44:30, 26.98s/batch, loss=15.850678]Training:  54%|█████▎    | 113/211 [1:06:52<38:07, 23.34s/batch, loss=15.850678]Training:  54%|█████▎    | 113/211 [1:08:41<38:07, 23.34s/batch, loss=15.258583]Training:  54%|█████▍    | 114/211 [1:08:41<1:19:23, 49.10s/batch, loss=15.258583]Training:  54%|█████▍    | 114/211 [1:08:44<1:19:23, 49.10s/batch, loss=14.690589]Training:  55%|█████▍    | 115/211 [1:08:44<56:29, 35.31s/batch, loss=14.690589]  Training:  55%|█████▍    | 115/211 [1:08:47<56:29, 35.31s/batch, loss=14.709727]Training:  55%|█████▍    | 116/211 [1:08:47<40:36, 25.64s/batch, loss=14.709727]Training:  55%|█████▍    | 116/211 [1:09:14<40:36, 25.64s/batch, loss=16.091940]Training:  55%|█████▌    | 117/211 [1:09:14<40:36, 25.92s/batch, loss=16.091940]Training:  55%|█████▌    | 117/211 [1:11:15<40:36, 25.92s/batch, loss=16.106691]Training:  56%|█████▌    | 118/211 [1:11:16<1:24:47, 54.70s/batch, loss=16.106691]Training:  56%|█████▌    | 118/211 [1:11:19<1:24:47, 54.70s/batch, loss=15.825450]Training:  56%|█████▋    | 119/211 [1:11:19<1:00:08, 39.22s/batch, loss=15.825450]Training:  56%|█████▋    | 119/211 [1:11:22<1:00:08, 39.22s/batch, loss=15.742877]Training:  57%|█████▋    | 120/211 [1:11:22<43:02, 28.38s/batch, loss=15.742877]  Training:  57%|█████▋    | 120/211 [1:11:25<43:02, 28.38s/batch, loss=15.131927]Training:  57%|█████▋    | 121/211 [1:11:25<31:10, 20.78s/batch, loss=15.131927]Training:  57%|█████▋    | 121/211 [1:13:49<31:10, 20.78s/batch, loss=15.574244]Training:  58%|█████▊    | 122/211 [1:13:50<1:26:07, 58.07s/batch, loss=15.574244]Training:  58%|█████▊    | 122/211 [1:13:53<1:26:07, 58.07s/batch, loss=14.809237]Training:  58%|█████▊    | 123/211 [1:13:53<1:00:58, 41.57s/batch, loss=14.809237]Training:  58%|█████▊    | 123/211 [1:13:56<1:00:58, 41.57s/batch, loss=14.019354]Training:  59%|█████▉    | 124/211 [1:13:56<43:31, 30.02s/batch, loss=14.019354]  Training:  59%|█████▉    | 124/211 [1:13:59<43:31, 30.02s/batch, loss=15.312360]Training:  59%|█████▉    | 125/211 [1:13:59<31:25, 21.92s/batch, loss=15.312360]Training:  59%|█████▉    | 125/211 [1:16:16<31:25, 21.92s/batch, loss=15.619358]Training:  60%|█████▉    | 126/211 [1:16:16<1:19:56, 56.43s/batch, loss=15.619358]Training:  60%|█████▉    | 126/211 [1:16:19<1:19:56, 56.43s/batch, loss=14.988937]Training:  60%|██████    | 127/211 [1:16:19<56:36, 40.44s/batch, loss=14.988937]  Training:  60%|██████    | 127/211 [1:16:22<56:36, 40.44s/batch, loss=15.168760]Training:  61%|██████    | 128/211 [1:16:22<40:26, 29.23s/batch, loss=15.168760]Training:  61%|██████    | 128/211 [1:16:25<40:26, 29.23s/batch, loss=15.283755]Training:  61%|██████    | 129/211 [1:16:25<29:15, 21.41s/batch, loss=15.283755]Training:  61%|██████    | 129/211 [1:18:29<29:15, 21.41s/batch, loss=15.212503]Training:  62%|██████▏   | 130/211 [1:18:29<1:10:20, 52.11s/batch, loss=15.212503]Training:  62%|██████▏   | 130/211 [1:18:32<1:10:20, 52.11s/batch, loss=15.707994]Training:  62%|██████▏   | 131/211 [1:18:32<49:53, 37.42s/batch, loss=15.707994]  Training:  62%|██████▏   | 131/211 [1:18:35<49:53, 37.42s/batch, loss=15.608163]Training:  63%|██████▎   | 132/211 [1:18:35<35:43, 27.14s/batch, loss=15.608163]Training:  63%|██████▎   | 132/211 [1:18:39<35:43, 27.14s/batch, loss=14.944350]Training:  63%|██████▎   | 133/211 [1:18:39<25:54, 19.92s/batch, loss=14.944350]Training:  63%|██████▎   | 133/211 [1:21:05<25:54, 19.92s/batch, loss=15.313144]Training:  64%|██████▎   | 134/211 [1:21:05<1:14:15, 57.86s/batch, loss=15.313144]Training:  64%|██████▎   | 134/211 [1:21:08<1:14:15, 57.86s/batch, loss=15.406208]Training:  64%|██████▍   | 135/211 [1:21:08<52:27, 41.42s/batch, loss=15.406208]  Training:  64%|██████▍   | 135/211 [1:21:11<52:27, 41.42s/batch, loss=14.952844]Training:  64%|██████▍   | 136/211 [1:21:11<37:23, 29.91s/batch, loss=14.952844]Training:  64%|██████▍   | 136/211 [1:21:14<37:23, 29.91s/batch, loss=15.247090]Training:  65%|██████▍   | 137/211 [1:21:14<27:00, 21.89s/batch, loss=15.247090]Training:  65%|██████▍   | 137/211 [1:23:26<27:00, 21.89s/batch, loss=15.200710]Training:  65%|██████▌   | 138/211 [1:23:27<1:06:55, 55.01s/batch, loss=15.200710]Training:  65%|██████▌   | 138/211 [1:23:30<1:06:55, 55.01s/batch, loss=14.666369]Training:  66%|██████▌   | 139/211 [1:23:30<47:21, 39.46s/batch, loss=14.666369]  Training:  66%|██████▌   | 139/211 [1:23:33<47:21, 39.46s/batch, loss=15.136471]Training:  66%|██████▋   | 140/211 [1:23:33<33:47, 28.55s/batch, loss=15.136471]Training:  66%|██████▋   | 140/211 [1:23:36<33:47, 28.55s/batch, loss=14.911650]Training:  67%|██████▋   | 141/211 [1:23:36<24:23, 20.91s/batch, loss=14.911650]Training:  67%|██████▋   | 141/211 [1:25:42<24:23, 20.91s/batch, loss=14.442231]Training:  67%|██████▋   | 142/211 [1:25:42<1:00:20, 52.47s/batch, loss=14.442231]Training:  67%|██████▋   | 142/211 [1:25:45<1:00:20, 52.47s/batch, loss=14.771070]Training:  68%|██████▊   | 143/211 [1:25:45<42:40, 37.65s/batch, loss=14.771070]  Training:  68%|██████▊   | 143/211 [1:25:48<42:40, 37.65s/batch, loss=14.321774]Training:  68%|██████▊   | 144/211 [1:25:48<30:27, 27.28s/batch, loss=14.321774]Training:  68%|██████▊   | 144/211 [1:25:51<30:27, 27.28s/batch, loss=14.319472]Training:  69%|██████▊   | 145/211 [1:25:51<22:01, 20.02s/batch, loss=14.319472]Training:  69%|██████▊   | 145/211 [1:28:04<22:01, 20.02s/batch, loss=15.048073]Training:  69%|██████▉   | 146/211 [1:28:05<58:30, 54.00s/batch, loss=15.048073]Training:  69%|██████▉   | 146/211 [1:28:08<58:30, 54.00s/batch, loss=14.705316]Training:  70%|██████▉   | 147/211 [1:28:08<41:18, 38.73s/batch, loss=14.705316]Training:  70%|██████▉   | 147/211 [1:28:11<41:18, 38.73s/batch, loss=14.913999]Training:  70%|███████   | 148/211 [1:28:11<29:26, 28.03s/batch, loss=14.913999]Training:  70%|███████   | 148/211 [1:28:14<29:26, 28.03s/batch, loss=14.854127]Training:  71%|███████   | 149/211 [1:28:14<21:14, 20.55s/batch, loss=14.854127]Training:  71%|███████   | 149/211 [1:30:31<21:14, 20.55s/batch, loss=14.524077]Training:  71%|███████   | 150/211 [1:30:32<56:44, 55.82s/batch, loss=14.524077]Training:  71%|███████   | 150/211 [1:30:35<56:44, 55.82s/batch, loss=14.467882]Training:  72%|███████▏  | 151/211 [1:30:35<40:00, 40.00s/batch, loss=14.467882]Training:  72%|███████▏  | 151/211 [1:30:38<40:00, 40.00s/batch, loss=14.550246]Training:  72%|███████▏  | 152/211 [1:30:38<28:27, 28.94s/batch, loss=14.550246]Training:  72%|███████▏  | 152/211 [1:30:41<28:27, 28.94s/batch, loss=14.211494]Training:  73%|███████▎  | 153/211 [1:30:41<20:28, 21.19s/batch, loss=14.211494]Training:  73%|███████▎  | 153/211 [1:33:07<20:28, 21.19s/batch, loss=15.454217]Training:  73%|███████▎  | 154/211 [1:33:08<56:01, 58.98s/batch, loss=15.454217]Training:  73%|███████▎  | 154/211 [1:33:11<56:01, 58.98s/batch, loss=14.608596]Training:  73%|███████▎  | 155/211 [1:33:11<39:23, 42.20s/batch, loss=14.608596]Training:  73%|███████▎  | 155/211 [1:33:15<39:23, 42.20s/batch, loss=15.435502]Training:  74%|███████▍  | 156/211 [1:33:15<27:56, 30.48s/batch, loss=15.435502]Training:  74%|███████▍  | 156/211 [1:33:18<27:56, 30.48s/batch, loss=14.282833]Training:  74%|███████▍  | 157/211 [1:33:18<20:02, 22.26s/batch, loss=14.282833]Training:  74%|███████▍  | 157/211 [1:35:35<20:02, 22.26s/batch, loss=15.003309]Training:  75%|███████▍  | 158/211 [1:35:36<50:22, 57.04s/batch, loss=15.003309]Training:  75%|███████▍  | 158/211 [1:35:39<50:22, 57.04s/batch, loss=14.977583]Training:  75%|███████▌  | 159/211 [1:35:39<35:25, 40.87s/batch, loss=14.977583]Training:  75%|███████▌  | 159/211 [1:35:42<35:25, 40.87s/batch, loss=15.015409]Training:  76%|███████▌  | 160/211 [1:35:42<25:06, 29.55s/batch, loss=15.015409]Training:  76%|███████▌  | 160/211 [1:35:45<25:06, 29.55s/batch, loss=14.720635]Training:  76%|███████▋  | 161/211 [1:35:45<18:00, 21.62s/batch, loss=14.720635]Training:  76%|███████▋  | 161/211 [1:37:51<18:00, 21.62s/batch, loss=14.757017]Training:  77%|███████▋  | 162/211 [1:37:52<43:19, 53.06s/batch, loss=14.757017]Training:  77%|███████▋  | 162/211 [1:37:55<43:19, 53.06s/batch, loss=14.860251]Training:  77%|███████▋  | 163/211 [1:37:55<30:26, 38.05s/batch, loss=14.860251]Training:  77%|███████▋  | 163/211 [1:37:58<30:26, 38.05s/batch, loss=14.522062]Training:  78%|███████▊  | 164/211 [1:37:58<21:35, 27.56s/batch, loss=14.522062]Training:  78%|███████▊  | 164/211 [1:38:01<21:35, 27.56s/batch, loss=14.486195]Training:  78%|███████▊  | 165/211 [1:38:01<15:29, 20.20s/batch, loss=14.486195]Training:  78%|███████▊  | 165/211 [1:40:06<15:29, 20.20s/batch, loss=14.044832]Training:  79%|███████▊  | 166/211 [1:40:06<38:50, 51.78s/batch, loss=14.044832]Training:  79%|███████▊  | 166/211 [1:40:09<38:50, 51.78s/batch, loss=14.019316]Training:  79%|███████▉  | 167/211 [1:40:09<27:15, 37.18s/batch, loss=14.019316]Training:  79%|███████▉  | 167/211 [1:40:12<27:15, 37.18s/batch, loss=14.013175]Training:  80%|███████▉  | 168/211 [1:40:12<19:18, 26.95s/batch, loss=14.013175]Training:  80%|███████▉  | 168/211 [1:40:16<19:18, 26.95s/batch, loss=15.158030]Training:  80%|████████  | 169/211 [1:40:16<13:52, 19.81s/batch, loss=15.158030]Training:  80%|████████  | 169/211 [1:42:10<13:52, 19.81s/batch, loss=13.821755]Training:  81%|████████  | 170/211 [1:42:10<33:00, 48.32s/batch, loss=13.821755]Training:  81%|████████  | 170/211 [1:42:13<33:00, 48.32s/batch, loss=14.549909]Training:  81%|████████  | 171/211 [1:42:13<23:10, 34.75s/batch, loss=14.549909]Training:  81%|████████  | 171/211 [1:42:17<23:10, 34.75s/batch, loss=14.368064]Training:  82%|████████▏ | 172/211 [1:42:17<16:24, 25.25s/batch, loss=14.368064]Training:  82%|████████▏ | 172/211 [1:42:20<16:24, 25.25s/batch, loss=14.106256]Training:  82%|████████▏ | 173/211 [1:42:20<11:47, 18.62s/batch, loss=14.106256]Training:  82%|████████▏ | 173/211 [1:44:27<11:47, 18.62s/batch, loss=14.147537]Training:  82%|████████▏ | 174/211 [1:44:27<31:35, 51.22s/batch, loss=14.147537]Training:  82%|████████▏ | 174/211 [1:44:30<31:35, 51.22s/batch, loss=13.907748]Training:  83%|████████▎ | 175/211 [1:44:30<22:04, 36.78s/batch, loss=13.907748]Training:  83%|████████▎ | 175/211 [1:44:33<22:04, 36.78s/batch, loss=14.204661]Training:  83%|████████▎ | 176/211 [1:44:33<15:33, 26.67s/batch, loss=14.204661]Training:  83%|████████▎ | 176/211 [1:44:43<15:33, 26.67s/batch, loss=14.741229]Training:  84%|████████▍ | 177/211 [1:44:43<12:16, 21.65s/batch, loss=14.741229]Training:  84%|████████▍ | 177/211 [1:46:30<12:16, 21.65s/batch, loss=14.153167]Training:  84%|████████▍ | 178/211 [1:46:30<25:57, 47.21s/batch, loss=14.153167]Training:  84%|████████▍ | 178/211 [1:46:33<25:57, 47.21s/batch, loss=14.392407]Training:  85%|████████▍ | 179/211 [1:46:33<18:07, 33.98s/batch, loss=14.392407]Training:  85%|████████▍ | 179/211 [1:46:36<18:07, 33.98s/batch, loss=14.457858]Training:  85%|████████▌ | 180/211 [1:46:36<12:46, 24.72s/batch, loss=14.457858]Training:  85%|████████▌ | 180/211 [1:47:04<12:46, 24.72s/batch, loss=14.962895]Training:  86%|████████▌ | 181/211 [1:47:04<12:50, 25.67s/batch, loss=14.962895]Training:  86%|████████▌ | 181/211 [1:48:40<12:50, 25.67s/batch, loss=14.879706]Training:  86%|████████▋ | 182/211 [1:48:40<22:34, 46.70s/batch, loss=14.879706]Training:  86%|████████▋ | 182/211 [1:48:43<22:34, 46.70s/batch, loss=14.477068]Training:  87%|████████▋ | 183/211 [1:48:43<15:41, 33.61s/batch, loss=14.477068]Training:  87%|████████▋ | 183/211 [1:48:46<15:41, 33.61s/batch, loss=14.726677]Training:  87%|████████▋ | 184/211 [1:48:46<11:00, 24.46s/batch, loss=14.726677]Training:  87%|████████▋ | 184/211 [1:49:16<11:00, 24.46s/batch, loss=14.731486]Training:  88%|████████▊ | 185/211 [1:49:16<11:20, 26.17s/batch, loss=14.731486]Training:  88%|████████▊ | 185/211 [1:51:00<11:20, 26.17s/batch, loss=14.266277]Training:  88%|████████▊ | 186/211 [1:51:00<20:39, 49.57s/batch, loss=14.266277]Training:  88%|████████▊ | 186/211 [1:51:03<20:39, 49.57s/batch, loss=14.307099]Training:  89%|████████▊ | 187/211 [1:51:03<14:14, 35.62s/batch, loss=14.307099]Training:  89%|████████▊ | 187/211 [1:51:07<14:14, 35.62s/batch, loss=14.369090]Training:  89%|████████▉ | 188/211 [1:51:07<09:55, 25.90s/batch, loss=14.369090]Training:  89%|████████▉ | 188/211 [1:51:41<09:55, 25.90s/batch, loss=14.550269]Training:  90%|████████▉ | 189/211 [1:51:41<10:25, 28.45s/batch, loss=14.550269]Training:  90%|████████▉ | 189/211 [1:53:26<10:25, 28.45s/batch, loss=13.902246]Training:  90%|█████████ | 190/211 [1:53:26<18:00, 51.45s/batch, loss=13.902246]Training:  90%|█████████ | 190/211 [1:53:29<18:00, 51.45s/batch, loss=14.522377]Training:  91%|█████████ | 191/211 [1:53:29<12:18, 36.95s/batch, loss=14.522377]Training:  91%|█████████ | 191/211 [1:53:32<12:18, 36.95s/batch, loss=14.776840]Training:  91%|█████████ | 192/211 [1:53:32<08:28, 26.78s/batch, loss=14.776840]Training:  91%|█████████ | 192/211 [1:54:05<08:28, 26.78s/batch, loss=14.278740]Training:  91%|█████████▏| 193/211 [1:54:05<08:33, 28.53s/batch, loss=14.278740]Training:  91%|█████████▏| 193/211 [1:55:32<08:33, 28.53s/batch, loss=14.133397]Training:  92%|█████████▏| 194/211 [1:55:32<13:05, 46.19s/batch, loss=14.133397]Training:  92%|█████████▏| 194/211 [1:55:35<13:05, 46.19s/batch, loss=14.878656]Training:  92%|█████████▏| 195/211 [1:55:35<08:51, 33.25s/batch, loss=14.878656]Training:  92%|█████████▏| 195/211 [1:55:38<08:51, 33.25s/batch, loss=14.629924]Training:  93%|█████████▎| 196/211 [1:55:38<06:02, 24.20s/batch, loss=14.629924]Training:  93%|█████████▎| 196/211 [1:56:38<06:02, 24.20s/batch, loss=13.677852]Training:  93%|█████████▎| 197/211 [1:56:38<08:07, 34.81s/batch, loss=13.677852]Training:  93%|█████████▎| 197/211 [1:58:06<08:07, 34.81s/batch, loss=14.218395]Training:  94%|█████████▍| 198/211 [1:58:06<10:58, 50.68s/batch, loss=14.218395]Training:  94%|█████████▍| 198/211 [1:58:09<10:58, 50.68s/batch, loss=15.007441]Training:  94%|█████████▍| 199/211 [1:58:09<07:16, 36.40s/batch, loss=15.007441]Training:  94%|█████████▍| 199/211 [1:58:12<07:16, 36.40s/batch, loss=14.037051]Training:  95%|█████████▍| 200/211 [1:58:12<04:50, 26.41s/batch, loss=14.037051]Training:  95%|█████████▍| 200/211 [1:58:54<04:50, 26.41s/batch, loss=13.744133]Training:  95%|█████████▌| 201/211 [1:58:54<05:11, 31.17s/batch, loss=13.744133]Training:  95%|█████████▌| 201/211 [2:00:20<05:11, 31.17s/batch, loss=13.914424]Training:  96%|█████████▌| 202/211 [2:00:21<07:10, 47.84s/batch, loss=13.914424]Training:  96%|█████████▌| 202/211 [2:00:24<07:10, 47.84s/batch, loss=14.391928]Training:  96%|█████████▌| 203/211 [2:00:24<04:35, 34.42s/batch, loss=14.391928]Training:  96%|█████████▌| 203/211 [2:00:27<04:35, 34.42s/batch, loss=14.046866]Training:  97%|█████████▋| 204/211 [2:00:27<02:55, 25.03s/batch, loss=14.046866]Training:  97%|█████████▋| 204/211 [2:01:18<02:55, 25.03s/batch, loss=14.230795]Training:  97%|█████████▋| 205/211 [2:01:18<03:17, 32.83s/batch, loss=14.230795]Training:  97%|█████████▋| 205/211 [2:02:28<03:17, 32.83s/batch, loss=14.525960]Training:  98%|█████████▊| 206/211 [2:02:28<03:39, 43.95s/batch, loss=14.525960]Training:  98%|█████████▊| 206/211 [2:02:31<03:39, 43.95s/batch, loss=14.218277]Training:  98%|█████████▊| 207/211 [2:02:31<02:06, 31.69s/batch, loss=14.218277]Training:  98%|█████████▊| 207/211 [2:02:34<02:06, 31.69s/batch, loss=13.846267]Training:  99%|█████████▊| 208/211 [2:02:34<01:09, 23.11s/batch, loss=13.846267]Training:  99%|█████████▊| 208/211 [2:02:54<01:09, 23.11s/batch, loss=14.086397]Training:  99%|█████████▉| 209/211 [2:02:54<00:44, 22.05s/batch, loss=14.086397]Training:  99%|█████████▉| 209/211 [2:03:21<00:44, 22.05s/batch, loss=14.871335]Training: 100%|█████████▉| 210/211 [2:03:21<00:23, 23.63s/batch, loss=14.871335]Training: 100%|█████████▉| 210/211 [2:03:22<00:23, 23.63s/batch, loss=13.238297]Training: 100%|██████████| 211/211 [2:03:22<00:00, 16.75s/batch, loss=13.238297]Training: 100%|██████████| 211/211 [2:03:22<00:00, 35.08s/batch, loss=13.238297]
Epoch 4, Train Loss: 15.6646, Val Loss: 13.9931
Training:   0%|          | 0/211 [00:00<?, ?batch/s]Training:   0%|          | 0/211 [02:04<?, ?batch/s, loss=13.416545]Training:   0%|          | 1/211 [02:04<7:16:23, 124.68s/batch, loss=13.416545]Training:   0%|          | 1/211 [02:07<7:16:23, 124.68s/batch, loss=14.977449]Training:   1%|          | 2/211 [02:07<3:05:09, 53.16s/batch, loss=14.977449] Training:   1%|          | 2/211 [02:10<3:05:09, 53.16s/batch, loss=13.580548]Training:   1%|▏         | 3/211 [02:10<1:45:03, 30.30s/batch, loss=13.580548]Training:   1%|▏         | 3/211 [02:13<1:45:03, 30.30s/batch, loss=13.113731]Training:   2%|▏         | 4/211 [02:13<1:07:29, 19.56s/batch, loss=13.113731]Training:   2%|▏         | 4/211 [04:14<1:07:29, 19.56s/batch, loss=13.282537]Training:   2%|▏         | 5/211 [04:14<3:12:45, 56.14s/batch, loss=13.282537]Training:   2%|▏         | 5/211 [04:18<3:12:45, 56.14s/batch, loss=13.711804]Training:   3%|▎         | 6/211 [04:18<2:10:13, 38.12s/batch, loss=13.711804]Training:   3%|▎         | 6/211 [04:24<2:10:13, 38.12s/batch, loss=14.421479]Training:   3%|▎         | 7/211 [04:24<1:34:14, 27.72s/batch, loss=14.421479]Training:   3%|▎         | 7/211 [04:27<1:34:14, 27.72s/batch, loss=14.144209]Training:   4%|▍         | 8/211 [04:27<1:07:15, 19.88s/batch, loss=14.144209]Training:   4%|▍         | 8/211 [06:37<1:07:15, 19.88s/batch, loss=14.423321]Training:   4%|▍         | 9/211 [06:38<3:03:26, 54.49s/batch, loss=14.423321]Training:   4%|▍         | 9/211 [06:41<3:03:26, 54.49s/batch, loss=14.158247]Training:   5%|▍         | 10/211 [06:41<2:09:20, 38.61s/batch, loss=14.158247]Training:   5%|▍         | 10/211 [06:47<2:09:20, 38.61s/batch, loss=13.572672]Training:   5%|▌         | 11/211 [06:47<1:35:43, 28.72s/batch, loss=13.572672]Training:   5%|▌         | 11/211 [06:50<1:35:43, 28.72s/batch, loss=13.938481]Training:   6%|▌         | 12/211 [06:50<1:09:23, 20.92s/batch, loss=13.938481]Training:   6%|▌         | 12/211 [09:13<1:09:23, 20.92s/batch, loss=14.032373]Training:   6%|▌         | 13/211 [09:13<3:10:53, 57.85s/batch, loss=14.032373]Training:   6%|▌         | 13/211 [09:16<3:10:53, 57.85s/batch, loss=14.152727]Training:   7%|▋         | 14/211 [09:16<2:15:41, 41.33s/batch, loss=14.152727]Training:   7%|▋         | 14/211 [09:20<2:15:41, 41.33s/batch, loss=14.015342]Training:   7%|▋         | 15/211 [09:20<1:38:14, 30.07s/batch, loss=14.015342]Training:   7%|▋         | 15/211 [09:23<1:38:14, 30.07s/batch, loss=14.072600]Training:   8%|▊         | 16/211 [09:23<1:11:25, 21.98s/batch, loss=14.072600]Training:   8%|▊         | 16/211 [11:54<1:11:25, 21.98s/batch, loss=14.486055]Training:   8%|▊         | 17/211 [11:54<3:16:18, 60.71s/batch, loss=14.486055]Training:   8%|▊         | 17/211 [11:58<3:16:18, 60.71s/batch, loss=13.652667]Training:   9%|▊         | 18/211 [11:58<2:20:29, 43.68s/batch, loss=13.652667]Training:   9%|▊         | 18/211 [12:01<2:20:29, 43.68s/batch, loss=13.752016]Training:   9%|▉         | 19/211 [12:01<1:40:45, 31.49s/batch, loss=13.752016]Training:   9%|▉         | 19/211 [12:04<1:40:45, 31.49s/batch, loss=13.846848]Training:   9%|▉         | 20/211 [12:04<1:13:05, 22.96s/batch, loss=13.846848]Training:   9%|▉         | 20/211 [14:47<1:13:05, 22.96s/batch, loss=13.843735]Training:  10%|▉         | 21/211 [14:48<3:26:36, 65.24s/batch, loss=13.843735]Training:  10%|▉         | 21/211 [14:53<3:26:36, 65.24s/batch, loss=13.387420]Training:  10%|█         | 22/211 [14:53<2:29:01, 47.31s/batch, loss=13.387420]Training:  10%|█         | 22/211 [14:57<2:29:01, 47.31s/batch, loss=14.371842]Training:  11%|█         | 23/211 [14:57<1:46:37, 34.03s/batch, loss=14.371842]Training:  11%|█         | 23/211 [15:00<1:46:37, 34.03s/batch, loss=14.017148]Training:  11%|█▏        | 24/211 [15:00<1:17:10, 24.76s/batch, loss=14.017148]Training:  11%|█▏        | 24/211 [18:33<1:17:10, 24.76s/batch, loss=13.637315]Training:  12%|█▏        | 25/211 [18:35<4:14:13, 82.01s/batch, loss=13.637315]Training:  12%|█▏        | 25/211 [18:40<4:14:13, 82.01s/batch, loss=13.516812]Training:  12%|█▏        | 26/211 [18:40<3:01:01, 58.71s/batch, loss=13.516812]Training:  12%|█▏        | 26/211 [18:47<3:01:01, 58.71s/batch, loss=13.870998]Training:  13%|█▎        | 27/211 [18:47<2:13:01, 43.38s/batch, loss=13.870998]Training:  13%|█▎        | 27/211 [18:55<2:13:01, 43.38s/batch, loss=13.683554]Training:  13%|█▎        | 28/211 [18:55<1:40:01, 32.80s/batch, loss=13.683554]Training:  13%|█▎        | 28/211 [21:18<1:40:01, 32.80s/batch, loss=13.491988]Training:  14%|█▎        | 29/211 [21:18<3:19:21, 65.72s/batch, loss=13.491988]Training:  14%|█▎        | 29/211 [21:22<3:19:21, 65.72s/batch, loss=13.996205]Training:  14%|█▍        | 30/211 [21:22<2:22:35, 47.27s/batch, loss=13.996205]Training:  14%|█▍        | 30/211 [21:33<2:22:35, 47.27s/batch, loss=14.150879]Training:  15%|█▍        | 31/211 [21:33<1:49:14, 36.41s/batch, loss=14.150879]Training:  15%|█▍        | 31/211 [21:37<1:49:14, 36.41s/batch, loss=14.206852]Training:  15%|█▌        | 32/211 [21:37<1:19:05, 26.51s/batch, loss=14.206852]Training:  15%|█▌        | 32/211 [24:05<1:19:05, 26.51s/batch, loss=13.857620]Training:  16%|█▌        | 33/211 [24:05<3:07:26, 63.18s/batch, loss=13.857620]Training:  16%|█▌        | 33/211 [24:09<3:07:26, 63.18s/batch, loss=13.127090]Training:  16%|█▌        | 34/211 [24:09<2:13:21, 45.21s/batch, loss=13.127090]Training:  16%|█▌        | 34/211 [24:18<2:13:21, 45.21s/batch, loss=14.041878]Training:  17%|█▋        | 35/211 [24:18<1:41:16, 34.52s/batch, loss=14.041878]Training:  17%|█▋        | 35/211 [24:28<1:41:16, 34.52s/batch, loss=13.427662]Training:  17%|█▋        | 36/211 [24:28<1:19:22, 27.21s/batch, loss=13.427662]Training:  17%|█▋        | 36/211 [26:52<1:19:22, 27.21s/batch, loss=13.421329]Training:  18%|█▊        | 37/211 [26:52<3:00:21, 62.19s/batch, loss=13.421329]Training:  18%|█▊        | 37/211 [26:55<3:00:21, 62.19s/batch, loss=13.733461]Training:  18%|█▊        | 38/211 [26:55<2:08:21, 44.52s/batch, loss=13.733461]Training:  18%|█▊        | 38/211 [26:59<2:08:21, 44.52s/batch, loss=13.823370]Training:  18%|█▊        | 39/211 [26:59<1:32:20, 32.21s/batch, loss=13.823370]Training:  18%|█▊        | 39/211 [27:05<1:32:20, 32.21s/batch, loss=13.349340]Training:  19%|█▉        | 40/211 [27:05<1:09:19, 24.32s/batch, loss=13.349340]Training:  19%|█▉        | 40/211 [29:33<1:09:19, 24.32s/batch, loss=13.574536]Training:  19%|█▉        | 41/211 [29:33<2:54:07, 61.46s/batch, loss=13.574536]Training:  19%|█▉        | 41/211 [29:36<2:54:07, 61.46s/batch, loss=13.626151]Training:  20%|█▉        | 42/211 [29:36<2:03:57, 44.01s/batch, loss=13.626151]Training:  20%|█▉        | 42/211 [29:40<2:03:57, 44.01s/batch, loss=13.801934]Training:  20%|██        | 43/211 [29:40<1:29:01, 31.80s/batch, loss=13.801934]Training:  20%|██        | 43/211 [29:43<1:29:01, 31.80s/batch, loss=13.880294]Training:  21%|██        | 44/211 [29:43<1:04:53, 23.31s/batch, loss=13.880294]Training:  21%|██        | 44/211 [32:02<1:04:53, 23.31s/batch, loss=13.879551]Training:  21%|██▏       | 45/211 [32:02<2:40:22, 57.97s/batch, loss=13.879551]Training:  21%|██▏       | 45/211 [32:06<2:40:22, 57.97s/batch, loss=13.460402]Training:  22%|██▏       | 46/211 [32:06<1:54:48, 41.75s/batch, loss=13.460402]Training:  22%|██▏       | 46/211 [32:09<1:54:48, 41.75s/batch, loss=13.646825]Training:  22%|██▏       | 47/211 [32:09<1:22:43, 30.27s/batch, loss=13.646825]Training:  22%|██▏       | 47/211 [32:13<1:22:43, 30.27s/batch, loss=13.632821]Training:  23%|██▎       | 48/211 [32:13<1:00:32, 22.28s/batch, loss=13.632821]Training:  23%|██▎       | 48/211 [34:31<1:00:32, 22.28s/batch, loss=13.327287]Training:  23%|██▎       | 49/211 [34:31<2:34:09, 57.10s/batch, loss=13.327287]Training:  23%|██▎       | 49/211 [34:34<2:34:09, 57.10s/batch, loss=13.964728]Training:  24%|██▎       | 50/211 [34:34<1:49:45, 40.90s/batch, loss=13.964728]Training:  24%|██▎       | 50/211 [34:38<1:49:45, 40.90s/batch, loss=13.696646]Training:  24%|██▍       | 51/211 [34:38<1:19:10, 29.69s/batch, loss=13.696646]Training:  24%|██▍       | 51/211 [34:42<1:19:10, 29.69s/batch, loss=13.884493]Training:  25%|██▍       | 52/211 [34:42<58:31, 22.08s/batch, loss=13.884493]  Training:  25%|██▍       | 52/211 [36:36<58:31, 22.08s/batch, loss=13.754397]Training:  25%|██▌       | 53/211 [36:36<2:10:26, 49.53s/batch, loss=13.754397]Training:  25%|██▌       | 53/211 [36:39<2:10:26, 49.53s/batch, loss=13.534366]Training:  26%|██▌       | 54/211 [36:39<1:33:22, 35.69s/batch, loss=13.534366]Training:  26%|██▌       | 54/211 [36:42<1:33:22, 35.69s/batch, loss=14.940684]Training:  26%|██▌       | 55/211 [36:42<1:07:23, 25.92s/batch, loss=14.940684]Training:  26%|██▌       | 55/211 [37:26<1:07:23, 25.92s/batch, loss=13.626517]Training:  27%|██▋       | 56/211 [37:26<1:20:27, 31.15s/batch, loss=13.626517]Training:  27%|██▋       | 56/211 [38:48<1:20:27, 31.15s/batch, loss=12.695564]Training:  27%|██▋       | 57/211 [38:48<1:59:16, 46.47s/batch, loss=12.695564]Training:  27%|██▋       | 57/211 [38:51<1:59:16, 46.47s/batch, loss=13.218147]Training:  27%|██▋       | 58/211 [38:51<1:25:39, 33.59s/batch, loss=13.218147]Training:  27%|██▋       | 58/211 [38:55<1:25:39, 33.59s/batch, loss=13.441083]Training:  28%|██▊       | 59/211 [38:55<1:02:22, 24.62s/batch, loss=13.441083]Training:  28%|██▊       | 59/211 [39:37<1:02:22, 24.62s/batch, loss=13.541487]Training:  28%|██▊       | 60/211 [39:38<1:15:27, 29.99s/batch, loss=13.541487]Training:  28%|██▊       | 60/211 [40:59<1:15:27, 29.99s/batch, loss=13.967089]Training:  29%|██▉       | 61/211 [40:59<1:53:33, 45.43s/batch, loss=13.967089]Training:  29%|██▉       | 61/211 [41:03<1:53:33, 45.43s/batch, loss=13.575796]Training:  29%|██▉       | 62/211 [41:03<1:21:39, 32.88s/batch, loss=13.575796]Training:  29%|██▉       | 62/211 [41:08<1:21:39, 32.88s/batch, loss=13.413040]Training:  30%|██▉       | 63/211 [41:08<1:00:46, 24.64s/batch, loss=13.413040]Training:  30%|██▉       | 63/211 [42:00<1:00:46, 24.64s/batch, loss=13.321418]Training:  30%|███       | 64/211 [42:00<1:20:31, 32.87s/batch, loss=13.321418]Training:  30%|███       | 64/211 [42:50<1:20:31, 32.87s/batch, loss=13.610744]Training:  31%|███       | 65/211 [42:50<1:32:41, 38.09s/batch, loss=13.610744]Training:  31%|███       | 65/211 [42:54<1:32:41, 38.09s/batch, loss=13.428533]Training:  31%|███▏      | 66/211 [42:54<1:07:21, 27.88s/batch, loss=13.428533]Training:  31%|███▏      | 66/211 [43:25<1:07:21, 27.88s/batch, loss=13.339145]Training:  32%|███▏      | 67/211 [43:25<1:08:53, 28.70s/batch, loss=13.339145]Training:  32%|███▏      | 67/211 [44:26<1:08:53, 28.70s/batch, loss=13.354291]Training:  32%|███▏      | 68/211 [44:26<1:31:12, 38.27s/batch, loss=13.354291]Training:  32%|███▏      | 68/211 [44:53<1:31:12, 38.27s/batch, loss=12.899487]Training:  33%|███▎      | 69/211 [44:53<1:22:53, 35.03s/batch, loss=12.899487]Training:  33%|███▎      | 69/211 [44:56<1:22:53, 35.03s/batch, loss=13.560022]Training:  33%|███▎      | 70/211 [44:56<59:57, 25.51s/batch, loss=13.560022]  Training:  33%|███▎      | 70/211 [45:34<59:57, 25.51s/batch, loss=13.480170]Training:  34%|███▎      | 71/211 [45:34<1:07:44, 29.03s/batch, loss=13.480170]Training:  34%|███▎      | 71/211 [46:42<1:07:44, 29.03s/batch, loss=13.301253]Training:  34%|███▍      | 72/211 [46:43<1:35:05, 41.04s/batch, loss=13.301253]Training:  34%|███▍      | 72/211 [47:07<1:35:05, 41.04s/batch, loss=12.987928]Training:  35%|███▍      | 73/211 [47:07<1:23:02, 36.10s/batch, loss=12.987928]Training:  35%|███▍      | 73/211 [47:10<1:23:02, 36.10s/batch, loss=13.387478]Training:  35%|███▌      | 74/211 [47:10<59:49, 26.20s/batch, loss=13.387478]  Training:  35%|███▌      | 74/211 [47:42<59:49, 26.20s/batch, loss=13.268316]Training:  36%|███▌      | 75/211 [47:42<1:02:42, 27.67s/batch, loss=13.268316]Training:  36%|███▌      | 75/211 [48:51<1:02:42, 27.67s/batch, loss=13.330133]Training:  36%|███▌      | 76/211 [48:51<1:30:33, 40.25s/batch, loss=13.330133]Training:  36%|███▌      | 76/211 [51:19<1:30:33, 40.25s/batch, loss=13.767313]Training:  36%|███▋      | 77/211 [51:19<2:42:17, 72.67s/batch, loss=13.767313]Training:  36%|███▋      | 77/211 [51:23<2:42:17, 72.67s/batch, loss=14.073779]Training:  37%|███▋      | 78/211 [51:23<1:54:48, 51.79s/batch, loss=14.073779]Training:  37%|███▋      | 78/211 [51:26<1:54:48, 51.79s/batch, loss=13.156671]Training:  37%|███▋      | 79/211 [51:26<1:21:47, 37.18s/batch, loss=13.156671]Training:  37%|███▋      | 79/211 [51:29<1:21:47, 37.18s/batch, loss=13.594536]Training:  38%|███▊      | 80/211 [51:29<58:49, 26.94s/batch, loss=13.594536]  Training:  38%|███▊      | 80/211 [53:03<58:49, 26.94s/batch, loss=13.160136]Training:  38%|███▊      | 81/211 [53:03<1:42:17, 47.21s/batch, loss=13.160136]Training:  38%|███▊      | 81/211 [53:06<1:42:17, 47.21s/batch, loss=12.853715]Training:  39%|███▉      | 82/211 [53:06<1:13:06, 34.01s/batch, loss=12.853715]Training:  39%|███▉      | 82/211 [53:10<1:13:06, 34.01s/batch, loss=13.064576]Training:  39%|███▉      | 83/211 [53:10<52:58, 24.84s/batch, loss=13.064576]  Training:  39%|███▉      | 83/211 [57:11<52:58, 24.84s/batch, loss=13.348389]Training:  40%|███▉      | 84/211 [57:11<3:09:47, 89.66s/batch, loss=13.348389]Training:  40%|███▉      | 84/211 [57:14<3:09:47, 89.66s/batch, loss=13.117368]Training:  40%|████      | 85/211 [57:14<2:13:43, 63.68s/batch, loss=13.117368]Training:  40%|████      | 85/211 [57:17<2:13:43, 63.68s/batch, loss=12.808941]Training:  41%|████      | 86/211 [57:17<1:34:46, 45.49s/batch, loss=12.808941]Training:  41%|████      | 86/211 [57:21<1:34:46, 45.49s/batch, loss=13.364945]Training:  41%|████      | 87/211 [57:21<1:08:10, 32.98s/batch, loss=13.364945]Training:  41%|████      | 87/211 [59:15<1:08:10, 32.98s/batch, loss=13.026248]Training:  42%|████▏     | 88/211 [59:15<1:57:25, 57.28s/batch, loss=13.026248]Training:  42%|████▏     | 88/211 [59:18<1:57:25, 57.28s/batch, loss=13.667052]Training:  42%|████▏     | 89/211 [59:18<1:23:26, 41.03s/batch, loss=13.667052]Training:  42%|████▏     | 89/211 [59:21<1:23:26, 41.03s/batch, loss=13.346718]Training:  43%|████▎     | 90/211 [59:21<59:49, 29.66s/batch, loss=13.346718]  Training:  43%|████▎     | 90/211 [59:24<59:49, 29.66s/batch, loss=13.024297]Training:  43%|████▎     | 91/211 [59:24<43:26, 21.72s/batch, loss=13.024297]Training:  43%|████▎     | 91/211 [1:01:07<43:26, 21.72s/batch, loss=13.062261]Training:  44%|████▎     | 92/211 [1:01:07<1:31:37, 46.20s/batch, loss=13.062261]Training:  44%|████▎     | 92/211 [1:01:10<1:31:37, 46.20s/batch, loss=12.593416]Training:  44%|████▍     | 93/211 [1:01:10<1:05:24, 33.26s/batch, loss=12.593416]Training:  44%|████▍     | 93/211 [1:01:14<1:05:24, 33.26s/batch, loss=12.571462]Training:  45%|████▍     | 94/211 [1:01:14<47:15, 24.23s/batch, loss=12.571462]  Training:  45%|████▍     | 94/211 [1:01:17<47:15, 24.23s/batch, loss=13.813759]Training:  45%|████▌     | 95/211 [1:01:17<34:36, 17.90s/batch, loss=13.813759]Training:  45%|████▌     | 95/211 [1:03:09<34:36, 17.90s/batch, loss=12.699217]Training:  45%|████▌     | 96/211 [1:03:09<1:28:19, 46.08s/batch, loss=12.699217]Training:  45%|████▌     | 96/211 [1:03:12<1:28:19, 46.08s/batch, loss=13.458760]Training:  46%|████▌     | 97/211 [1:03:12<1:03:02, 33.18s/batch, loss=13.458760]Training:  46%|████▌     | 97/211 [1:03:15<1:03:02, 33.18s/batch, loss=12.663648]Training:  46%|████▋     | 98/211 [1:03:15<45:34, 24.20s/batch, loss=12.663648]  Training:  46%|████▋     | 98/211 [1:03:18<45:34, 24.20s/batch, loss=13.009046]Training:  47%|████▋     | 99/211 [1:03:18<33:20, 17.87s/batch, loss=13.009046]Training:  47%|████▋     | 99/211 [1:05:12<33:20, 17.87s/batch, loss=13.095019]Training:  47%|████▋     | 100/211 [1:05:13<1:26:42, 46.87s/batch, loss=13.095019]Training:  47%|████▋     | 100/211 [1:05:16<1:26:42, 46.87s/batch, loss=12.612738]Training:  48%|████▊     | 101/211 [1:05:16<1:02:05, 33.87s/batch, loss=12.612738]Training:  48%|████▊     | 101/211 [1:05:20<1:02:05, 33.87s/batch, loss=12.946705]Training:  48%|████▊     | 102/211 [1:05:20<44:56, 24.74s/batch, loss=12.946705]  Training:  48%|████▊     | 102/211 [1:05:23<44:56, 24.74s/batch, loss=13.869117]Training:  49%|████▉     | 103/211 [1:05:23<33:03, 18.37s/batch, loss=13.869117]Training:  49%|████▉     | 103/211 [1:07:12<33:03, 18.37s/batch, loss=13.108694]Training:  49%|████▉     | 104/211 [1:07:12<1:21:27, 45.67s/batch, loss=13.108694]Training:  49%|████▉     | 104/211 [1:07:16<1:21:27, 45.67s/batch, loss=12.645478]Training:  50%|████▉     | 105/211 [1:07:16<58:08, 32.91s/batch, loss=12.645478]  Training:  50%|████▉     | 105/211 [1:07:19<58:08, 32.91s/batch, loss=12.967077]Training:  50%|█████     | 106/211 [1:07:19<42:18, 24.18s/batch, loss=12.967077]Training:  50%|█████     | 106/211 [1:07:23<42:18, 24.18s/batch, loss=12.944794]Training:  51%|█████     | 107/211 [1:07:23<31:10, 17.98s/batch, loss=12.944794]Training:  51%|█████     | 107/211 [1:09:06<31:10, 17.98s/batch, loss=12.619847]Training:  51%|█████     | 108/211 [1:09:06<1:14:40, 43.50s/batch, loss=12.619847]Training:  51%|█████     | 108/211 [1:09:09<1:14:40, 43.50s/batch, loss=13.151089]Training:  52%|█████▏    | 109/211 [1:09:09<53:23, 31.40s/batch, loss=13.151089]  Training:  52%|█████▏    | 109/211 [1:09:12<53:23, 31.40s/batch, loss=13.207230]Training:  52%|█████▏    | 110/211 [1:09:12<38:33, 22.90s/batch, loss=13.207230]Training:  52%|█████▏    | 110/211 [1:09:15<38:33, 22.90s/batch, loss=12.762980]Training:  53%|█████▎    | 111/211 [1:09:15<28:15, 16.96s/batch, loss=12.762980]Training:  53%|█████▎    | 111/211 [1:11:09<28:15, 16.96s/batch, loss=12.661873]Training:  53%|█████▎    | 112/211 [1:11:09<1:16:08, 46.15s/batch, loss=12.661873]Training:  53%|█████▎    | 112/211 [1:11:13<1:16:08, 46.15s/batch, loss=13.351935]Training:  54%|█████▎    | 113/211 [1:11:13<54:16, 33.23s/batch, loss=13.351935]  Training:  54%|█████▎    | 113/211 [1:11:16<54:16, 33.23s/batch, loss=12.909440]Training:  54%|█████▍    | 114/211 [1:11:16<39:22, 24.36s/batch, loss=12.909440]Training:  54%|█████▍    | 114/211 [1:11:19<39:22, 24.36s/batch, loss=12.882528]Training:  55%|█████▍    | 115/211 [1:11:19<28:45, 17.98s/batch, loss=12.882528]Training:  55%|█████▍    | 115/211 [1:13:32<28:45, 17.98s/batch, loss=12.760378]Training:  55%|█████▍    | 116/211 [1:13:33<1:23:21, 52.64s/batch, loss=12.760378]Training:  55%|█████▍    | 116/211 [1:13:36<1:23:21, 52.64s/batch, loss=13.132506]Training:  55%|█████▌    | 117/211 [1:13:36<59:18, 37.86s/batch, loss=13.132506]  Training:  55%|█████▌    | 117/211 [1:13:39<59:18, 37.86s/batch, loss=12.848777]Training:  56%|█████▌    | 118/211 [1:13:39<42:33, 27.46s/batch, loss=12.848777]Training:  56%|█████▌    | 118/211 [1:13:42<42:33, 27.46s/batch, loss=12.417759]Training:  56%|█████▋    | 119/211 [1:13:42<30:52, 20.14s/batch, loss=12.417759]Training:  56%|█████▋    | 119/211 [1:15:21<30:52, 20.14s/batch, loss=13.062099]Training:  57%|█████▋    | 120/211 [1:15:21<1:06:15, 43.68s/batch, loss=13.062099]Training:  57%|█████▋    | 120/211 [1:15:24<1:06:15, 43.68s/batch, loss=12.683363]Training:  57%|█████▋    | 121/211 [1:15:24<47:15, 31.50s/batch, loss=12.683363]  Training:  57%|█████▋    | 121/211 [1:15:27<47:15, 31.50s/batch, loss=12.861899]Training:  58%|█████▊    | 122/211 [1:15:27<34:06, 23.00s/batch, loss=12.861899]Training:  58%|█████▊    | 122/211 [1:15:31<34:06, 23.00s/batch, loss=12.643664]Training:  58%|█████▊    | 123/211 [1:15:31<25:01, 17.06s/batch, loss=12.643664]Training:  58%|█████▊    | 123/211 [1:17:30<25:01, 17.06s/batch, loss=12.800618]Training:  59%|█████▉    | 124/211 [1:17:30<1:09:20, 47.82s/batch, loss=12.800618]Training:  59%|█████▉    | 124/211 [1:17:33<1:09:20, 47.82s/batch, loss=13.285728]Training:  59%|█████▉    | 125/211 [1:17:33<49:19, 34.42s/batch, loss=13.285728]  Training:  59%|█████▉    | 125/211 [1:17:37<49:19, 34.42s/batch, loss=13.225579]Training:  60%|█████▉    | 126/211 [1:17:37<35:36, 25.13s/batch, loss=13.225579]Training:  60%|█████▉    | 126/211 [1:17:40<35:36, 25.13s/batch, loss=13.098150]Training:  60%|██████    | 127/211 [1:17:40<25:56, 18.52s/batch, loss=13.098150]Training:  60%|██████    | 127/211 [1:19:35<25:56, 18.52s/batch, loss=12.577374]Training:  61%|██████    | 128/211 [1:19:35<1:05:47, 47.56s/batch, loss=12.577374]Training:  61%|██████    | 128/211 [1:19:38<1:05:47, 47.56s/batch, loss=12.672072]Training:  61%|██████    | 129/211 [1:19:38<46:47, 34.23s/batch, loss=12.672072]  Training:  61%|██████    | 129/211 [1:19:41<46:47, 34.23s/batch, loss=12.956869]Training:  62%|██████▏   | 130/211 [1:19:41<33:36, 24.90s/batch, loss=12.956869]Training:  62%|██████▏   | 130/211 [1:19:44<33:36, 24.90s/batch, loss=12.898549]Training:  62%|██████▏   | 131/211 [1:19:44<24:28, 18.36s/batch, loss=12.898549]Training:  62%|██████▏   | 131/211 [1:21:45<24:28, 18.36s/batch, loss=12.437307]Training:  63%|██████▎   | 132/211 [1:21:45<1:04:34, 49.05s/batch, loss=12.437307]Training:  63%|██████▎   | 132/211 [1:21:48<1:04:34, 49.05s/batch, loss=12.650352]Training:  63%|██████▎   | 133/211 [1:21:48<45:56, 35.34s/batch, loss=12.650352]  Training:  63%|██████▎   | 133/211 [1:21:52<45:56, 35.34s/batch, loss=13.006246]Training:  64%|██████▎   | 134/211 [1:21:52<32:56, 25.67s/batch, loss=13.006246]Training:  64%|██████▎   | 134/211 [1:21:55<32:56, 25.67s/batch, loss=12.626373]Training:  64%|██████▍   | 135/211 [1:21:55<23:59, 18.94s/batch, loss=12.626373]Training:  64%|██████▍   | 135/211 [1:23:49<23:59, 18.94s/batch, loss=12.802579]Training:  64%|██████▍   | 136/211 [1:23:49<59:20, 47.48s/batch, loss=12.802579]Training:  64%|██████▍   | 136/211 [1:23:52<59:20, 47.48s/batch, loss=12.559923]Training:  65%|██████▍   | 137/211 [1:23:52<42:10, 34.19s/batch, loss=12.559923]Training:  65%|██████▍   | 137/211 [1:23:56<42:10, 34.19s/batch, loss=13.346029]Training:  65%|██████▌   | 138/211 [1:23:56<30:29, 25.06s/batch, loss=13.346029]Training:  65%|██████▌   | 138/211 [1:24:00<30:29, 25.06s/batch, loss=12.749260]Training:  66%|██████▌   | 139/211 [1:24:00<22:30, 18.75s/batch, loss=12.749260]Training:  66%|██████▌   | 139/211 [1:25:56<22:30, 18.75s/batch, loss=12.863335]Training:  66%|██████▋   | 140/211 [1:25:56<56:52, 48.07s/batch, loss=12.863335]Training:  66%|██████▋   | 140/211 [1:26:01<56:52, 48.07s/batch, loss=12.818642]Training:  67%|██████▋   | 141/211 [1:26:01<40:44, 34.91s/batch, loss=12.818642]Training:  67%|██████▋   | 141/211 [1:26:04<40:44, 34.91s/batch, loss=12.351864]Training:  67%|██████▋   | 142/211 [1:26:04<29:09, 25.36s/batch, loss=12.351864]Training:  67%|██████▋   | 142/211 [1:26:07<29:09, 25.36s/batch, loss=12.252806]Training:  68%|██████▊   | 143/211 [1:26:07<21:10, 18.69s/batch, loss=12.252806]Training:  68%|██████▊   | 143/211 [1:28:03<21:10, 18.69s/batch, loss=12.872137]Training:  68%|██████▊   | 144/211 [1:28:04<53:56, 48.30s/batch, loss=12.872137]Training:  68%|██████▊   | 144/211 [1:28:07<53:56, 48.30s/batch, loss=12.644191]Training:  69%|██████▊   | 145/211 [1:28:07<38:13, 34.75s/batch, loss=12.644191]Training:  69%|██████▊   | 145/211 [1:28:15<38:13, 34.75s/batch, loss=12.489170]Training:  69%|██████▉   | 146/211 [1:28:15<29:00, 26.78s/batch, loss=12.489170]Training:  69%|██████▉   | 146/211 [1:28:19<29:00, 26.78s/batch, loss=12.251558]Training:  70%|██████▉   | 147/211 [1:28:19<20:59, 19.68s/batch, loss=12.251558]Training:  70%|██████▉   | 147/211 [1:30:16<20:59, 19.68s/batch, loss=12.662465]Training:  70%|███████   | 148/211 [1:30:16<51:19, 48.88s/batch, loss=12.662465]Training:  70%|███████   | 148/211 [1:30:19<51:19, 48.88s/batch, loss=12.847248]Training:  71%|███████   | 149/211 [1:30:19<36:28, 35.31s/batch, loss=12.847248]Training:  71%|███████   | 149/211 [1:30:23<36:28, 35.31s/batch, loss=12.635115]Training:  71%|███████   | 150/211 [1:30:23<26:15, 25.83s/batch, loss=12.635115]Training:  71%|███████   | 150/211 [1:30:26<26:15, 25.83s/batch, loss=12.960988]Training:  72%|███████▏  | 151/211 [1:30:26<19:01, 19.02s/batch, loss=12.960988]Training:  72%|███████▏  | 151/211 [1:32:21<19:01, 19.02s/batch, loss=12.838714]Training:  72%|███████▏  | 152/211 [1:32:21<47:00, 47.81s/batch, loss=12.838714]Training:  72%|███████▏  | 152/211 [1:32:25<47:00, 47.81s/batch, loss=12.638191]Training:  73%|███████▎  | 153/211 [1:32:25<33:25, 34.57s/batch, loss=12.638191]Training:  73%|███████▎  | 153/211 [1:32:28<33:25, 34.57s/batch, loss=12.394959]Training:  73%|███████▎  | 154/211 [1:32:28<23:52, 25.12s/batch, loss=12.394959]Training:  73%|███████▎  | 154/211 [1:32:31<23:52, 25.12s/batch, loss=12.752146]Training:  73%|███████▎  | 155/211 [1:32:31<17:16, 18.51s/batch, loss=12.752146]Training:  73%|███████▎  | 155/211 [1:34:13<17:16, 18.51s/batch, loss=12.129255]Training:  74%|███████▍  | 156/211 [1:34:13<40:00, 43.65s/batch, loss=12.129255]Training:  74%|███████▍  | 156/211 [1:34:16<40:00, 43.65s/batch, loss=12.765225]Training:  74%|███████▍  | 157/211 [1:34:16<28:19, 31.48s/batch, loss=12.765225]Training:  74%|███████▍  | 157/211 [1:34:40<28:19, 31.48s/batch, loss=13.174829]Training:  75%|███████▍  | 158/211 [1:34:40<25:44, 29.14s/batch, loss=13.174829]Training:  75%|███████▍  | 158/211 [1:34:43<25:44, 29.14s/batch, loss=12.467567]Training:  75%|███████▌  | 159/211 [1:34:43<18:29, 21.33s/batch, loss=12.467567]Training:  75%|███████▌  | 159/211 [1:36:40<18:29, 21.33s/batch, loss=12.939703]Training:  76%|███████▌  | 160/211 [1:36:41<42:38, 50.16s/batch, loss=12.939703]Training:  76%|███████▌  | 160/211 [1:36:44<42:38, 50.16s/batch, loss=12.306490]Training:  76%|███████▋  | 161/211 [1:36:44<30:02, 36.05s/batch, loss=12.306490]Training:  76%|███████▋  | 161/211 [1:36:53<30:02, 36.05s/batch, loss=12.610880]Training:  77%|███████▋  | 162/211 [1:36:53<22:50, 27.97s/batch, loss=12.610880]Training:  77%|███████▋  | 162/211 [1:36:56<22:50, 27.97s/batch, loss=12.020844]Training:  77%|███████▋  | 163/211 [1:36:56<16:24, 20.51s/batch, loss=12.020844]Training:  77%|███████▋  | 163/211 [1:38:45<16:24, 20.51s/batch, loss=12.867880]Training:  78%|███████▊  | 164/211 [1:38:46<37:04, 47.34s/batch, loss=12.867880]Training:  78%|███████▊  | 164/211 [1:38:49<37:04, 47.34s/batch, loss=11.860991]Training:  78%|███████▊  | 165/211 [1:38:49<26:08, 34.09s/batch, loss=11.860991]Training:  78%|███████▊  | 165/211 [1:39:23<26:08, 34.09s/batch, loss=11.835800]Training:  79%|███████▊  | 166/211 [1:39:23<25:30, 34.01s/batch, loss=11.835800]Training:  79%|███████▊  | 166/211 [1:39:26<25:30, 34.01s/batch, loss=12.297026]Training:  79%|███████▉  | 167/211 [1:39:26<18:08, 24.73s/batch, loss=12.297026]Training:  79%|███████▉  | 167/211 [1:40:49<18:08, 24.73s/batch, loss=12.923239]Training:  80%|███████▉  | 168/211 [1:40:49<30:20, 42.34s/batch, loss=12.923239]Training:  80%|███████▉  | 168/211 [1:40:52<30:20, 42.34s/batch, loss=11.659862]Training:  80%|████████  | 169/211 [1:40:52<21:25, 30.60s/batch, loss=11.659862]Training:  80%|████████  | 169/211 [1:41:53<21:25, 30.60s/batch, loss=12.511932]Training:  81%|████████  | 170/211 [1:41:53<27:08, 39.71s/batch, loss=12.511932]Training:  81%|████████  | 170/211 [1:41:57<27:08, 39.71s/batch, loss=12.351311]Training:  81%|████████  | 171/211 [1:41:57<19:10, 28.77s/batch, loss=12.351311]Training:  81%|████████  | 171/211 [1:42:51<19:10, 28.77s/batch, loss=12.430757]Training:  82%|████████▏ | 172/211 [1:42:52<23:49, 36.66s/batch, loss=12.430757]Training:  82%|████████▏ | 172/211 [1:42:55<23:49, 36.66s/batch, loss=12.239437]Training:  82%|████████▏ | 173/211 [1:42:55<16:50, 26.58s/batch, loss=12.239437]Training:  82%|████████▏ | 173/211 [1:44:07<16:50, 26.58s/batch, loss=12.087990]Training:  82%|████████▏ | 174/211 [1:44:07<24:53, 40.37s/batch, loss=12.087990]Training:  82%|████████▏ | 174/211 [1:44:11<24:53, 40.37s/batch, loss=12.123922]Training:  83%|████████▎ | 175/211 [1:44:11<17:32, 29.23s/batch, loss=12.123922]Training:  83%|████████▎ | 175/211 [1:45:02<17:32, 29.23s/batch, loss=12.774002]Training:  83%|████████▎ | 176/211 [1:45:02<20:50, 35.74s/batch, loss=12.774002]Training:  83%|████████▎ | 176/211 [1:45:05<20:50, 35.74s/batch, loss=12.162026]Training:  84%|████████▍ | 177/211 [1:45:05<14:43, 25.98s/batch, loss=12.162026]Training:  84%|████████▍ | 177/211 [1:46:23<14:43, 25.98s/batch, loss=11.977199]Training:  84%|████████▍ | 178/211 [1:46:23<22:58, 41.76s/batch, loss=11.977199]Training:  84%|████████▍ | 178/211 [1:46:27<22:58, 41.76s/batch, loss=11.908450]Training:  85%|████████▍ | 179/211 [1:46:27<16:06, 30.20s/batch, loss=11.908450]Training:  85%|████████▍ | 179/211 [1:46:54<16:06, 30.20s/batch, loss=12.714935]Training:  85%|████████▌ | 180/211 [1:46:54<15:10, 29.37s/batch, loss=12.714935]Training:  85%|████████▌ | 180/211 [1:47:01<15:10, 29.37s/batch, loss=12.045531]Training:  86%|████████▌ | 181/211 [1:47:01<11:21, 22.71s/batch, loss=12.045531]Training:  86%|████████▌ | 181/211 [1:48:27<11:21, 22.71s/batch, loss=12.419104]Training:  86%|████████▋ | 182/211 [1:48:27<20:07, 41.63s/batch, loss=12.419104]Training:  86%|████████▋ | 182/211 [1:48:30<20:07, 41.63s/batch, loss=11.587078]Training:  87%|████████▋ | 183/211 [1:48:30<14:03, 30.12s/batch, loss=11.587078]Training:  87%|████████▋ | 183/211 [1:49:16<14:03, 30.12s/batch, loss=12.577895]Training:  87%|████████▋ | 184/211 [1:49:16<15:36, 34.69s/batch, loss=12.577895]Training:  87%|████████▋ | 184/211 [1:49:19<15:36, 34.69s/batch, loss=12.471392]Training:  88%|████████▊ | 185/211 [1:49:19<10:55, 25.21s/batch, loss=12.471392]Training:  88%|████████▊ | 185/211 [1:50:37<10:55, 25.21s/batch, loss=12.635282]Training:  88%|████████▊ | 186/211 [1:50:37<17:11, 41.26s/batch, loss=12.635282]Training:  88%|████████▊ | 186/211 [1:50:40<17:11, 41.26s/batch, loss=12.657551]Training:  89%|████████▊ | 187/211 [1:50:40<11:55, 29.81s/batch, loss=12.657551]Training:  89%|████████▊ | 187/211 [1:51:26<11:55, 29.81s/batch, loss=12.332255]Training:  89%|████████▉ | 188/211 [1:51:26<13:11, 34.43s/batch, loss=12.332255]Training:  89%|████████▉ | 188/211 [1:51:41<13:11, 34.43s/batch, loss=12.123341]Training:  90%|████████▉ | 189/211 [1:51:41<10:32, 28.75s/batch, loss=12.123341]Training:  90%|████████▉ | 189/211 [1:52:59<10:32, 28.75s/batch, loss=12.413526]Training:  90%|█████████ | 190/211 [1:52:59<15:14, 43.55s/batch, loss=12.413526]Training:  90%|█████████ | 190/211 [1:53:03<15:14, 43.55s/batch, loss=12.206710]Training:  91%|█████████ | 191/211 [1:53:03<10:29, 31.47s/batch, loss=12.206710]Training:  91%|█████████ | 191/211 [1:53:24<10:29, 31.47s/batch, loss=12.349981]Training:  91%|█████████ | 192/211 [1:53:24<09:00, 28.43s/batch, loss=12.349981]Training:  91%|█████████ | 192/211 [1:53:50<09:00, 28.43s/batch, loss=11.915796]Training:  91%|█████████▏| 193/211 [1:53:50<08:20, 27.82s/batch, loss=11.915796]Training:  91%|█████████▏| 193/211 [1:55:18<08:20, 27.82s/batch, loss=12.020541]Training:  92%|█████████▏| 194/211 [1:55:18<12:57, 45.74s/batch, loss=12.020541]Training:  92%|█████████▏| 194/211 [1:55:21<12:57, 45.74s/batch, loss=12.145744]Training:  92%|█████████▏| 195/211 [1:55:21<08:47, 32.96s/batch, loss=12.145744]Training:  92%|█████████▏| 195/211 [1:55:33<08:47, 32.96s/batch, loss=11.454069]Training:  93%|█████████▎| 196/211 [1:55:33<06:41, 26.74s/batch, loss=11.454069]Training:  93%|█████████▎| 196/211 [1:56:11<06:41, 26.74s/batch, loss=12.677772]Training:  93%|█████████▎| 197/211 [1:56:11<07:01, 30.12s/batch, loss=12.677772]Training:  93%|█████████▎| 197/211 [1:57:29<07:01, 30.12s/batch, loss=12.151428]Training:  94%|█████████▍| 198/211 [1:57:29<09:39, 44.54s/batch, loss=12.151428]Training:  94%|█████████▍| 198/211 [1:57:33<09:39, 44.54s/batch, loss=12.184155]Training:  94%|█████████▍| 199/211 [1:57:33<06:25, 32.13s/batch, loss=12.184155]Training:  94%|█████████▍| 199/211 [1:57:43<06:25, 32.13s/batch, loss=11.934402]Training:  95%|█████████▍| 200/211 [1:57:43<04:43, 25.77s/batch, loss=11.934402]Training:  95%|█████████▍| 200/211 [1:58:24<04:43, 25.77s/batch, loss=12.495811]Training:  95%|█████████▌| 201/211 [1:58:24<05:02, 30.24s/batch, loss=12.495811]Training:  95%|█████████▌| 201/211 [1:59:39<05:02, 30.24s/batch, loss=12.764337]Training:  96%|█████████▌| 202/211 [1:59:39<06:33, 43.75s/batch, loss=12.764337]Training:  96%|█████████▌| 202/211 [1:59:52<06:33, 43.75s/batch, loss=12.548659]Training:  96%|█████████▌| 203/211 [1:59:52<04:35, 34.38s/batch, loss=12.548659]Training:  96%|█████████▌| 203/211 [2:00:14<04:35, 34.38s/batch, loss=12.381507]Training:  97%|█████████▋| 204/211 [2:00:14<03:34, 30.60s/batch, loss=12.381507]Training:  97%|█████████▋| 204/211 [2:00:43<03:34, 30.60s/batch, loss=12.277175]Training:  97%|█████████▋| 205/211 [2:00:43<03:01, 30.23s/batch, loss=12.277175]Training:  97%|█████████▋| 205/211 [2:01:42<03:01, 30.23s/batch, loss=11.772260]Training:  98%|█████████▊| 206/211 [2:01:43<03:15, 39.03s/batch, loss=11.772260]Training:  98%|█████████▊| 206/211 [2:01:46<03:15, 39.03s/batch, loss=11.892248]Training:  98%|█████████▊| 207/211 [2:01:46<01:52, 28.25s/batch, loss=11.892248]Training:  98%|█████████▊| 207/211 [2:01:59<01:52, 28.25s/batch, loss=12.343369]Training:  99%|█████████▊| 208/211 [2:01:59<01:11, 23.80s/batch, loss=12.343369]Training:  99%|█████████▊| 208/211 [2:02:22<01:11, 23.80s/batch, loss=12.381866]Training:  99%|█████████▉| 209/211 [2:02:22<00:46, 23.49s/batch, loss=12.381866]Training:  99%|█████████▉| 209/211 [2:02:51<00:46, 23.49s/batch, loss=12.001678]Training: 100%|█████████▉| 210/211 [2:02:51<00:25, 25.16s/batch, loss=12.001678]Training: 100%|█████████▉| 210/211 [2:02:53<00:25, 25.16s/batch, loss=12.613274]Training: 100%|██████████| 211/211 [2:02:53<00:00, 18.27s/batch, loss=12.613274]Training: 100%|██████████| 211/211 [2:02:54<00:00, 34.95s/batch, loss=12.613274]
Epoch 5, Train Loss: 13.0411, Val Loss: 12.1183
Training:   0%|          | 0/211 [00:00<?, ?batch/s]Training:   0%|          | 0/211 [01:48<?, ?batch/s, loss=11.884326]Training:   0%|          | 1/211 [01:48<6:20:16, 108.65s/batch, loss=11.884326]Training:   0%|          | 1/211 [02:08<6:20:16, 108.65s/batch, loss=11.838251]Training:   1%|          | 2/211 [02:08<3:16:46, 56.49s/batch, loss=11.838251] Training:   1%|          | 2/211 [02:11<3:16:46, 56.49s/batch, loss=12.014973]Training:   1%|▏         | 3/211 [02:11<1:51:18, 32.11s/batch, loss=12.014973]Training:   1%|▏         | 3/211 [02:14<1:51:18, 32.11s/batch, loss=11.528658]Training:   2%|▏         | 4/211 [02:14<1:11:18, 20.67s/batch, loss=11.528658]Training:   2%|▏         | 4/211 [03:50<1:11:18, 20.67s/batch, loss=12.652556]Training:   2%|▏         | 5/211 [03:51<2:44:43, 47.98s/batch, loss=12.652556]Training:   2%|▏         | 5/211 [04:11<2:44:43, 47.98s/batch, loss=12.176981]Training:   3%|▎         | 6/211 [04:11<2:12:12, 38.70s/batch, loss=12.176981]Training:   3%|▎         | 6/211 [04:15<2:12:12, 38.70s/batch, loss=12.271866]Training:   3%|▎         | 7/211 [04:15<1:32:11, 27.12s/batch, loss=12.271866]Training:   3%|▎         | 7/211 [04:18<1:32:11, 27.12s/batch, loss=11.687522]Training:   4%|▍         | 8/211 [04:18<1:05:52, 19.47s/batch, loss=11.687522]Training:   4%|▍         | 8/211 [05:47<1:05:52, 19.47s/batch, loss=12.185142]Training:   4%|▍         | 9/211 [05:47<2:19:06, 41.32s/batch, loss=12.185142]Training:   4%|▍         | 9/211 [06:09<2:19:06, 41.32s/batch, loss=11.809762]Training:   5%|▍         | 10/211 [06:09<1:58:08, 35.27s/batch, loss=11.809762]Training:   5%|▍         | 10/211 [06:12<1:58:08, 35.27s/batch, loss=12.072223]Training:   5%|▌         | 11/211 [06:12<1:24:44, 25.42s/batch, loss=12.072223]Training:   5%|▌         | 11/211 [06:17<1:24:44, 25.42s/batch, loss=11.966936]Training:   6%|▌         | 12/211 [06:17<1:03:24, 19.12s/batch, loss=11.966936]Training:   6%|▌         | 12/211 [07:57<1:03:24, 19.12s/batch, loss=12.769340]Training:   6%|▌         | 13/211 [07:57<2:24:01, 43.64s/batch, loss=12.769340]Training:   6%|▌         | 13/211 [08:17<2:24:01, 43.64s/batch, loss=12.531161]Training:   7%|▋         | 14/211 [08:17<2:00:07, 36.59s/batch, loss=12.531161]Training:   7%|▋         | 14/211 [08:20<2:00:07, 36.59s/batch, loss=11.588546]Training:   7%|▋         | 15/211 [08:20<1:26:35, 26.51s/batch, loss=11.588546]Training:   7%|▋         | 15/211 [08:23<1:26:35, 26.51s/batch, loss=12.060272]Training:   8%|▊         | 16/211 [08:23<1:03:15, 19.47s/batch, loss=12.060272]Training:   8%|▊         | 16/211 [09:55<1:03:15, 19.47s/batch, loss=11.718862]Training:   8%|▊         | 17/211 [09:55<2:13:06, 41.17s/batch, loss=11.718862]Training:   8%|▊         | 17/211 [10:34<2:13:06, 41.17s/batch, loss=12.212900]Training:   9%|▊         | 18/211 [10:34<2:10:30, 40.57s/batch, loss=12.212900]Training:   9%|▊         | 18/211 [10:37<2:10:30, 40.57s/batch, loss=11.645424]Training:   9%|▉         | 19/211 [10:37<1:33:50, 29.32s/batch, loss=11.645424]Training:   9%|▉         | 19/211 [10:40<1:33:50, 29.32s/batch, loss=12.264278]Training:   9%|▉         | 20/211 [10:40<1:08:16, 21.45s/batch, loss=12.264278]Training:   9%|▉         | 20/211 [11:58<1:08:16, 21.45s/batch, loss=11.869353]Training:  10%|▉         | 21/211 [11:59<2:02:28, 38.68s/batch, loss=11.869353]Training:  10%|▉         | 21/211 [12:44<2:02:28, 38.68s/batch, loss=11.642440]Training:  10%|█         | 22/211 [12:44<2:07:10, 40.38s/batch, loss=11.642440]Training:  10%|█         | 22/211 [12:47<2:07:10, 40.38s/batch, loss=12.105231]Training:  11%|█         | 23/211 [12:47<1:31:29, 29.20s/batch, loss=12.105231]Training:  11%|█         | 23/211 [12:50<1:31:29, 29.20s/batch, loss=11.230229]Training:  11%|█▏        | 24/211 [12:50<1:06:37, 21.38s/batch, loss=11.230229]Training:  11%|█▏        | 24/211 [14:25<1:06:37, 21.38s/batch, loss=11.963401]Training:  12%|█▏        | 25/211 [14:25<2:15:02, 43.56s/batch, loss=11.963401]Training:  12%|█▏        | 25/211 [15:05<2:15:02, 43.56s/batch, loss=12.410954]Training:  12%|█▏        | 26/211 [15:05<2:10:49, 42.43s/batch, loss=12.410954]Training:  12%|█▏        | 26/211 [15:08<2:10:49, 42.43s/batch, loss=11.728863]Training:  13%|█▎        | 27/211 [15:08<1:33:56, 30.64s/batch, loss=11.728863]Training:  13%|█▎        | 27/211 [15:11<1:33:56, 30.64s/batch, loss=11.921347]Training:  13%|█▎        | 28/211 [15:11<1:08:15, 22.38s/batch, loss=11.921347]Training:  13%|█▎        | 28/211 [16:40<1:08:15, 22.38s/batch, loss=11.368607]Training:  14%|█▎        | 29/211 [16:40<2:08:45, 42.45s/batch, loss=11.368607]Training:  14%|█▎        | 29/211 [17:24<2:08:45, 42.45s/batch, loss=11.618090]Training:  14%|█▍        | 30/211 [17:24<2:08:47, 42.69s/batch, loss=11.618090]Training:  14%|█▍        | 30/211 [17:27<2:08:47, 42.69s/batch, loss=11.652484]Training:  15%|█▍        | 31/211 [17:27<1:32:27, 30.82s/batch, loss=11.652484]Training:  15%|█▍        | 31/211 [17:30<1:32:27, 30.82s/batch, loss=11.739204]Training:  15%|█▌        | 32/211 [17:30<1:07:17, 22.55s/batch, loss=11.739204]Training:  15%|█▌        | 32/211 [18:52<1:07:17, 22.55s/batch, loss=12.032880]Training:  16%|█▌        | 33/211 [18:53<2:00:53, 40.75s/batch, loss=12.032880]Training:  16%|█▌        | 33/211 [19:29<2:00:53, 40.75s/batch, loss=12.319113]Training:  16%|█▌        | 34/211 [19:29<1:56:09, 39.37s/batch, loss=12.319113]Training:  16%|█▌        | 34/211 [19:33<1:56:09, 39.37s/batch, loss=11.687398]Training:  17%|█▋        | 35/211 [19:33<1:23:34, 28.49s/batch, loss=11.687398]Training:  17%|█▋        | 35/211 [19:36<1:23:34, 28.49s/batch, loss=12.324168]Training:  17%|█▋        | 36/211 [19:36<1:00:51, 20.87s/batch, loss=12.324168]Training:  17%|█▋        | 36/211 [21:08<1:00:51, 20.87s/batch, loss=11.377200]Training:  18%|█▊        | 37/211 [21:08<2:02:41, 42.31s/batch, loss=11.377200]Training:  18%|█▊        | 37/211 [21:39<2:02:41, 42.31s/batch, loss=11.950375]Training:  18%|█▊        | 38/211 [21:39<1:51:56, 38.83s/batch, loss=11.950375]Training:  18%|█▊        | 38/211 [21:42<1:51:56, 38.83s/batch, loss=11.379649]Training:  18%|█▊        | 39/211 [21:42<1:20:33, 28.10s/batch, loss=11.379649]Training:  18%|█▊        | 39/211 [21:45<1:20:33, 28.10s/batch, loss=11.735027]Training:  19%|█▉        | 40/211 [21:45<58:44, 20.61s/batch, loss=11.735027]  Training:  19%|█▉        | 40/211 [23:16<58:44, 20.61s/batch, loss=11.513780]Training:  19%|█▉        | 41/211 [23:17<1:59:04, 42.03s/batch, loss=11.513780]Training:  19%|█▉        | 41/211 [23:51<1:59:04, 42.03s/batch, loss=11.721181]Training:  20%|█▉        | 42/211 [23:51<1:51:58, 39.75s/batch, loss=11.721181]Training:  20%|█▉        | 42/211 [23:54<1:51:58, 39.75s/batch, loss=12.191186]Training:  20%|██        | 43/211 [23:54<1:20:31, 28.76s/batch, loss=12.191186]Training:  20%|██        | 43/211 [23:57<1:20:31, 28.76s/batch, loss=12.898046]Training:  21%|██        | 44/211 [23:57<58:38, 21.07s/batch, loss=12.898046]  Training:  21%|██        | 44/211 [25:15<58:38, 21.07s/batch, loss=12.444612]Training:  21%|██▏       | 45/211 [25:15<1:45:01, 37.96s/batch, loss=12.444612]Training:  21%|██▏       | 45/211 [26:00<1:45:01, 37.96s/batch, loss=11.877726]Training:  22%|██▏       | 46/211 [26:00<1:50:23, 40.14s/batch, loss=11.877726]Training:  22%|██▏       | 46/211 [26:03<1:50:23, 40.14s/batch, loss=11.743813]Training:  22%|██▏       | 47/211 [26:03<1:19:20, 29.03s/batch, loss=11.743813]Training:  22%|██▏       | 47/211 [26:06<1:19:20, 29.03s/batch, loss=12.145445]Training:  23%|██▎       | 48/211 [26:06<57:44, 21.26s/batch, loss=12.145445]  Training:  23%|██▎       | 48/211 [27:20<57:44, 21.26s/batch, loss=11.949488]Training:  23%|██▎       | 49/211 [27:20<1:39:41, 36.92s/batch, loss=11.949488]Training:  23%|██▎       | 49/211 [28:10<1:39:41, 36.92s/batch, loss=11.239187]Training:  24%|██▎       | 50/211 [28:10<1:49:24, 40.77s/batch, loss=11.239187]Training:  24%|██▎       | 50/211 [28:13<1:49:24, 40.77s/batch, loss=12.178520]Training:  24%|██▍       | 51/211 [28:13<1:18:36, 29.48s/batch, loss=12.178520]Training:  24%|██▍       | 51/211 [28:16<1:18:36, 29.48s/batch, loss=12.475474]Training:  25%|██▍       | 52/211 [28:16<57:08, 21.56s/batch, loss=12.475474]  Training:  25%|██▍       | 52/211 [29:23<57:08, 21.56s/batch, loss=12.525961]Training:  25%|██▌       | 53/211 [29:23<1:32:50, 35.26s/batch, loss=12.525961]Training:  25%|██▌       | 53/211 [30:28<1:32:50, 35.26s/batch, loss=11.625758]Training:  26%|██▌       | 54/211 [30:28<1:55:48, 44.26s/batch, loss=11.625758]Training:  26%|██▌       | 54/211 [30:31<1:55:48, 44.26s/batch, loss=11.876513]Training:  26%|██▌       | 55/211 [30:31<1:22:59, 31.92s/batch, loss=11.876513]Training:  26%|██▌       | 55/211 [30:35<1:22:59, 31.92s/batch, loss=11.886198]Training:  27%|██▋       | 56/211 [30:35<1:00:09, 23.29s/batch, loss=11.886198]Training:  27%|██▋       | 56/211 [31:12<1:00:09, 23.29s/batch, loss=11.713346]Training:  27%|██▋       | 57/211 [31:12<1:11:01, 27.67s/batch, loss=11.713346]Training:  27%|██▋       | 57/211 [32:49<1:11:01, 27.67s/batch, loss=12.200702]Training:  27%|██▋       | 58/211 [32:49<2:03:30, 48.44s/batch, loss=12.200702]Training:  27%|██▋       | 58/211 [32:53<2:03:30, 48.44s/batch, loss=11.576966]Training:  28%|██▊       | 59/211 [32:53<1:28:19, 34.87s/batch, loss=11.576966]Training:  28%|██▊       | 59/211 [32:56<1:28:19, 34.87s/batch, loss=11.467394]Training:  28%|██▊       | 60/211 [32:56<1:03:46, 25.34s/batch, loss=11.467394]Training:  28%|██▊       | 60/211 [33:21<1:03:46, 25.34s/batch, loss=11.718361]Training:  29%|██▉       | 61/211 [33:21<1:03:24, 25.36s/batch, loss=11.718361]Training:  29%|██▉       | 61/211 [34:58<1:03:24, 25.36s/batch, loss=11.971971]Training:  29%|██▉       | 62/211 [34:58<1:56:24, 46.87s/batch, loss=11.971971]Training:  29%|██▉       | 62/211 [35:01<1:56:24, 46.87s/batch, loss=12.105606]Training:  30%|██▉       | 63/211 [35:01<1:23:13, 33.74s/batch, loss=12.105606]Training:  30%|██▉       | 63/211 [35:04<1:23:13, 33.74s/batch, loss=11.564466]Training:  30%|███       | 64/211 [35:04<1:00:10, 24.56s/batch, loss=11.564466]Training:  30%|███       | 64/211 [35:15<1:00:10, 24.56s/batch, loss=12.060591]Training:  31%|███       | 65/211 [35:15<49:50, 20.48s/batch, loss=12.060591]  Training:  31%|███       | 65/211 [37:13<49:50, 20.48s/batch, loss=11.678493]Training:  31%|███▏      | 66/211 [37:13<2:00:08, 49.72s/batch, loss=11.678493]Training:  31%|███▏      | 66/211 [37:16<2:00:08, 49.72s/batch, loss=11.490747]Training:  32%|███▏      | 67/211 [37:16<1:25:45, 35.73s/batch, loss=11.490747]Training:  32%|███▏      | 67/211 [37:20<1:25:45, 35.73s/batch, loss=11.270585]Training:  32%|███▏      | 68/211 [37:20<1:01:55, 25.98s/batch, loss=11.270585]Training:  32%|███▏      | 68/211 [37:23<1:01:55, 25.98s/batch, loss=11.802601]Training:  33%|███▎      | 69/211 [37:23<45:15, 19.12s/batch, loss=11.802601]  Training:  33%|███▎      | 69/211 [39:26<45:15, 19.12s/batch, loss=12.017593]Training:  33%|███▎      | 70/211 [39:27<1:58:47, 50.55s/batch, loss=12.017593]Training:  33%|███▎      | 70/211 [39:30<1:58:47, 50.55s/batch, loss=12.197013]Training:  34%|███▎      | 71/211 [39:30<1:24:45, 36.33s/batch, loss=12.197013]Training:  34%|███▎      | 71/211 [39:33<1:24:45, 36.33s/batch, loss=11.757542]Training:  34%|███▍      | 72/211 [39:33<1:01:06, 26.38s/batch, loss=11.757542]Training:  34%|███▍      | 72/211 [39:36<1:01:06, 26.38s/batch, loss=11.483887]Training:  35%|███▍      | 73/211 [39:36<44:41, 19.43s/batch, loss=11.483887]  Training:  35%|███▍      | 73/211 [41:11<44:41, 19.43s/batch, loss=11.875652]Training:  35%|███▌      | 74/211 [41:11<1:35:56, 42.01s/batch, loss=11.875652]Training:  35%|███▌      | 74/211 [41:14<1:35:56, 42.01s/batch, loss=11.553227]Training:  36%|███▌      | 75/211 [41:14<1:08:50, 30.37s/batch, loss=11.553227]Training:  36%|███▌      | 75/211 [41:17<1:08:50, 30.37s/batch, loss=11.897561]Training:  36%|███▌      | 76/211 [41:17<49:57, 22.21s/batch, loss=11.897561]  Training:  36%|███▌      | 76/211 [41:43<49:57, 22.21s/batch, loss=11.532049]Training:  36%|███▋      | 77/211 [41:43<52:09, 23.36s/batch, loss=11.532049]Training:  36%|███▋      | 77/211 [43:39<52:09, 23.36s/batch, loss=11.966677]Training:  37%|███▋      | 78/211 [43:40<1:53:39, 51.27s/batch, loss=11.966677]Training:  37%|███▋      | 78/211 [43:43<1:53:39, 51.27s/batch, loss=11.486616]Training:  37%|███▋      | 79/211 [43:43<1:21:01, 36.83s/batch, loss=11.486616]Training:  37%|███▋      | 79/211 [43:46<1:21:01, 36.83s/batch, loss=11.937021]Training:  38%|███▊      | 80/211 [43:46<58:16, 26.69s/batch, loss=11.937021]  Training:  38%|███▊      | 80/211 [44:03<58:16, 26.69s/batch, loss=11.406373]Training:  38%|███▊      | 81/211 [44:03<51:46, 23.90s/batch, loss=11.406373]Training:  38%|███▊      | 81/211 [45:46<51:46, 23.90s/batch, loss=11.893336]Training:  39%|███▉      | 82/211 [45:46<1:42:23, 47.62s/batch, loss=11.893336]Training:  39%|███▉      | 82/211 [45:49<1:42:23, 47.62s/batch, loss=11.512097]Training:  39%|███▉      | 83/211 [45:49<1:13:06, 34.27s/batch, loss=11.512097]Training:  39%|███▉      | 83/211 [45:52<1:13:06, 34.27s/batch, loss=11.729146]Training:  40%|███▉      | 84/211 [45:52<52:43, 24.91s/batch, loss=11.729146]  Training:  40%|███▉      | 84/211 [46:11<52:43, 24.91s/batch, loss=12.011607]Training:  40%|████      | 85/211 [46:11<48:18, 23.01s/batch, loss=12.011607]Training:  40%|████      | 85/211 [47:55<48:18, 23.01s/batch, loss=11.497390]Training:  41%|████      | 86/211 [47:55<1:38:53, 47.47s/batch, loss=11.497390]Training:  41%|████      | 86/211 [47:59<1:38:53, 47.47s/batch, loss=11.233444]Training:  41%|████      | 87/211 [47:59<1:10:36, 34.17s/batch, loss=11.233444]Training:  41%|████      | 87/211 [48:02<1:10:36, 34.17s/batch, loss=12.017100]Training:  42%|████▏     | 88/211 [48:02<50:56, 24.85s/batch, loss=12.017100]  Training:  42%|████▏     | 88/211 [48:05<50:56, 24.85s/batch, loss=11.651944]Training:  42%|████▏     | 89/211 [48:05<37:15, 18.32s/batch, loss=11.651944]Training:  42%|████▏     | 89/211 [50:01<37:15, 18.32s/batch, loss=11.181351]Training:  43%|████▎     | 90/211 [50:02<1:36:50, 48.02s/batch, loss=11.181351]Training:  43%|████▎     | 90/211 [50:05<1:36:50, 48.02s/batch, loss=11.532801]Training:  43%|████▎     | 91/211 [50:05<1:09:06, 34.55s/batch, loss=11.532801]Training:  43%|████▎     | 91/211 [50:08<1:09:06, 34.55s/batch, loss=12.176994]Training:  44%|████▎     | 92/211 [50:08<49:48, 25.12s/batch, loss=12.176994]  Training:  44%|████▎     | 92/211 [50:11<49:48, 25.12s/batch, loss=11.946769]Training:  44%|████▍     | 93/211 [50:11<36:24, 18.52s/batch, loss=11.946769]Training:  44%|████▍     | 93/211 [52:03<36:24, 18.52s/batch, loss=11.262993]Training:  45%|████▍     | 94/211 [52:03<1:30:41, 46.51s/batch, loss=11.262993]Training:  45%|████▍     | 94/211 [52:06<1:30:41, 46.51s/batch, loss=11.036667]Training:  45%|████▌     | 95/211 [52:06<1:04:46, 33.50s/batch, loss=11.036667]Training:  45%|████▌     | 95/211 [52:10<1:04:46, 33.50s/batch, loss=11.558534]Training:  45%|████▌     | 96/211 [52:10<46:46, 24.40s/batch, loss=11.558534]  Training:  45%|████▌     | 96/211 [52:14<46:46, 24.40s/batch, loss=11.921917]Training:  46%|████▌     | 97/211 [52:14<35:04, 18.46s/batch, loss=11.921917]Training:  46%|████▌     | 97/211 [53:56<35:04, 18.46s/batch, loss=11.519972]Training:  46%|████▋     | 98/211 [53:56<1:22:07, 43.60s/batch, loss=11.519972]Training:  46%|████▋     | 98/211 [54:00<1:22:07, 43.60s/batch, loss=12.012054]Training:  47%|████▋     | 99/211 [54:00<58:46, 31.49s/batch, loss=12.012054]  Training:  47%|████▋     | 99/211 [54:03<58:46, 31.49s/batch, loss=11.339242]Training:  47%|████▋     | 100/211 [54:03<42:30, 22.97s/batch, loss=11.339242]Training:  47%|████▋     | 100/211 [54:26<42:30, 22.97s/batch, loss=11.624974]Training:  48%|████▊     | 101/211 [54:26<42:26, 23.15s/batch, loss=11.624974]Training:  48%|████▊     | 101/211 [56:02<42:26, 23.15s/batch, loss=12.045027]Training:  48%|████▊     | 102/211 [56:02<1:21:35, 44.91s/batch, loss=12.045027]Training:  48%|████▊     | 102/211 [56:05<1:21:35, 44.91s/batch, loss=11.352091]Training:  49%|████▉     | 103/211 [56:05<58:16, 32.38s/batch, loss=11.352091]  Training:  49%|████▉     | 103/211 [56:08<58:16, 32.38s/batch, loss=11.424429]Training:  49%|████▉     | 104/211 [56:08<42:06, 23.61s/batch, loss=11.424429]Training:  49%|████▉     | 104/211 [56:27<42:06, 23.61s/batch, loss=12.110579]Training:  50%|████▉     | 105/211 [56:27<39:05, 22.13s/batch, loss=12.110579]Training:  50%|████▉     | 105/211 [58:14<39:05, 22.13s/batch, loss=11.236876]Training:  50%|█████     | 106/211 [58:14<1:23:27, 47.69s/batch, loss=11.236876]Training:  50%|█████     | 106/211 [58:17<1:23:27, 47.69s/batch, loss=11.406856]Training:  51%|█████     | 107/211 [58:17<59:28, 34.31s/batch, loss=11.406856]  Training:  51%|█████     | 107/211 [58:20<59:28, 34.31s/batch, loss=11.697897]Training:  51%|█████     | 108/211 [58:20<42:49, 24.95s/batch, loss=11.697897]Training:  51%|█████     | 108/211 [58:45<42:49, 24.95s/batch, loss=11.261371]Training:  52%|█████▏    | 109/211 [58:45<41:59, 24.70s/batch, loss=11.261371]Training:  52%|█████▏    | 109/211 [1:00:17<41:59, 24.70s/batch, loss=11.040027]Training:  52%|█████▏    | 110/211 [1:00:17<1:15:59, 45.15s/batch, loss=11.040027]Training:  52%|█████▏    | 110/211 [1:00:20<1:15:59, 45.15s/batch, loss=11.522923]Training:  53%|█████▎    | 111/211 [1:00:20<54:11, 32.51s/batch, loss=11.522923]  Training:  53%|█████▎    | 111/211 [1:00:24<54:11, 32.51s/batch, loss=11.699363]Training:  53%|█████▎    | 112/211 [1:00:24<39:05, 23.69s/batch, loss=11.699363]Training:  53%|█████▎    | 112/211 [1:00:56<39:05, 23.69s/batch, loss=11.522559]Training:  54%|█████▎    | 113/211 [1:00:56<42:52, 26.25s/batch, loss=11.522559]Training:  54%|█████▎    | 113/211 [1:02:21<42:52, 26.25s/batch, loss=11.827498]Training:  54%|█████▍    | 114/211 [1:02:22<1:11:29, 44.22s/batch, loss=11.827498]Training:  54%|█████▍    | 114/211 [1:02:25<1:11:29, 44.22s/batch, loss=11.377501]Training:  55%|█████▍    | 115/211 [1:02:25<51:03, 31.91s/batch, loss=11.377501]  Training:  55%|█████▍    | 115/211 [1:02:28<51:03, 31.91s/batch, loss=11.610712]Training:  55%|█████▍    | 116/211 [1:02:28<36:50, 23.26s/batch, loss=11.610712]Training:  55%|█████▍    | 116/211 [1:03:07<36:50, 23.26s/batch, loss=11.595405]Training:  55%|█████▌    | 117/211 [1:03:07<43:46, 27.95s/batch, loss=11.595405]Training:  55%|█████▌    | 117/211 [1:04:38<43:46, 27.95s/batch, loss=11.661717]Training:  56%|█████▌    | 118/211 [1:04:39<1:12:55, 47.05s/batch, loss=11.661717]Training:  56%|█████▌    | 118/211 [1:04:42<1:12:55, 47.05s/batch, loss=11.825723]Training:  56%|█████▋    | 119/211 [1:04:42<51:55, 33.87s/batch, loss=11.825723]  Training:  56%|█████▋    | 119/211 [1:04:45<51:55, 33.87s/batch, loss=11.576121]Training:  57%|█████▋    | 120/211 [1:04:45<37:22, 24.64s/batch, loss=11.576121]Training:  57%|█████▋    | 120/211 [1:05:27<37:22, 24.64s/batch, loss=11.994842]Training:  57%|█████▋    | 121/211 [1:05:27<44:54, 29.94s/batch, loss=11.994842]Training:  57%|█████▋    | 121/211 [1:06:48<44:54, 29.94s/batch, loss=11.065117]Training:  58%|█████▊    | 122/211 [1:06:48<1:07:08, 45.26s/batch, loss=11.065117]Training:  58%|█████▊    | 122/211 [1:06:54<1:07:08, 45.26s/batch, loss=11.678302]Training:  58%|█████▊    | 123/211 [1:06:54<48:56, 33.37s/batch, loss=11.678302]  Training:  58%|█████▊    | 123/211 [1:06:57<48:56, 33.37s/batch, loss=12.030625]Training:  59%|█████▉    | 124/211 [1:06:57<35:14, 24.30s/batch, loss=12.030625]Training:  59%|█████▉    | 124/211 [1:07:24<35:14, 24.30s/batch, loss=11.289519]Training:  59%|█████▉    | 125/211 [1:07:24<35:59, 25.11s/batch, loss=11.289519]Training:  59%|█████▉    | 125/211 [1:08:55<35:59, 25.11s/batch, loss=10.974037]Training:  60%|█████▉    | 126/211 [1:08:56<1:03:47, 45.02s/batch, loss=10.974037]Training:  60%|█████▉    | 126/211 [1:08:59<1:03:47, 45.02s/batch, loss=11.431548]Training:  60%|██████    | 127/211 [1:08:59<45:29, 32.49s/batch, loss=11.431548]  Training:  60%|██████    | 127/211 [1:09:02<45:29, 32.49s/batch, loss=11.633590]Training:  61%|██████    | 128/211 [1:09:02<32:46, 23.69s/batch, loss=11.633590]Training:  61%|██████    | 128/211 [1:09:37<32:46, 23.69s/batch, loss=11.128379]Training:  61%|██████    | 129/211 [1:09:37<36:56, 27.03s/batch, loss=11.128379]Training:  61%|██████    | 129/211 [1:10:53<36:56, 27.03s/batch, loss=11.139198]Training:  62%|██████▏   | 130/211 [1:10:53<56:37, 41.94s/batch, loss=11.139198]Training:  62%|██████▏   | 130/211 [1:11:00<56:37, 41.94s/batch, loss=10.440722]Training:  62%|██████▏   | 131/211 [1:11:00<41:42, 31.29s/batch, loss=10.440722]Training:  62%|██████▏   | 131/211 [1:11:03<41:42, 31.29s/batch, loss=11.257484]Training:  63%|██████▎   | 132/211 [1:11:03<30:04, 22.85s/batch, loss=11.257484]Training:  63%|██████▎   | 132/211 [1:11:56<30:04, 22.85s/batch, loss=11.420765]Training:  63%|██████▎   | 133/211 [1:11:56<41:33, 31.97s/batch, loss=11.420765]Training:  63%|██████▎   | 133/211 [1:13:06<41:33, 31.97s/batch, loss=11.611464]Training:  64%|██████▎   | 134/211 [1:13:06<55:22, 43.15s/batch, loss=11.611464]Training:  64%|██████▎   | 134/211 [1:13:22<55:22, 43.15s/batch, loss=10.994874]Training:  64%|██████▍   | 135/211 [1:13:22<44:22, 35.04s/batch, loss=10.994874]Training:  64%|██████▍   | 135/211 [1:13:25<44:22, 35.04s/batch, loss=11.663465]Training:  64%|██████▍   | 136/211 [1:13:25<31:50, 25.47s/batch, loss=11.663465]Training:  64%|██████▍   | 136/211 [1:14:11<31:50, 25.47s/batch, loss=11.362642]Training:  65%|██████▍   | 137/211 [1:14:12<39:34, 32.09s/batch, loss=11.362642]Training:  65%|██████▍   | 137/211 [1:15:10<39:34, 32.09s/batch, loss=11.082670]Training:  65%|██████▌   | 138/211 [1:15:10<48:23, 39.78s/batch, loss=11.082670]Training:  65%|██████▌   | 138/211 [1:15:29<48:23, 39.78s/batch, loss=11.366470]Training:  66%|██████▌   | 139/211 [1:15:29<40:12, 33.51s/batch, loss=11.366470]Training:  66%|██████▌   | 139/211 [1:15:32<40:12, 33.51s/batch, loss=11.796117]Training:  66%|██████▋   | 140/211 [1:15:32<28:52, 24.40s/batch, loss=11.796117]Training:  66%|██████▋   | 140/211 [1:16:11<28:52, 24.40s/batch, loss=11.403597]Training:  67%|██████▋   | 141/211 [1:16:11<33:39, 28.85s/batch, loss=11.403597]Training:  67%|██████▋   | 141/211 [1:17:18<33:39, 28.85s/batch, loss=11.607214]Training:  67%|██████▋   | 142/211 [1:17:18<46:08, 40.13s/batch, loss=11.607214]Training:  67%|██████▋   | 142/211 [1:17:41<46:08, 40.13s/batch, loss=11.532661]Training:  68%|██████▊   | 143/211 [1:17:41<39:37, 34.97s/batch, loss=11.532661]Training:  68%|██████▊   | 143/211 [1:17:44<39:37, 34.97s/batch, loss=10.700894]Training:  68%|██████▊   | 144/211 [1:17:44<28:23, 25.43s/batch, loss=10.700894]Training:  68%|██████▊   | 144/211 [1:18:26<28:23, 25.43s/batch, loss=11.798880]Training:  69%|██████▊   | 145/211 [1:18:27<33:44, 30.67s/batch, loss=11.798880]Training:  69%|██████▊   | 145/211 [1:19:30<33:44, 30.67s/batch, loss=11.098841]Training:  69%|██████▉   | 146/211 [1:19:30<43:41, 40.33s/batch, loss=11.098841]Training:  69%|██████▉   | 146/211 [1:19:47<43:41, 40.33s/batch, loss=11.707260]Training:  70%|██████▉   | 147/211 [1:19:47<35:45, 33.52s/batch, loss=11.707260]Training:  70%|██████▉   | 147/211 [1:19:50<35:45, 33.52s/batch, loss=11.151986]Training:  70%|███████   | 148/211 [1:19:50<25:37, 24.40s/batch, loss=11.151986]Training:  70%|███████   | 148/211 [1:20:27<25:37, 24.40s/batch, loss=11.663796]Training:  71%|███████   | 149/211 [1:20:28<29:14, 28.29s/batch, loss=11.663796]Training:  71%|███████   | 149/211 [1:21:38<29:14, 28.29s/batch, loss=11.259920]Training:  71%|███████   | 150/211 [1:21:38<41:39, 40.98s/batch, loss=11.259920]Training:  71%|███████   | 150/211 [1:22:21<41:39, 40.98s/batch, loss=11.432302]Training:  72%|███████▏  | 151/211 [1:22:21<41:37, 41.63s/batch, loss=11.432302]Training:  72%|███████▏  | 151/211 [1:22:25<41:37, 41.63s/batch, loss=11.324009]Training:  72%|███████▏  | 152/211 [1:22:25<29:33, 30.06s/batch, loss=11.324009]Training:  72%|███████▏  | 152/211 [1:22:45<29:33, 30.06s/batch, loss=11.277336]Training:  73%|███████▎  | 153/211 [1:22:45<26:08, 27.04s/batch, loss=11.277336]Training:  73%|███████▎  | 153/211 [1:23:52<26:08, 27.04s/batch, loss=11.084962]Training:  73%|███████▎  | 154/211 [1:23:52<37:14, 39.20s/batch, loss=11.084962]Training:  73%|███████▎  | 154/211 [1:24:48<37:14, 39.20s/batch, loss=11.097226]Training:  73%|███████▎  | 155/211 [1:24:48<41:22, 44.32s/batch, loss=11.097226]Training:  73%|███████▎  | 155/211 [1:24:51<41:22, 44.32s/batch, loss=11.370714]Training:  74%|███████▍  | 156/211 [1:24:51<29:17, 31.96s/batch, loss=11.370714]Training:  74%|███████▍  | 156/211 [1:25:14<29:17, 31.96s/batch, loss=11.252917]Training:  74%|███████▍  | 157/211 [1:25:14<26:04, 28.98s/batch, loss=11.252917]Training:  74%|███████▍  | 157/211 [1:26:15<26:04, 28.98s/batch, loss=11.290148]Training:  75%|███████▍  | 158/211 [1:26:15<34:08, 38.64s/batch, loss=11.290148]Training:  75%|███████▍  | 158/211 [1:27:06<34:08, 38.64s/batch, loss=11.408804]Training:  75%|███████▌  | 159/211 [1:27:06<36:48, 42.47s/batch, loss=11.408804]Training:  75%|███████▌  | 159/211 [1:27:09<36:48, 42.47s/batch, loss=11.366563]Training:  76%|███████▌  | 160/211 [1:27:09<26:05, 30.69s/batch, loss=11.366563]Training:  76%|███████▌  | 160/211 [1:27:31<26:05, 30.69s/batch, loss=11.438021]Training:  76%|███████▋  | 161/211 [1:27:31<23:24, 28.08s/batch, loss=11.438021]Training:  76%|███████▋  | 161/211 [1:28:33<23:24, 28.08s/batch, loss=11.719643]Training:  77%|███████▋  | 162/211 [1:28:34<31:27, 38.51s/batch, loss=11.719643]Training:  77%|███████▋  | 162/211 [1:29:32<31:27, 38.51s/batch, loss=10.875304]Training:  77%|███████▋  | 163/211 [1:29:32<35:33, 44.44s/batch, loss=10.875304]Training:  77%|███████▋  | 163/211 [1:29:36<35:33, 44.44s/batch, loss=11.558239]Training:  78%|███████▊  | 164/211 [1:29:36<25:06, 32.05s/batch, loss=11.558239]Training:  78%|███████▊  | 164/211 [1:29:53<25:06, 32.05s/batch, loss=11.427111]Training:  78%|███████▊  | 165/211 [1:29:53<21:17, 27.78s/batch, loss=11.427111]Training:  78%|███████▊  | 165/211 [1:31:01<21:17, 27.78s/batch, loss=11.541057]Training:  79%|███████▊  | 166/211 [1:31:01<29:42, 39.61s/batch, loss=11.541057]Training:  79%|███████▊  | 166/211 [1:31:45<29:42, 39.61s/batch, loss=11.525530]Training:  79%|███████▉  | 167/211 [1:31:46<30:15, 41.26s/batch, loss=11.525530]Training:  79%|███████▉  | 167/211 [1:31:49<30:15, 41.26s/batch, loss=10.655945]Training:  80%|███████▉  | 168/211 [1:31:49<21:22, 29.82s/batch, loss=10.655945]Training:  80%|███████▉  | 168/211 [1:32:07<21:22, 29.82s/batch, loss=11.278770]Training:  80%|████████  | 169/211 [1:32:07<18:27, 26.36s/batch, loss=11.278770]Training:  80%|████████  | 169/211 [1:33:12<18:27, 26.36s/batch, loss=11.306022]Training:  81%|████████  | 170/211 [1:33:13<26:08, 38.26s/batch, loss=11.306022]Training:  81%|████████  | 170/211 [1:33:50<26:08, 38.26s/batch, loss=11.414082]Training:  81%|████████  | 171/211 [1:33:50<25:07, 37.70s/batch, loss=11.414082]Training:  81%|████████  | 171/211 [1:33:53<25:07, 37.70s/batch, loss=11.478408]Training:  82%|████████▏ | 172/211 [1:33:53<17:45, 27.31s/batch, loss=11.478408]Training:  82%|████████▏ | 172/211 [1:34:12<17:45, 27.31s/batch, loss=11.310574]Training:  82%|████████▏ | 173/211 [1:34:12<15:51, 25.03s/batch, loss=11.310574]Training:  82%|████████▏ | 173/211 [1:35:21<15:51, 25.03s/batch, loss=11.088852]Training:  82%|████████▏ | 174/211 [1:35:21<23:29, 38.09s/batch, loss=11.088852]Training:  82%|████████▏ | 174/211 [1:35:56<23:29, 38.09s/batch, loss=10.834859]Training:  83%|████████▎ | 175/211 [1:35:56<22:20, 37.24s/batch, loss=10.834859]Training:  83%|████████▎ | 175/211 [1:35:59<22:20, 37.24s/batch, loss=11.312428]Training:  83%|████████▎ | 176/211 [1:35:59<15:45, 27.02s/batch, loss=11.312428]Training:  83%|████████▎ | 176/211 [1:36:36<15:45, 27.02s/batch, loss=11.000091]Training:  84%|████████▍ | 177/211 [1:36:36<16:52, 29.78s/batch, loss=11.000091]Training:  84%|████████▍ | 177/211 [1:37:40<16:52, 29.78s/batch, loss=11.024590]Training:  84%|████████▍ | 178/211 [1:37:40<22:08, 40.27s/batch, loss=11.024590]Training:  84%|████████▍ | 178/211 [1:38:11<22:08, 40.27s/batch, loss=11.198210]Training:  85%|████████▍ | 179/211 [1:38:11<20:00, 37.51s/batch, loss=11.198210]Training:  85%|████████▍ | 179/211 [1:38:14<20:00, 37.51s/batch, loss=11.211081]Training:  85%|████████▌ | 180/211 [1:38:14<14:03, 27.20s/batch, loss=11.211081]Training:  85%|████████▌ | 180/211 [1:38:41<14:03, 27.20s/batch, loss=11.568503]Training:  86%|████████▌ | 181/211 [1:38:41<13:26, 26.87s/batch, loss=11.568503]Training:  86%|████████▌ | 181/211 [1:39:52<13:26, 26.87s/batch, loss=11.033874]Training:  86%|████████▋ | 182/211 [1:39:53<19:31, 40.39s/batch, loss=11.033874]Training:  86%|████████▋ | 182/211 [1:40:33<19:31, 40.39s/batch, loss=11.299967]Training:  87%|████████▋ | 183/211 [1:40:33<18:49, 40.35s/batch, loss=11.299967]Training:  87%|████████▋ | 183/211 [1:40:36<18:49, 40.35s/batch, loss=11.023106]Training:  87%|████████▋ | 184/211 [1:40:36<13:08, 29.19s/batch, loss=11.023106]Training:  87%|████████▋ | 184/211 [1:40:48<13:08, 29.19s/batch, loss=11.228124]Training:  88%|████████▊ | 185/211 [1:40:48<10:29, 24.20s/batch, loss=11.228124]Training:  88%|████████▊ | 185/211 [1:42:03<10:29, 24.20s/batch, loss=11.171356]Training:  88%|████████▊ | 186/211 [1:42:04<16:26, 39.47s/batch, loss=11.171356]Training:  88%|████████▊ | 186/211 [1:42:50<16:26, 39.47s/batch, loss=11.381221]Training:  89%|████████▊ | 187/211 [1:42:50<16:37, 41.58s/batch, loss=11.381221]Training:  89%|████████▊ | 187/211 [1:42:53<16:37, 41.58s/batch, loss=11.160498]Training:  89%|████████▉ | 188/211 [1:42:53<11:30, 30.04s/batch, loss=11.160498]Training:  89%|████████▉ | 188/211 [1:42:56<11:30, 30.04s/batch, loss=10.627234]Training:  90%|████████▉ | 189/211 [1:42:56<08:03, 21.98s/batch, loss=10.627234]Training:  90%|████████▉ | 189/211 [1:44:00<08:03, 21.98s/batch, loss=11.022548]Training:  90%|█████████ | 190/211 [1:44:01<12:08, 34.68s/batch, loss=11.022548]Training:  90%|█████████ | 190/211 [1:44:53<12:08, 34.68s/batch, loss=11.088795]Training:  91%|█████████ | 191/211 [1:44:53<13:19, 39.97s/batch, loss=11.088795]Training:  91%|█████████ | 191/211 [1:44:56<13:19, 39.97s/batch, loss=11.147181]Training:  91%|█████████ | 192/211 [1:44:56<09:09, 28.90s/batch, loss=11.147181]Training:  91%|█████████ | 192/211 [1:45:01<09:09, 28.90s/batch, loss=11.437883]Training:  91%|█████████▏| 193/211 [1:45:01<06:28, 21.59s/batch, loss=11.437883]Training:  91%|█████████▏| 193/211 [1:46:09<06:28, 21.59s/batch, loss=11.200109]Training:  92%|█████████▏| 194/211 [1:46:09<10:07, 35.76s/batch, loss=11.200109]Training:  92%|█████████▏| 194/211 [1:47:10<10:07, 35.76s/batch, loss=10.790135]Training:  92%|█████████▏| 195/211 [1:47:10<11:31, 43.23s/batch, loss=10.790135]Training:  92%|█████████▏| 195/211 [1:47:13<11:31, 43.23s/batch, loss=10.881967]Training:  93%|█████████▎| 196/211 [1:47:13<07:48, 31.22s/batch, loss=10.881967]Training:  93%|█████████▎| 196/211 [1:47:16<07:48, 31.22s/batch, loss=10.930118]Training:  93%|█████████▎| 197/211 [1:47:16<05:19, 22.80s/batch, loss=10.930118]Training:  93%|█████████▎| 197/211 [1:48:10<05:19, 22.80s/batch, loss=11.209287]Training:  94%|█████████▍| 198/211 [1:48:10<06:57, 32.08s/batch, loss=11.209287]Training:  94%|█████████▍| 198/211 [1:49:25<06:57, 32.08s/batch, loss=10.799294]Training:  94%|█████████▍| 199/211 [1:49:25<09:00, 45.01s/batch, loss=10.799294]Training:  94%|█████████▍| 199/211 [1:49:29<09:00, 45.01s/batch, loss=10.859389]Training:  95%|█████████▍| 200/211 [1:49:29<05:56, 32.45s/batch, loss=10.859389]Training:  95%|█████████▍| 200/211 [1:49:32<05:56, 32.45s/batch, loss=11.326362]Training:  95%|█████████▌| 201/211 [1:49:32<03:56, 23.65s/batch, loss=11.326362]Training:  95%|█████████▌| 201/211 [1:50:23<03:56, 23.65s/batch, loss=11.056284]Training:  96%|█████████▌| 202/211 [1:50:23<04:47, 31.94s/batch, loss=11.056284]Training:  96%|█████████▌| 202/211 [1:51:43<04:47, 31.94s/batch, loss=11.021432]Training:  96%|█████████▌| 203/211 [1:51:44<06:12, 46.56s/batch, loss=11.021432]Training:  96%|█████████▌| 203/211 [1:51:47<06:12, 46.56s/batch, loss=11.278795]Training:  97%|█████████▋| 204/211 [1:51:47<03:54, 33.52s/batch, loss=11.278795]Training:  97%|█████████▋| 204/211 [1:51:50<03:54, 33.52s/batch, loss=11.353040]Training:  97%|█████████▋| 205/211 [1:51:50<02:26, 24.39s/batch, loss=11.353040]Training:  97%|█████████▋| 205/211 [1:52:16<02:26, 24.39s/batch, loss=11.354726]Training:  98%|█████████▊| 206/211 [1:52:16<02:04, 24.81s/batch, loss=11.354726]Training:  98%|█████████▊| 206/211 [1:53:38<02:04, 24.81s/batch, loss=10.599566]Training:  98%|█████████▊| 207/211 [1:53:38<02:48, 42.12s/batch, loss=10.599566]Training:  98%|█████████▊| 207/211 [1:53:41<02:48, 42.12s/batch, loss=11.278738]Training:  99%|█████████▊| 208/211 [1:53:41<01:31, 30.43s/batch, loss=11.278738]Training:  99%|█████████▊| 208/211 [1:53:44<01:31, 30.43s/batch, loss=11.067266]Training:  99%|█████████▉| 209/211 [1:53:44<00:44, 22.23s/batch, loss=11.067266]Training:  99%|█████████▉| 209/211 [1:53:47<00:44, 22.23s/batch, loss=11.302033]Training: 100%|█████████▉| 210/211 [1:53:47<00:16, 16.49s/batch, loss=11.302033]Training: 100%|█████████▉| 210/211 [1:53:48<00:16, 16.49s/batch, loss=11.409948]Training: 100%|██████████| 211/211 [1:53:48<00:00, 11.78s/batch, loss=11.409948]Training: 100%|██████████| 211/211 [1:53:48<00:00, 32.36s/batch, loss=11.409948]
Epoch 6, Train Loss: 11.5632, Val Loss: 10.9970
Training:   0%|          | 0/211 [00:00<?, ?batch/s]Training:   0%|          | 0/211 [01:45<?, ?batch/s, loss=11.080186]Training:   0%|          | 1/211 [01:46<6:11:10, 106.05s/batch, loss=11.080186]Training:   0%|          | 1/211 [01:56<6:11:10, 106.05s/batch, loss=10.641666]Training:   1%|          | 2/211 [01:56<2:53:09, 49.71s/batch, loss=10.641666] Training:   1%|          | 2/211 [01:59<2:53:09, 49.71s/batch, loss=10.726352]Training:   1%|▏         | 3/211 [01:59<1:38:43, 28.48s/batch, loss=10.726352]Training:   1%|▏         | 3/211 [02:02<1:38:43, 28.48s/batch, loss=11.171024]Training:   2%|▏         | 4/211 [02:02<1:03:38, 18.45s/batch, loss=11.171024]Training:   2%|▏         | 4/211 [04:01<1:03:38, 18.45s/batch, loss=10.947094]Training:   2%|▏         | 5/211 [04:01<3:07:49, 54.71s/batch, loss=10.947094]Training:   2%|▏         | 5/211 [04:04<3:07:49, 54.71s/batch, loss=10.695154]Training:   3%|▎         | 6/211 [04:04<2:07:01, 37.18s/batch, loss=10.695154]Training:   3%|▎         | 6/211 [04:07<2:07:01, 37.18s/batch, loss=10.770377]Training:   3%|▎         | 7/211 [04:07<1:28:29, 26.03s/batch, loss=10.770377]Training:   3%|▎         | 7/211 [04:11<1:28:29, 26.03s/batch, loss=10.969433]Training:   4%|▍         | 8/211 [04:11<1:03:30, 18.77s/batch, loss=10.969433]Training:   4%|▍         | 8/211 [05:57<1:03:30, 18.77s/batch, loss=10.455679]Training:   4%|▍         | 9/211 [05:58<2:36:02, 46.35s/batch, loss=10.455679]Training:   4%|▍         | 9/211 [06:01<2:36:02, 46.35s/batch, loss=11.067009]Training:   5%|▍         | 10/211 [06:01<1:51:20, 33.24s/batch, loss=11.067009]Training:   5%|▍         | 10/211 [06:10<1:51:20, 33.24s/batch, loss=11.312447]Training:   5%|▌         | 11/211 [06:10<1:25:42, 25.71s/batch, loss=11.312447]Training:   5%|▌         | 11/211 [06:13<1:25:42, 25.71s/batch, loss=11.377097]Training:   6%|▌         | 12/211 [06:13<1:02:26, 18.83s/batch, loss=11.377097]Training:   6%|▌         | 12/211 [08:06<1:02:26, 18.83s/batch, loss=10.929238]Training:   6%|▌         | 13/211 [08:06<2:36:17, 47.36s/batch, loss=10.929238]Training:   6%|▌         | 13/211 [08:09<2:36:17, 47.36s/batch, loss=11.075148]Training:   7%|▋         | 14/211 [08:09<1:51:39, 34.01s/batch, loss=11.075148]Training:   7%|▋         | 14/211 [08:22<1:51:39, 34.01s/batch, loss=11.216410]Training:   7%|▋         | 15/211 [08:22<1:30:29, 27.70s/batch, loss=11.216410]Training:   7%|▋         | 15/211 [08:26<1:30:29, 27.70s/batch, loss=10.899982]Training:   8%|▊         | 16/211 [08:26<1:05:58, 20.30s/batch, loss=10.899982]Training:   8%|▊         | 16/211 [10:11<1:05:58, 20.30s/batch, loss=11.146081]Training:   8%|▊         | 17/211 [10:11<2:28:07, 45.81s/batch, loss=11.146081]Training:   8%|▊         | 17/211 [10:14<2:28:07, 45.81s/batch, loss=10.701466]Training:   9%|▊         | 18/211 [10:14<1:46:08, 33.00s/batch, loss=10.701466]Training:   9%|▊         | 18/211 [10:24<1:46:08, 33.00s/batch, loss=10.326279]Training:   9%|▉         | 19/211 [10:24<1:23:19, 26.04s/batch, loss=10.326279]Training:   9%|▉         | 19/211 [10:27<1:23:19, 26.04s/batch, loss=10.813519]Training:   9%|▉         | 20/211 [10:27<1:00:57, 19.15s/batch, loss=10.813519]Training:   9%|▉         | 20/211 [12:17<1:00:57, 19.15s/batch, loss=11.077714]Training:  10%|▉         | 21/211 [12:17<2:27:33, 46.60s/batch, loss=11.077714]Training:  10%|▉         | 21/211 [12:21<2:27:33, 46.60s/batch, loss=11.130255]Training:  10%|█         | 22/211 [12:21<1:45:47, 33.59s/batch, loss=11.130255]Training:  10%|█         | 22/211 [12:32<1:45:47, 33.59s/batch, loss=10.965155]Training:  11%|█         | 23/211 [12:32<1:24:44, 27.05s/batch, loss=10.965155]Training:  11%|█         | 23/211 [12:36<1:24:44, 27.05s/batch, loss=11.318423]Training:  11%|█▏        | 24/211 [12:36<1:01:56, 19.87s/batch, loss=11.318423]Training:  11%|█▏        | 24/211 [14:26<1:01:56, 19.87s/batch, loss=10.915415]Training:  12%|█▏        | 25/211 [14:26<2:26:20, 47.21s/batch, loss=10.915415]Training:  12%|█▏        | 25/211 [14:30<2:26:20, 47.21s/batch, loss=10.724347]Training:  12%|█▏        | 26/211 [14:30<1:44:48, 33.99s/batch, loss=10.724347]Training:  12%|█▏        | 26/211 [14:35<1:44:48, 33.99s/batch, loss=10.650043]Training:  13%|█▎        | 27/211 [14:35<1:18:05, 25.46s/batch, loss=10.650043]Training:  13%|█▎        | 27/211 [14:38<1:18:05, 25.46s/batch, loss=11.117308]Training:  13%|█▎        | 28/211 [14:38<57:13, 18.76s/batch, loss=11.117308]  Training:  13%|█▎        | 28/211 [16:30<57:13, 18.76s/batch, loss=11.017364]Training:  14%|█▎        | 29/211 [16:30<2:21:13, 46.56s/batch, loss=11.017364]Training:  14%|█▎        | 29/211 [16:33<2:21:13, 46.56s/batch, loss=10.649220]Training:  14%|█▍        | 30/211 [16:33<1:41:11, 33.55s/batch, loss=10.649220]Training:  14%|█▍        | 30/211 [16:36<1:41:11, 33.55s/batch, loss=10.439708]Training:  15%|█▍        | 31/211 [16:36<1:13:14, 24.41s/batch, loss=10.439708]Training:  15%|█▍        | 31/211 [16:39<1:13:14, 24.41s/batch, loss=10.820501]Training:  15%|█▌        | 32/211 [16:39<53:48, 18.03s/batch, loss=10.820501]  Training:  15%|█▌        | 32/211 [18:51<53:48, 18.03s/batch, loss=11.003043]Training:  16%|█▌        | 33/211 [18:52<2:35:19, 52.35s/batch, loss=11.003043]Training:  16%|█▌        | 33/211 [18:55<2:35:19, 52.35s/batch, loss=10.843165]Training:  16%|█▌        | 34/211 [18:55<1:50:53, 37.59s/batch, loss=10.843165]Training:  16%|█▌        | 34/211 [18:58<1:50:53, 37.59s/batch, loss=10.536246]Training:  17%|█▋        | 35/211 [18:58<1:20:03, 27.29s/batch, loss=10.536246]Training:  17%|█▋        | 35/211 [19:01<1:20:03, 27.29s/batch, loss=10.782025]Training:  17%|█▋        | 36/211 [19:01<58:27, 20.04s/batch, loss=10.782025]  Training:  17%|█▋        | 36/211 [21:00<58:27, 20.04s/batch, loss=11.415882]Training:  18%|█▊        | 37/211 [21:01<2:24:34, 49.85s/batch, loss=11.415882]Training:  18%|█▊        | 37/211 [21:04<2:24:34, 49.85s/batch, loss=10.726053]Training:  18%|█▊        | 38/211 [21:04<1:43:26, 35.87s/batch, loss=10.726053]Training:  18%|█▊        | 38/211 [21:07<1:43:26, 35.87s/batch, loss=10.365799]Training:  18%|█▊        | 39/211 [21:07<1:14:36, 26.02s/batch, loss=10.365799]Training:  18%|█▊        | 39/211 [21:10<1:14:36, 26.02s/batch, loss=10.787765]Training:  19%|█▉        | 40/211 [21:10<54:34, 19.15s/batch, loss=10.787765]  Training:  19%|█▉        | 40/211 [22:50<54:34, 19.15s/batch, loss=10.690840]Training:  19%|█▉        | 41/211 [22:50<2:03:04, 43.44s/batch, loss=10.690840]Training:  19%|█▉        | 41/211 [22:53<2:03:04, 43.44s/batch, loss=10.750019]Training:  20%|█▉        | 42/211 [22:53<1:28:22, 31.38s/batch, loss=10.750019]Training:  20%|█▉        | 42/211 [22:56<1:28:22, 31.38s/batch, loss=10.613769]Training:  20%|██        | 43/211 [22:56<1:04:07, 22.90s/batch, loss=10.613769]Training:  20%|██        | 43/211 [23:00<1:04:07, 22.90s/batch, loss=10.732407]Training:  21%|██        | 44/211 [23:00<47:13, 16.97s/batch, loss=10.732407]  Training:  21%|██        | 44/211 [24:35<47:13, 16.97s/batch, loss=10.992570]Training:  21%|██▏       | 45/211 [24:36<1:52:33, 40.69s/batch, loss=10.992570]Training:  21%|██▏       | 45/211 [24:39<1:52:33, 40.69s/batch, loss=11.208819]Training:  22%|██▏       | 46/211 [24:39<1:20:57, 29.44s/batch, loss=11.208819]Training:  22%|██▏       | 46/211 [24:42<1:20:57, 29.44s/batch, loss=10.758499]Training:  22%|██▏       | 47/211 [24:42<58:59, 21.58s/batch, loss=10.758499]  Training:  22%|██▏       | 47/211 [24:45<58:59, 21.58s/batch, loss=10.831571]Training:  23%|██▎       | 48/211 [24:45<43:35, 16.05s/batch, loss=10.831571]Training:  23%|██▎       | 48/211 [26:33<43:35, 16.05s/batch, loss=10.656528]Training:  23%|██▎       | 49/211 [26:33<1:57:43, 43.60s/batch, loss=10.656528]Training:  23%|██▎       | 49/211 [26:36<1:57:43, 43.60s/batch, loss=11.065164]Training:  24%|██▎       | 50/211 [26:36<1:24:27, 31.47s/batch, loss=11.065164]Training:  24%|██▎       | 50/211 [26:39<1:24:27, 31.47s/batch, loss=10.585684]Training:  24%|██▍       | 51/211 [26:39<1:01:17, 22.98s/batch, loss=10.585684]Training:  24%|██▍       | 51/211 [26:43<1:01:17, 22.98s/batch, loss=11.256884]Training:  25%|██▍       | 52/211 [26:43<45:05, 17.02s/batch, loss=11.256884]  Training:  25%|██▍       | 52/211 [28:15<45:05, 17.02s/batch, loss=10.985691]Training:  25%|██▌       | 53/211 [28:15<1:44:38, 39.74s/batch, loss=10.985691]Training:  25%|██▌       | 53/211 [28:19<1:44:38, 39.74s/batch, loss=10.689068]Training:  26%|██▌       | 54/211 [28:19<1:15:20, 28.80s/batch, loss=10.689068]Training:  26%|██▌       | 54/211 [28:22<1:15:20, 28.80s/batch, loss=11.007672]Training:  26%|██▌       | 55/211 [28:22<54:57, 21.14s/batch, loss=11.007672]  Training:  26%|██▌       | 55/211 [28:25<54:57, 21.14s/batch, loss=10.889293]Training:  27%|██▋       | 56/211 [28:25<40:48, 15.80s/batch, loss=10.889293]Training:  27%|██▋       | 56/211 [29:50<40:48, 15.80s/batch, loss=11.246778]Training:  27%|██▋       | 57/211 [29:51<1:34:20, 36.76s/batch, loss=11.246778]Training:  27%|██▋       | 57/211 [29:54<1:34:20, 36.76s/batch, loss=11.169103]Training:  27%|██▋       | 58/211 [29:54<1:08:08, 26.72s/batch, loss=11.169103]Training:  27%|██▋       | 58/211 [29:57<1:08:08, 26.72s/batch, loss=10.926037]Training:  28%|██▊       | 59/211 [29:57<49:47, 19.65s/batch, loss=10.926037]  Training:  28%|██▊       | 59/211 [30:01<49:47, 19.65s/batch, loss=11.191396]Training:  28%|██▊       | 60/211 [30:01<37:05, 14.74s/batch, loss=11.191396]Training:  28%|██▊       | 60/211 [31:31<37:05, 14.74s/batch, loss=10.768972]Training:  29%|██▉       | 61/211 [31:32<1:34:30, 37.80s/batch, loss=10.768972]Training:  29%|██▉       | 61/211 [31:35<1:34:30, 37.80s/batch, loss=11.229372]Training:  29%|██▉       | 62/211 [31:35<1:08:03, 27.40s/batch, loss=11.229372]Training:  29%|██▉       | 62/211 [31:39<1:08:03, 27.40s/batch, loss=10.300441]Training:  30%|██▉       | 63/211 [31:39<49:45, 20.17s/batch, loss=10.300441]  Training:  30%|██▉       | 63/211 [31:42<49:45, 20.17s/batch, loss=10.502066]Training:  30%|███       | 64/211 [31:42<36:59, 15.10s/batch, loss=10.502066]Training:  30%|███       | 64/211 [33:13<36:59, 15.10s/batch, loss=10.803979]Training:  31%|███       | 65/211 [33:13<1:32:31, 38.02s/batch, loss=10.803979]Training:  31%|███       | 65/211 [33:17<1:32:31, 38.02s/batch, loss=10.728521]Training:  31%|███▏      | 66/211 [33:17<1:06:36, 27.56s/batch, loss=10.728521]Training:  31%|███▏      | 66/211 [33:20<1:06:36, 27.56s/batch, loss=11.235299]Training:  32%|███▏      | 67/211 [33:20<48:35, 20.25s/batch, loss=11.235299]  Training:  32%|███▏      | 67/211 [33:23<48:35, 20.25s/batch, loss=10.708024]Training:  32%|███▏      | 68/211 [33:23<36:01, 15.12s/batch, loss=10.708024]Training:  32%|███▏      | 68/211 [35:01<36:01, 15.12s/batch, loss=11.072321]Training:  33%|███▎      | 69/211 [35:01<1:34:59, 40.14s/batch, loss=11.072321]Training:  33%|███▎      | 69/211 [35:19<1:34:59, 40.14s/batch, loss=10.886773]Training:  33%|███▎      | 70/211 [35:19<1:18:10, 33.27s/batch, loss=10.886773]Training:  33%|███▎      | 70/211 [35:22<1:18:10, 33.27s/batch, loss=11.092166]Training:  34%|███▎      | 71/211 [35:22<56:33, 24.24s/batch, loss=11.092166]  Training:  34%|███▎      | 71/211 [35:25<56:33, 24.24s/batch, loss=10.896217]Training:  34%|███▍      | 72/211 [35:25<41:33, 17.94s/batch, loss=10.896217]Training:  34%|███▍      | 72/211 [36:59<41:33, 17.94s/batch, loss=10.787946]Training:  35%|███▍      | 73/211 [37:00<1:34:07, 40.92s/batch, loss=10.787946]Training:  35%|███▍      | 73/211 [37:03<1:34:07, 40.92s/batch, loss=11.218228]Training:  35%|███▌      | 74/211 [37:03<1:07:36, 29.61s/batch, loss=11.218228]Training:  35%|███▌      | 74/211 [37:06<1:07:36, 29.61s/batch, loss=10.660311]Training:  36%|███▌      | 75/211 [37:06<49:11, 21.70s/batch, loss=10.660311]  Training:  36%|███▌      | 75/211 [37:09<49:11, 21.70s/batch, loss=10.874374]Training:  36%|███▌      | 76/211 [37:09<36:16, 16.12s/batch, loss=10.874374]Training:  36%|███▌      | 76/211 [38:47<36:16, 16.12s/batch, loss=11.163155]Training:  36%|███▋      | 77/211 [38:48<1:31:08, 40.81s/batch, loss=11.163155]Training:  36%|███▋      | 77/211 [38:55<1:31:08, 40.81s/batch, loss=11.062600]Training:  37%|███▋      | 78/211 [38:55<1:08:23, 30.86s/batch, loss=11.062600]Training:  37%|███▋      | 78/211 [38:58<1:08:23, 30.86s/batch, loss=10.614818]Training:  37%|███▋      | 79/211 [38:58<49:38, 22.57s/batch, loss=10.614818]  Training:  37%|███▋      | 79/211 [39:02<49:38, 22.57s/batch, loss=11.217049]Training:  38%|███▊      | 80/211 [39:02<36:32, 16.74s/batch, loss=11.217049]Training:  38%|███▊      | 80/211 [40:27<36:32, 16.74s/batch, loss=10.989874]Training:  38%|███▊      | 81/211 [40:27<1:21:00, 37.39s/batch, loss=10.989874]Training:  38%|███▊      | 81/211 [40:57<1:21:00, 37.39s/batch, loss=10.560467]Training:  39%|███▉      | 82/211 [40:57<1:15:31, 35.13s/batch, loss=10.560467]Training:  39%|███▉      | 82/211 [41:00<1:15:31, 35.13s/batch, loss=10.383959]Training:  39%|███▉      | 83/211 [41:00<54:32, 25.56s/batch, loss=10.383959]  Training:  39%|███▉      | 83/211 [41:03<54:32, 25.56s/batch, loss=10.456248]Training:  40%|███▉      | 84/211 [41:03<39:54, 18.85s/batch, loss=10.456248]Training:  40%|███▉      | 84/211 [42:12<39:54, 18.85s/batch, loss=11.116028]Training:  40%|████      | 85/211 [42:12<1:10:44, 33.69s/batch, loss=11.116028]Training:  40%|████      | 85/211 [42:50<1:10:44, 33.69s/batch, loss=10.480914]Training:  41%|████      | 86/211 [42:50<1:12:58, 35.03s/batch, loss=10.480914]Training:  41%|████      | 86/211 [42:53<1:12:58, 35.03s/batch, loss=10.454193]Training:  41%|████      | 87/211 [42:53<52:39, 25.48s/batch, loss=10.454193]  Training:  41%|████      | 87/211 [42:56<52:39, 25.48s/batch, loss=10.585421]Training:  42%|████▏     | 88/211 [42:56<38:30, 18.79s/batch, loss=10.585421]Training:  42%|████▏     | 88/211 [44:02<38:30, 18.79s/batch, loss=11.076871]Training:  42%|████▏     | 89/211 [44:02<1:07:00, 32.95s/batch, loss=11.076871]Training:  42%|████▏     | 89/211 [44:46<1:07:00, 32.95s/batch, loss=10.805215]Training:  43%|████▎     | 90/211 [44:46<1:13:02, 36.22s/batch, loss=10.805215]Training:  43%|████▎     | 90/211 [44:49<1:13:02, 36.22s/batch, loss=10.938711]Training:  43%|████▎     | 91/211 [44:49<52:35, 26.29s/batch, loss=10.938711]  Training:  43%|████▎     | 91/211 [44:52<52:35, 26.29s/batch, loss=10.848867]Training:  44%|████▎     | 92/211 [44:52<38:18, 19.32s/batch, loss=10.848867]Training:  44%|████▎     | 92/211 [46:00<38:18, 19.32s/batch, loss=11.098541]Training:  44%|████▍     | 93/211 [46:00<1:06:27, 33.79s/batch, loss=11.098541]Training:  44%|████▍     | 93/211 [46:51<1:06:27, 33.79s/batch, loss=10.250294]Training:  45%|████▍     | 94/211 [46:51<1:16:08, 39.04s/batch, loss=10.250294]Training:  45%|████▍     | 94/211 [46:54<1:16:08, 39.04s/batch, loss=10.905946]Training:  45%|████▌     | 95/211 [46:54<54:42, 28.30s/batch, loss=10.905946]  Training:  45%|████▌     | 95/211 [46:57<54:42, 28.30s/batch, loss=10.501629]Training:  45%|████▌     | 96/211 [46:57<39:44, 20.73s/batch, loss=10.501629]Training:  45%|████▌     | 96/211 [47:44<39:44, 20.73s/batch, loss=10.837510]Training:  46%|████▌     | 97/211 [47:44<54:05, 28.47s/batch, loss=10.837510]Training:  46%|████▌     | 97/211 [48:44<54:05, 28.47s/batch, loss=10.519835]Training:  46%|████▋     | 98/211 [48:44<1:11:37, 38.03s/batch, loss=10.519835]Training:  46%|████▋     | 98/211 [48:48<1:11:37, 38.03s/batch, loss=10.679885]Training:  47%|████▋     | 99/211 [48:48<51:29, 27.59s/batch, loss=10.679885]  Training:  47%|████▋     | 99/211 [48:51<51:29, 27.59s/batch, loss=10.325705]Training:  47%|████▋     | 100/211 [48:51<37:26, 20.24s/batch, loss=10.325705]Training:  47%|████▋     | 100/211 [49:43<37:26, 20.24s/batch, loss=10.528723]Training:  48%|████▊     | 101/211 [49:43<54:55, 29.96s/batch, loss=10.528723]Training:  48%|████▊     | 101/211 [50:41<54:55, 29.96s/batch, loss=11.018467]Training:  48%|████▊     | 102/211 [50:41<1:09:28, 38.25s/batch, loss=11.018467]Training:  48%|████▊     | 102/211 [50:44<1:09:28, 38.25s/batch, loss=10.671926]Training:  49%|████▉     | 103/211 [50:44<49:56, 27.75s/batch, loss=10.671926]  Training:  49%|████▉     | 103/211 [50:47<49:56, 27.75s/batch, loss=11.149593]Training:  49%|████▉     | 104/211 [50:47<36:22, 20.40s/batch, loss=11.149593]Training:  49%|████▉     | 104/211 [51:45<36:22, 20.40s/batch, loss=10.267712]Training:  50%|████▉     | 105/211 [51:45<55:35, 31.47s/batch, loss=10.267712]Training:  50%|████▉     | 105/211 [52:36<55:35, 31.47s/batch, loss=10.214634]Training:  50%|█████     | 106/211 [52:36<1:05:38, 37.51s/batch, loss=10.214634]Training:  50%|█████     | 106/211 [52:39<1:05:38, 37.51s/batch, loss=10.319431]Training:  51%|█████     | 107/211 [52:39<47:08, 27.20s/batch, loss=10.319431]  Training:  51%|█████     | 107/211 [52:43<47:08, 27.20s/batch, loss=10.213216]Training:  51%|█████     | 108/211 [52:43<34:19, 19.99s/batch, loss=10.213216]Training:  51%|█████     | 108/211 [53:37<34:19, 19.99s/batch, loss=10.365642]Training:  52%|█████▏    | 109/211 [53:37<51:24, 30.24s/batch, loss=10.365642]Training:  52%|█████▏    | 109/211 [54:21<51:24, 30.24s/batch, loss=10.478045]Training:  52%|█████▏    | 110/211 [54:21<58:11, 34.57s/batch, loss=10.478045]Training:  52%|█████▏    | 110/211 [54:24<58:11, 34.57s/batch, loss=10.777547]Training:  53%|█████▎    | 111/211 [54:24<41:52, 25.13s/batch, loss=10.777547]Training:  53%|█████▎    | 111/211 [54:28<41:52, 25.13s/batch, loss=10.740213]Training:  53%|█████▎    | 112/211 [54:28<30:34, 18.53s/batch, loss=10.740213]Training:  53%|█████▎    | 112/211 [55:29<30:34, 18.53s/batch, loss=10.854157]Training:  54%|█████▎    | 113/211 [55:29<51:12, 31.35s/batch, loss=10.854157]Training:  54%|█████▎    | 113/211 [56:10<51:12, 31.35s/batch, loss=10.564953]Training:  54%|█████▍    | 114/211 [56:10<55:18, 34.21s/batch, loss=10.564953]Training:  54%|█████▍    | 114/211 [56:13<55:18, 34.21s/batch, loss=10.814721]Training:  55%|█████▍    | 115/211 [56:13<39:51, 24.91s/batch, loss=10.814721]Training:  55%|█████▍    | 115/211 [56:16<39:51, 24.91s/batch, loss=10.310250]Training:  55%|█████▍    | 116/211 [56:16<29:03, 18.36s/batch, loss=10.310250]Training:  55%|█████▍    | 116/211 [57:35<29:03, 18.36s/batch, loss=10.706676]Training:  55%|█████▌    | 117/211 [57:36<57:36, 36.77s/batch, loss=10.706676]Training:  55%|█████▌    | 117/211 [57:57<57:36, 36.77s/batch, loss=10.432957]Training:  56%|█████▌    | 118/211 [57:57<49:33, 31.97s/batch, loss=10.432957]Training:  56%|█████▌    | 118/211 [58:00<49:33, 31.97s/batch, loss=10.595969]Training:  56%|█████▋    | 119/211 [58:00<35:44, 23.31s/batch, loss=10.595969]Training:  56%|█████▋    | 119/211 [58:03<35:44, 23.31s/batch, loss=10.355166]Training:  57%|█████▋    | 120/211 [58:03<26:09, 17.25s/batch, loss=10.355166]Training:  57%|█████▋    | 120/211 [59:23<26:09, 17.25s/batch, loss=10.931270]Training:  57%|█████▋    | 121/211 [59:23<54:26, 36.29s/batch, loss=10.931270]Training:  57%|█████▋    | 121/211 [59:54<54:26, 36.29s/batch, loss=10.826227]Training:  58%|█████▊    | 122/211 [59:54<51:22, 34.63s/batch, loss=10.826227]Training:  58%|█████▊    | 122/211 [59:57<51:22, 34.63s/batch, loss=10.742564]Training:  58%|█████▊    | 123/211 [59:57<36:56, 25.19s/batch, loss=10.742564]Training:  58%|█████▊    | 123/211 [1:00:00<36:56, 25.19s/batch, loss=11.094346]Training:  59%|█████▉    | 124/211 [1:00:00<26:54, 18.56s/batch, loss=11.094346]Training:  59%|█████▉    | 124/211 [1:01:19<26:54, 18.56s/batch, loss=10.675920]Training:  59%|█████▉    | 125/211 [1:01:19<52:17, 36.48s/batch, loss=10.675920]Training:  59%|█████▉    | 125/211 [1:01:47<52:17, 36.48s/batch, loss=10.459599]Training:  60%|█████▉    | 126/211 [1:01:47<48:04, 33.94s/batch, loss=10.459599]Training:  60%|█████▉    | 126/211 [1:01:50<48:04, 33.94s/batch, loss=10.560648]Training:  60%|██████    | 127/211 [1:01:50<34:36, 24.72s/batch, loss=10.560648]Training:  60%|██████    | 127/211 [1:01:53<34:36, 24.72s/batch, loss=10.614382]Training:  61%|██████    | 128/211 [1:01:53<25:14, 18.25s/batch, loss=10.614382]Training:  61%|██████    | 128/211 [1:03:10<25:14, 18.25s/batch, loss=10.477854]Training:  61%|██████    | 129/211 [1:03:10<48:49, 35.72s/batch, loss=10.477854]Training:  61%|██████    | 129/211 [1:03:34<48:49, 35.72s/batch, loss=10.344786]Training:  62%|██████▏   | 130/211 [1:03:34<43:46, 32.42s/batch, loss=10.344786]Training:  62%|██████▏   | 130/211 [1:03:38<43:46, 32.42s/batch, loss=10.963918]Training:  62%|██████▏   | 131/211 [1:03:38<31:31, 23.64s/batch, loss=10.963918]Training:  62%|██████▏   | 131/211 [1:03:41<31:31, 23.64s/batch, loss=10.159406]Training:  63%|██████▎   | 132/211 [1:03:41<23:01, 17.48s/batch, loss=10.159406]Training:  63%|██████▎   | 132/211 [1:04:52<23:01, 17.48s/batch, loss=10.280477]Training:  63%|██████▎   | 133/211 [1:04:52<43:54, 33.78s/batch, loss=10.280477]Training:  63%|██████▎   | 133/211 [1:05:25<43:54, 33.78s/batch, loss=10.956403]Training:  64%|██████▎   | 134/211 [1:05:25<42:58, 33.49s/batch, loss=10.956403]Training:  64%|██████▎   | 134/211 [1:05:28<42:58, 33.49s/batch, loss=10.799527]Training:  64%|██████▍   | 135/211 [1:05:28<30:55, 24.42s/batch, loss=10.799527]Training:  64%|██████▍   | 135/211 [1:05:32<30:55, 24.42s/batch, loss=10.543090]Training:  64%|██████▍   | 136/211 [1:05:32<22:34, 18.06s/batch, loss=10.543090]Training:  64%|██████▍   | 136/211 [1:06:52<22:34, 18.06s/batch, loss=10.619953]Training:  65%|██████▍   | 137/211 [1:06:52<45:26, 36.85s/batch, loss=10.619953]Training:  65%|██████▍   | 137/211 [1:07:19<45:26, 36.85s/batch, loss=10.090679]Training:  65%|██████▌   | 138/211 [1:07:19<41:13, 33.88s/batch, loss=10.090679]Training:  65%|██████▌   | 138/211 [1:07:23<41:13, 33.88s/batch, loss=10.661352]Training:  66%|██████▌   | 139/211 [1:07:23<29:35, 24.66s/batch, loss=10.661352]Training:  66%|██████▌   | 139/211 [1:07:26<29:35, 24.66s/batch, loss=10.506474]Training:  66%|██████▋   | 140/211 [1:07:26<21:32, 18.20s/batch, loss=10.506474]Training:  66%|██████▋   | 140/211 [1:09:00<21:32, 18.20s/batch, loss=10.433766]Training:  67%|██████▋   | 141/211 [1:09:00<48:01, 41.17s/batch, loss=10.433766]Training:  67%|██████▋   | 141/211 [1:09:08<48:01, 41.17s/batch, loss=10.488646]Training:  67%|██████▋   | 142/211 [1:09:08<35:45, 31.09s/batch, loss=10.488646]Training:  67%|██████▋   | 142/211 [1:09:11<35:45, 31.09s/batch, loss=10.683134]Training:  68%|██████▊   | 143/211 [1:09:11<25:44, 22.71s/batch, loss=10.683134]Training:  68%|██████▊   | 143/211 [1:09:14<25:44, 22.71s/batch, loss=10.442980]Training:  68%|██████▊   | 144/211 [1:09:14<18:47, 16.83s/batch, loss=10.442980]Training:  68%|██████▊   | 144/211 [1:10:55<18:47, 16.83s/batch, loss=10.404060]Training:  69%|██████▊   | 145/211 [1:10:55<46:18, 42.09s/batch, loss=10.404060]Training:  69%|██████▊   | 145/211 [1:10:58<46:18, 42.09s/batch, loss=10.641461]Training:  69%|██████▉   | 146/211 [1:10:58<32:57, 30.43s/batch, loss=10.641461]Training:  69%|██████▉   | 146/211 [1:11:02<32:57, 30.43s/batch, loss=10.577865]Training:  70%|██████▉   | 147/211 [1:11:02<23:43, 22.25s/batch, loss=10.577865]Training:  70%|██████▉   | 147/211 [1:11:05<23:43, 22.25s/batch, loss=10.344450]Training:  70%|███████   | 148/211 [1:11:05<17:19, 16.50s/batch, loss=10.344450]Training:  70%|███████   | 148/211 [1:12:35<17:19, 16.50s/batch, loss=10.306881]Training:  71%|███████   | 149/211 [1:12:36<40:09, 38.87s/batch, loss=10.306881]Training:  71%|███████   | 149/211 [1:12:39<40:09, 38.87s/batch, loss=10.388578]Training:  71%|███████   | 150/211 [1:12:39<28:37, 28.15s/batch, loss=10.388578]Training:  71%|███████   | 150/211 [1:12:42<28:37, 28.15s/batch, loss=10.607383]Training:  72%|███████▏  | 151/211 [1:12:42<20:41, 20.69s/batch, loss=10.607383]Training:  72%|███████▏  | 151/211 [1:12:45<20:41, 20.69s/batch, loss=10.473411]Training:  72%|███████▏  | 152/211 [1:12:45<15:10, 15.44s/batch, loss=10.473411]Training:  72%|███████▏  | 152/211 [1:14:27<15:10, 15.44s/batch, loss=10.564680]Training:  73%|███████▎  | 153/211 [1:14:27<39:54, 41.29s/batch, loss=10.564680]Training:  73%|███████▎  | 153/211 [1:14:30<39:54, 41.29s/batch, loss=10.182857]Training:  73%|███████▎  | 154/211 [1:14:30<28:20, 29.83s/batch, loss=10.182857]Training:  73%|███████▎  | 154/211 [1:14:33<28:20, 29.83s/batch, loss=10.348067]Training:  73%|███████▎  | 155/211 [1:14:33<20:21, 21.81s/batch, loss=10.348067]Training:  73%|███████▎  | 155/211 [1:14:36<20:21, 21.81s/batch, loss=9.947902] Training:  74%|███████▍  | 156/211 [1:14:36<14:53, 16.24s/batch, loss=9.947902]Training:  74%|███████▍  | 156/211 [1:16:14<14:53, 16.24s/batch, loss=10.269213]Training:  74%|███████▍  | 157/211 [1:16:14<36:39, 40.73s/batch, loss=10.269213]Training:  74%|███████▍  | 157/211 [1:16:18<36:39, 40.73s/batch, loss=10.391310]Training:  75%|███████▍  | 158/211 [1:16:18<26:02, 29.48s/batch, loss=10.391310]Training:  75%|███████▍  | 158/211 [1:16:21<26:02, 29.48s/batch, loss=10.307155]Training:  75%|███████▌  | 159/211 [1:16:21<18:43, 21.61s/batch, loss=10.307155]Training:  75%|███████▌  | 159/211 [1:16:24<18:43, 21.61s/batch, loss=10.164556]Training:  76%|███████▌  | 160/211 [1:16:24<13:39, 16.06s/batch, loss=10.164556]Training:  76%|███████▌  | 160/211 [1:17:56<13:39, 16.06s/batch, loss=10.316095]Training:  76%|███████▋  | 161/211 [1:17:57<32:38, 39.17s/batch, loss=10.316095]Training:  76%|███████▋  | 161/211 [1:18:00<32:38, 39.17s/batch, loss=10.196424]Training:  77%|███████▋  | 162/211 [1:18:00<23:09, 28.36s/batch, loss=10.196424]Training:  77%|███████▋  | 162/211 [1:18:03<23:09, 28.36s/batch, loss=10.047442]Training:  77%|███████▋  | 163/211 [1:18:03<16:39, 20.82s/batch, loss=10.047442]Training:  77%|███████▋  | 163/211 [1:18:07<16:39, 20.82s/batch, loss=10.224346]Training:  78%|███████▊  | 164/211 [1:18:07<12:10, 15.54s/batch, loss=10.224346]Training:  78%|███████▊  | 164/211 [1:19:41<12:10, 15.54s/batch, loss=10.209130]Training:  78%|███████▊  | 165/211 [1:19:41<30:00, 39.14s/batch, loss=10.209130]Training:  78%|███████▊  | 165/211 [1:19:44<30:00, 39.14s/batch, loss=10.522921]Training:  79%|███████▊  | 166/211 [1:19:44<21:16, 28.37s/batch, loss=10.522921]Training:  79%|███████▊  | 166/211 [1:19:47<21:16, 28.37s/batch, loss=9.778654] Training:  79%|███████▉  | 167/211 [1:19:47<15:15, 20.80s/batch, loss=9.778654]Training:  79%|███████▉  | 167/211 [1:19:50<15:15, 20.80s/batch, loss=10.782663]Training:  80%|███████▉  | 168/211 [1:19:50<11:06, 15.51s/batch, loss=10.782663]Training:  80%|███████▉  | 168/211 [1:21:40<11:06, 15.51s/batch, loss=10.900920]Training:  80%|████████  | 169/211 [1:21:41<30:45, 43.94s/batch, loss=10.900920]Training:  80%|████████  | 169/211 [1:21:44<30:45, 43.94s/batch, loss=11.021119]Training:  81%|████████  | 170/211 [1:21:44<21:40, 31.72s/batch, loss=11.021119]Training:  81%|████████  | 170/211 [1:21:47<21:40, 31.72s/batch, loss=10.233228]Training:  81%|████████  | 171/211 [1:21:47<15:26, 23.16s/batch, loss=10.233228]Training:  81%|████████  | 171/211 [1:21:50<15:26, 23.16s/batch, loss=10.323161]Training:  82%|████████▏ | 172/211 [1:21:50<11:09, 17.18s/batch, loss=10.323161]Training:  82%|████████▏ | 172/211 [1:23:27<11:09, 17.18s/batch, loss=10.406923]Training:  82%|████████▏ | 173/211 [1:23:28<26:05, 41.21s/batch, loss=10.406923]Training:  82%|████████▏ | 173/211 [1:23:31<26:05, 41.21s/batch, loss=10.082034]Training:  82%|████████▏ | 174/211 [1:23:31<18:23, 29.81s/batch, loss=10.082034]Training:  82%|████████▏ | 174/211 [1:23:34<18:23, 29.81s/batch, loss=10.601437]Training:  83%|████████▎ | 175/211 [1:23:34<13:05, 21.81s/batch, loss=10.601437]Training:  83%|████████▎ | 175/211 [1:23:37<13:05, 21.81s/batch, loss=10.297985]Training:  83%|████████▎ | 176/211 [1:23:37<09:28, 16.24s/batch, loss=10.297985]Training:  83%|████████▎ | 176/211 [1:25:25<09:28, 16.24s/batch, loss=9.991434] Training:  84%|████████▍ | 177/211 [1:25:25<24:46, 43.71s/batch, loss=9.991434]Training:  84%|████████▍ | 177/211 [1:25:28<24:46, 43.71s/batch, loss=10.017465]Training:  84%|████████▍ | 178/211 [1:25:28<17:22, 31.58s/batch, loss=10.017465]Training:  84%|████████▍ | 178/211 [1:25:31<17:22, 31.58s/batch, loss=10.445460]Training:  85%|████████▍ | 179/211 [1:25:31<12:17, 23.04s/batch, loss=10.445460]Training:  85%|████████▍ | 179/211 [1:25:34<12:17, 23.04s/batch, loss=10.387210]Training:  85%|████████▌ | 180/211 [1:25:34<08:49, 17.06s/batch, loss=10.387210]Training:  85%|████████▌ | 180/211 [1:27:23<08:49, 17.06s/batch, loss=10.395561]Training:  86%|████████▌ | 181/211 [1:27:24<22:21, 44.73s/batch, loss=10.395561]Training:  86%|████████▌ | 181/211 [1:27:27<22:21, 44.73s/batch, loss=10.701853]Training:  86%|████████▋ | 182/211 [1:27:27<15:35, 32.25s/batch, loss=10.701853]Training:  86%|████████▋ | 182/211 [1:27:30<15:35, 32.25s/batch, loss=10.431239]Training:  87%|████████▋ | 183/211 [1:27:30<10:58, 23.52s/batch, loss=10.431239]Training:  87%|████████▋ | 183/211 [1:27:34<10:58, 23.52s/batch, loss=10.196637]Training:  87%|████████▋ | 184/211 [1:27:34<07:56, 17.66s/batch, loss=10.196637]Training:  87%|████████▋ | 184/211 [1:29:13<07:56, 17.66s/batch, loss=10.283378]Training:  88%|████████▊ | 185/211 [1:29:13<18:13, 42.04s/batch, loss=10.283378]Training:  88%|████████▊ | 185/211 [1:29:16<18:13, 42.04s/batch, loss=10.255806]Training:  88%|████████▊ | 186/211 [1:29:16<12:39, 30.36s/batch, loss=10.255806]Training:  88%|████████▊ | 186/211 [1:29:19<12:39, 30.36s/batch, loss=10.522311]Training:  89%|████████▊ | 187/211 [1:29:19<08:52, 22.20s/batch, loss=10.522311]Training:  89%|████████▊ | 187/211 [1:29:22<08:52, 22.20s/batch, loss=10.421682]Training:  89%|████████▉ | 188/211 [1:29:22<06:19, 16.49s/batch, loss=10.421682]Training:  89%|████████▉ | 188/211 [1:31:12<06:19, 16.49s/batch, loss=10.150245]Training:  90%|████████▉ | 189/211 [1:31:12<16:16, 44.40s/batch, loss=10.150245]Training:  90%|████████▉ | 189/211 [1:31:15<16:16, 44.40s/batch, loss=10.233210]Training:  90%|█████████ | 190/211 [1:31:15<11:12, 32.02s/batch, loss=10.233210]Training:  90%|█████████ | 190/211 [1:31:18<11:12, 32.02s/batch, loss=10.468898]Training:  91%|█████████ | 191/211 [1:31:18<07:46, 23.35s/batch, loss=10.468898]Training:  91%|█████████ | 191/211 [1:31:21<07:46, 23.35s/batch, loss=10.155144]Training:  91%|█████████ | 192/211 [1:31:21<05:28, 17.31s/batch, loss=10.155144]Training:  91%|█████████ | 192/211 [1:33:03<05:28, 17.31s/batch, loss=10.230880]Training:  91%|█████████▏| 193/211 [1:33:03<12:46, 42.61s/batch, loss=10.230880]Training:  91%|█████████▏| 193/211 [1:33:06<12:46, 42.61s/batch, loss=10.594167]Training:  92%|█████████▏| 194/211 [1:33:06<08:43, 30.79s/batch, loss=10.594167]Training:  92%|█████████▏| 194/211 [1:33:09<08:43, 30.79s/batch, loss=10.338461]Training:  92%|█████████▏| 195/211 [1:33:09<05:59, 22.50s/batch, loss=10.338461]Training:  92%|█████████▏| 195/211 [1:33:12<05:59, 22.50s/batch, loss=10.131695]Training:  93%|█████████▎| 196/211 [1:33:12<04:10, 16.70s/batch, loss=10.131695]Training:  93%|█████████▎| 196/211 [1:34:59<04:10, 16.70s/batch, loss=10.217594]Training:  93%|█████████▎| 197/211 [1:34:59<10:10, 43.64s/batch, loss=10.217594]Training:  93%|█████████▎| 197/211 [1:35:02<10:10, 43.64s/batch, loss=10.702655]Training:  94%|█████████▍| 198/211 [1:35:02<06:49, 31.51s/batch, loss=10.702655]Training:  94%|█████████▍| 198/211 [1:35:05<06:49, 31.51s/batch, loss=10.291020]Training:  94%|█████████▍| 199/211 [1:35:05<04:36, 23.00s/batch, loss=10.291020]Training:  94%|█████████▍| 199/211 [1:35:08<04:36, 23.00s/batch, loss=10.078627]Training:  95%|█████████▍| 200/211 [1:35:08<03:07, 17.04s/batch, loss=10.078627]Training:  95%|█████████▍| 200/211 [1:36:48<03:07, 17.04s/batch, loss=10.325540]Training:  95%|█████████▌| 201/211 [1:36:49<06:59, 42.00s/batch, loss=10.325540]Training:  95%|█████████▌| 201/211 [1:36:52<06:59, 42.00s/batch, loss=10.187845]Training:  96%|█████████▌| 202/211 [1:36:52<04:33, 30.34s/batch, loss=10.187845]Training:  96%|█████████▌| 202/211 [1:36:55<04:33, 30.34s/batch, loss=10.350105]Training:  96%|█████████▌| 203/211 [1:36:55<02:57, 22.18s/batch, loss=10.350105]Training:  96%|█████████▌| 203/211 [1:36:58<02:57, 22.18s/batch, loss=10.625614]Training:  97%|█████████▋| 204/211 [1:36:58<01:55, 16.51s/batch, loss=10.625614]Training:  97%|█████████▋| 204/211 [1:38:03<01:55, 16.51s/batch, loss=9.872894] Training:  97%|█████████▋| 205/211 [1:38:03<03:06, 31.10s/batch, loss=9.872894]Training:  97%|█████████▋| 205/211 [1:38:07<03:06, 31.10s/batch, loss=10.241603]Training:  98%|█████████▊| 206/211 [1:38:07<01:53, 22.73s/batch, loss=10.241603]Training:  98%|█████████▊| 206/211 [1:38:10<01:53, 22.73s/batch, loss=10.350254]Training:  98%|█████████▊| 207/211 [1:38:10<01:07, 16.87s/batch, loss=10.350254]Training:  98%|█████████▊| 207/211 [1:38:13<01:07, 16.87s/batch, loss=10.584862]Training:  99%|█████████▊| 208/211 [1:38:13<00:38, 12.73s/batch, loss=10.584862]Training:  99%|█████████▊| 208/211 [1:38:50<00:38, 12.73s/batch, loss=10.291363]Training:  99%|█████████▉| 209/211 [1:38:50<00:39, 19.98s/batch, loss=10.291363]Training:  99%|█████████▉| 209/211 [1:38:53<00:39, 19.98s/batch, loss=10.342802]Training: 100%|█████████▉| 210/211 [1:38:53<00:14, 14.86s/batch, loss=10.342802]Training: 100%|█████████▉| 210/211 [1:38:53<00:14, 14.86s/batch, loss=10.746915]Training: 100%|██████████| 211/211 [1:38:53<00:00, 10.62s/batch, loss=10.746915]Training: 100%|██████████| 211/211 [1:38:53<00:00, 28.12s/batch, loss=10.746915]
Epoch 7, Train Loss: 10.6378, Val Loss: 10.2701
Training:   0%|          | 0/211 [00:00<?, ?batch/s]Training:   0%|          | 0/211 [01:15<?, ?batch/s, loss=10.183799]Training:   0%|          | 1/211 [01:15<4:24:18, 75.52s/batch, loss=10.183799]Training:   0%|          | 1/211 [01:26<4:24:18, 75.52s/batch, loss=10.028362]Training:   1%|          | 2/211 [01:26<2:11:30, 37.75s/batch, loss=10.028362]Training:   1%|          | 2/211 [01:42<2:11:30, 37.75s/batch, loss=10.603408]Training:   1%|▏         | 3/211 [01:42<1:36:20, 27.79s/batch, loss=10.603408]Training:   1%|▏         | 3/211 [01:46<1:36:20, 27.79s/batch, loss=10.731417]Training:   2%|▏         | 4/211 [01:46<1:02:41, 18.17s/batch, loss=10.731417]Training:   2%|▏         | 4/211 [02:59<1:02:41, 18.17s/batch, loss=9.925340] Training:   2%|▏         | 5/211 [03:00<2:11:55, 38.43s/batch, loss=9.925340]Training:   2%|▏         | 5/211 [03:03<2:11:55, 38.43s/batch, loss=10.348640]Training:   3%|▎         | 6/211 [03:03<1:30:22, 26.45s/batch, loss=10.348640]Training:   3%|▎         | 6/211 [03:35<1:30:22, 26.45s/batch, loss=10.737133]Training:   3%|▎         | 7/211 [03:35<1:35:47, 28.17s/batch, loss=10.737133]Training:   3%|▎         | 7/211 [03:38<1:35:47, 28.17s/batch, loss=10.469954]Training:   4%|▍         | 8/211 [03:38<1:08:20, 20.20s/batch, loss=10.469954]Training:   4%|▍         | 8/211 [05:00<1:08:20, 20.20s/batch, loss=10.390035]Training:   4%|▍         | 9/211 [05:00<2:13:07, 39.54s/batch, loss=10.390035]Training:   4%|▍         | 9/211 [05:03<2:13:07, 39.54s/batch, loss=10.539968]Training:   5%|▍         | 10/211 [05:03<1:34:53, 28.33s/batch, loss=10.539968]Training:   5%|▍         | 10/211 [05:21<1:34:53, 28.33s/batch, loss=10.617448]Training:   5%|▌         | 11/211 [05:21<1:23:26, 25.03s/batch, loss=10.617448]Training:   5%|▌         | 11/211 [05:24<1:23:26, 25.03s/batch, loss=9.807917] Training:   6%|▌         | 12/211 [05:24<1:00:49, 18.34s/batch, loss=9.807917]Training:   6%|▌         | 12/211 [06:48<1:00:49, 18.34s/batch, loss=10.273192]Training:   6%|▌         | 13/211 [06:49<2:06:44, 38.41s/batch, loss=10.273192]Training:   6%|▌         | 13/211 [06:52<2:06:44, 38.41s/batch, loss=10.352305]Training:   7%|▋         | 14/211 [06:52<1:31:13, 27.78s/batch, loss=10.352305]Training:   7%|▋         | 14/211 [06:55<1:31:13, 27.78s/batch, loss=10.007549]Training:   7%|▋         | 15/211 [06:55<1:06:31, 20.36s/batch, loss=10.007549]Training:   7%|▋         | 15/211 [07:12<1:06:31, 20.36s/batch, loss=9.814351] Training:   8%|▊         | 16/211 [07:12<1:02:50, 19.34s/batch, loss=9.814351]Training:   8%|▊         | 16/211 [08:35<1:02:50, 19.34s/batch, loss=10.497926]Training:   8%|▊         | 17/211 [08:35<2:04:51, 38.62s/batch, loss=10.497926]Training:   8%|▊         | 17/211 [08:39<2:04:51, 38.62s/batch, loss=10.241893]Training:   9%|▊         | 18/211 [08:39<1:30:01, 27.99s/batch, loss=10.241893]Training:   9%|▊         | 18/211 [08:42<1:30:01, 27.99s/batch, loss=10.254288]Training:   9%|▉         | 19/211 [08:42<1:05:45, 20.55s/batch, loss=10.254288]Training:   9%|▉         | 19/211 [08:49<1:05:45, 20.55s/batch, loss=10.185543]Training:   9%|▉         | 20/211 [08:49<53:05, 16.68s/batch, loss=10.185543]  Training:   9%|▉         | 20/211 [10:17<53:05, 16.68s/batch, loss=10.085102]Training:  10%|▉         | 21/211 [10:18<2:00:54, 38.18s/batch, loss=10.085102]Training:  10%|▉         | 21/211 [10:21<2:00:54, 38.18s/batch, loss=10.547691]Training:  10%|█         | 22/211 [10:21<1:27:08, 27.66s/batch, loss=10.547691]Training:  10%|█         | 22/211 [10:24<1:27:08, 27.66s/batch, loss=10.077334]Training:  11%|█         | 23/211 [10:24<1:03:35, 20.30s/batch, loss=10.077334]Training:  11%|█         | 23/211 [10:52<1:03:35, 20.30s/batch, loss=10.284037]Training:  11%|█▏        | 24/211 [10:52<1:09:56, 22.44s/batch, loss=10.284037]Training:  11%|█▏        | 24/211 [11:46<1:09:56, 22.44s/batch, loss=10.632381]Training:  12%|█▏        | 25/211 [11:46<1:39:45, 32.18s/batch, loss=10.632381]Training:  12%|█▏        | 25/211 [11:56<1:39:45, 32.18s/batch, loss=10.474309]Training:  12%|█▏        | 26/211 [11:56<1:18:30, 25.46s/batch, loss=10.474309]Training:  12%|█▏        | 26/211 [12:08<1:18:30, 25.46s/batch, loss=9.890864] Training:  13%|█▎        | 27/211 [12:08<1:05:22, 21.32s/batch, loss=9.890864]Training:  13%|█▎        | 27/211 [12:36<1:05:22, 21.32s/batch, loss=9.748500]Training:  13%|█▎        | 28/211 [12:36<1:11:03, 23.30s/batch, loss=9.748500]Training:  13%|█▎        | 28/211 [13:34<1:11:03, 23.30s/batch, loss=10.089825]Training:  14%|█▎        | 29/211 [13:35<1:43:46, 34.21s/batch, loss=10.089825]Training:  14%|█▎        | 29/211 [13:54<1:43:46, 34.21s/batch, loss=10.128821]Training:  14%|█▍        | 30/211 [13:54<1:28:51, 29.46s/batch, loss=10.128821]Training:  14%|█▍        | 30/211 [13:58<1:28:51, 29.46s/batch, loss=10.119680]Training:  15%|█▍        | 31/211 [13:58<1:06:05, 22.03s/batch, loss=10.119680]Training:  15%|█▍        | 31/211 [14:30<1:06:05, 22.03s/batch, loss=9.897852] Training:  15%|█▌        | 32/211 [14:30<1:14:37, 25.02s/batch, loss=9.897852]Training:  15%|█▌        | 32/211 [15:25<1:14:37, 25.02s/batch, loss=10.308760]Training:  16%|█▌        | 33/211 [15:25<1:40:51, 34.00s/batch, loss=10.308760]Training:  16%|█▌        | 33/211 [15:44<1:40:51, 34.00s/batch, loss=10.158676]Training:  16%|█▌        | 34/211 [15:44<1:26:36, 29.36s/batch, loss=10.158676]Training:  16%|█▌        | 34/211 [16:08<1:26:36, 29.36s/batch, loss=10.394753]Training:  17%|█▋        | 35/211 [16:08<1:21:15, 27.70s/batch, loss=10.394753]Training:  17%|█▋        | 35/211 [16:17<1:21:15, 27.70s/batch, loss=10.353415]Training:  17%|█▋        | 36/211 [16:17<1:04:39, 22.17s/batch, loss=10.353415]Training:  17%|█▋        | 36/211 [17:12<1:04:39, 22.17s/batch, loss=10.227059]Training:  18%|█▊        | 37/211 [17:12<1:32:51, 32.02s/batch, loss=10.227059]Training:  18%|█▊        | 37/211 [17:35<1:32:51, 32.02s/batch, loss=9.656217] Training:  18%|█▊        | 38/211 [17:35<1:24:04, 29.16s/batch, loss=9.656217]Training:  18%|█▊        | 38/211 [17:48<1:24:04, 29.16s/batch, loss=10.279737]Training:  18%|█▊        | 39/211 [17:48<1:10:20, 24.54s/batch, loss=10.279737]Training:  18%|█▊        | 39/211 [18:04<1:10:20, 24.54s/batch, loss=10.288650]Training:  19%|█▉        | 40/211 [18:04<1:02:00, 21.76s/batch, loss=10.288650]Training:  19%|█▉        | 40/211 [18:56<1:02:00, 21.76s/batch, loss=10.413362]Training:  19%|█▉        | 41/211 [18:57<1:28:14, 31.14s/batch, loss=10.413362]Training:  19%|█▉        | 41/211 [19:21<1:28:14, 31.14s/batch, loss=10.504418]Training:  20%|█▉        | 42/211 [19:21<1:22:17, 29.21s/batch, loss=10.504418]Training:  20%|█▉        | 42/211 [19:39<1:22:17, 29.21s/batch, loss=10.165112]Training:  20%|██        | 43/211 [19:39<1:12:28, 25.89s/batch, loss=10.165112]Training:  20%|██        | 43/211 [20:05<1:12:28, 25.89s/batch, loss=10.098321]Training:  21%|██        | 44/211 [20:05<1:11:47, 25.79s/batch, loss=10.098321]Training:  21%|██        | 44/211 [20:52<1:11:47, 25.79s/batch, loss=10.063097]Training:  21%|██▏       | 45/211 [20:53<1:29:30, 32.35s/batch, loss=10.063097]Training:  21%|██▏       | 45/211 [21:19<1:29:30, 32.35s/batch, loss=9.690993] Training:  22%|██▏       | 46/211 [21:19<1:24:14, 30.64s/batch, loss=9.690993]Training:  22%|██▏       | 46/211 [21:39<1:24:14, 30.64s/batch, loss=9.829448]Training:  22%|██▏       | 47/211 [21:39<1:14:36, 27.29s/batch, loss=9.829448]Training:  22%|██▏       | 47/211 [22:03<1:14:36, 27.29s/batch, loss=10.024630]Training:  23%|██▎       | 48/211 [22:03<1:11:51, 26.45s/batch, loss=10.024630]Training:  23%|██▎       | 48/211 [22:49<1:11:51, 26.45s/batch, loss=9.756602] Training:  23%|██▎       | 49/211 [22:49<1:26:41, 32.11s/batch, loss=9.756602]Training:  23%|██▎       | 49/211 [23:26<1:26:41, 32.11s/batch, loss=10.087674]Training:  24%|██▎       | 50/211 [23:26<1:30:19, 33.66s/batch, loss=10.087674]Training:  24%|██▎       | 50/211 [23:35<1:30:19, 33.66s/batch, loss=10.068821]Training:  24%|██▍       | 51/211 [23:35<1:10:29, 26.43s/batch, loss=10.068821]Training:  24%|██▍       | 51/211 [23:39<1:10:29, 26.43s/batch, loss=10.187284]Training:  25%|██▍       | 52/211 [23:39<51:32, 19.45s/batch, loss=10.187284]  Training:  25%|██▍       | 52/211 [24:38<51:32, 19.45s/batch, loss=10.027467]Training:  25%|██▌       | 53/211 [24:39<1:23:47, 31.82s/batch, loss=10.027467]Training:  25%|██▌       | 53/211 [25:16<1:23:47, 31.82s/batch, loss=10.409701]Training:  26%|██▌       | 54/211 [25:16<1:26:49, 33.18s/batch, loss=10.409701]Training:  26%|██▌       | 54/211 [25:27<1:26:49, 33.18s/batch, loss=10.277727]Training:  26%|██▌       | 55/211 [25:27<1:09:14, 26.63s/batch, loss=10.277727]Training:  26%|██▌       | 55/211 [25:30<1:09:14, 26.63s/batch, loss=10.316408]Training:  27%|██▋       | 56/211 [25:30<50:36, 19.59s/batch, loss=10.316408]  Training:  27%|██▋       | 56/211 [26:23<50:36, 19.59s/batch, loss=10.434526]Training:  27%|██▋       | 57/211 [26:23<1:16:14, 29.71s/batch, loss=10.434526]Training:  27%|██▋       | 57/211 [27:08<1:16:14, 29.71s/batch, loss=10.024330]Training:  27%|██▋       | 58/211 [27:08<1:27:00, 34.12s/batch, loss=10.024330]Training:  27%|██▋       | 58/211 [27:11<1:27:00, 34.12s/batch, loss=10.537178]Training:  28%|██▊       | 59/211 [27:11<1:03:08, 24.92s/batch, loss=10.537178]Training:  28%|██▊       | 59/211 [27:23<1:03:08, 24.92s/batch, loss=10.103728]Training:  28%|██▊       | 60/211 [27:23<52:46, 20.97s/batch, loss=10.103728]  Training:  28%|██▊       | 60/211 [28:09<52:46, 20.97s/batch, loss=10.342190]Training:  29%|██▉       | 61/211 [28:10<1:11:32, 28.62s/batch, loss=10.342190]Training:  29%|██▉       | 61/211 [28:50<1:11:32, 28.62s/batch, loss=9.542056] Training:  29%|██▉       | 62/211 [28:50<1:19:38, 32.07s/batch, loss=9.542056]Training:  29%|██▉       | 62/211 [29:00<1:19:38, 32.07s/batch, loss=9.972554]Training:  30%|██▉       | 63/211 [29:00<1:02:44, 25.43s/batch, loss=9.972554]Training:  30%|██▉       | 63/211 [29:12<1:02:44, 25.43s/batch, loss=10.087914]Training:  30%|███       | 64/211 [29:12<52:26, 21.41s/batch, loss=10.087914]  Training:  30%|███       | 64/211 [29:43<52:26, 21.41s/batch, loss=9.980801] Training:  31%|███       | 65/211 [29:44<1:00:04, 24.69s/batch, loss=9.980801]Training:  31%|███       | 65/211 [30:37<1:00:04, 24.69s/batch, loss=10.390710]Training:  31%|███▏      | 66/211 [30:37<1:20:31, 33.32s/batch, loss=10.390710]Training:  31%|███▏      | 66/211 [30:50<1:20:31, 33.32s/batch, loss=10.331654]Training:  32%|███▏      | 67/211 [30:50<1:04:41, 26.96s/batch, loss=10.331654]Training:  32%|███▏      | 67/211 [31:08<1:04:41, 26.96s/batch, loss=10.182205]Training:  32%|███▏      | 68/211 [31:08<57:53, 24.29s/batch, loss=10.182205]  Training:  32%|███▏      | 68/211 [31:32<57:53, 24.29s/batch, loss=10.237038]Training:  33%|███▎      | 69/211 [31:34<58:36, 24.76s/batch, loss=10.237038]Training:  33%|███▎      | 69/211 [32:19<58:36, 24.76s/batch, loss=9.857781] Training:  33%|███▎      | 70/211 [32:19<1:12:46, 30.97s/batch, loss=9.857781]Training:  33%|███▎      | 70/211 [32:29<1:12:46, 30.97s/batch, loss=10.010314]Training:  34%|███▎      | 71/211 [32:29<57:29, 24.64s/batch, loss=10.010314]  Training:  34%|███▎      | 71/211 [32:52<57:29, 24.64s/batch, loss=9.893820] Training:  34%|███▍      | 72/211 [32:52<55:46, 24.08s/batch, loss=9.893820]Training:  34%|███▍      | 72/211 [33:26<55:46, 24.08s/batch, loss=10.160617]Training:  35%|███▍      | 73/211 [33:26<1:02:27, 27.16s/batch, loss=10.160617]Training:  35%|███▍      | 73/211 [34:16<1:02:27, 27.16s/batch, loss=9.993216] Training:  35%|███▌      | 74/211 [34:16<1:17:51, 34.10s/batch, loss=9.993216]Training:  35%|███▌      | 74/211 [34:28<1:17:51, 34.10s/batch, loss=9.690962]Training:  36%|███▌      | 75/211 [34:28<1:02:14, 27.46s/batch, loss=9.690962]Training:  36%|███▌      | 75/211 [34:36<1:02:14, 27.46s/batch, loss=9.790914]Training:  36%|███▌      | 76/211 [34:36<48:25, 21.52s/batch, loss=9.790914]  Training:  36%|███▌      | 76/211 [35:11<48:25, 21.52s/batch, loss=10.216875]Training:  36%|███▋      | 77/211 [35:11<57:10, 25.60s/batch, loss=10.216875]Training:  36%|███▋      | 77/211 [36:09<57:10, 25.60s/batch, loss=10.054827]Training:  37%|███▋      | 78/211 [36:09<1:18:34, 35.45s/batch, loss=10.054827]Training:  37%|███▋      | 78/211 [36:35<1:18:34, 35.45s/batch, loss=10.108090]Training:  37%|███▋      | 79/211 [36:35<1:11:40, 32.58s/batch, loss=10.108090]Training:  37%|███▋      | 79/211 [36:39<1:11:40, 32.58s/batch, loss=9.789300] Training:  38%|███▊      | 80/211 [36:39<51:53, 23.77s/batch, loss=9.789300]  Training:  38%|███▊      | 80/211 [37:07<51:53, 23.77s/batch, loss=10.307335]Training:  38%|███▊      | 81/211 [37:07<54:42, 25.25s/batch, loss=10.307335]Training:  38%|███▊      | 81/211 [37:55<54:42, 25.25s/batch, loss=10.083662]Training:  39%|███▉      | 82/211 [37:55<1:09:05, 32.14s/batch, loss=10.083662]Training:  39%|███▉      | 82/211 [38:29<1:09:05, 32.14s/batch, loss=10.243045]Training:  39%|███▉      | 83/211 [38:29<1:09:45, 32.70s/batch, loss=10.243045]Training:  39%|███▉      | 83/211 [38:33<1:09:45, 32.70s/batch, loss=9.741668] Training:  40%|███▉      | 84/211 [38:33<50:27, 23.84s/batch, loss=9.741668]  Training:  40%|███▉      | 84/211 [39:00<50:27, 23.84s/batch, loss=10.238213]Training:  40%|████      | 85/211 [39:00<52:37, 25.06s/batch, loss=10.238213]Training:  40%|████      | 85/211 [39:38<52:37, 25.06s/batch, loss=10.059923]Training:  41%|████      | 86/211 [39:38<1:00:13, 28.91s/batch, loss=10.059923]Training:  41%|████      | 86/211 [40:22<1:00:13, 28.91s/batch, loss=10.184575]Training:  41%|████      | 87/211 [40:23<1:09:33, 33.66s/batch, loss=10.184575]Training:  41%|████      | 87/211 [40:26<1:09:33, 33.66s/batch, loss=10.203130]Training:  42%|████▏     | 88/211 [40:26<50:12, 24.49s/batch, loss=10.203130]  Training:  42%|████▏     | 88/211 [40:57<50:12, 24.49s/batch, loss=10.068989]Training:  42%|████▏     | 89/211 [40:57<53:30, 26.32s/batch, loss=10.068989]Training:  42%|████▏     | 89/211 [41:23<53:30, 26.32s/batch, loss=9.639547] Training:  43%|████▎     | 90/211 [41:23<52:53, 26.22s/batch, loss=9.639547]Training:  43%|████▎     | 90/211 [42:26<52:53, 26.22s/batch, loss=9.998064]Training:  43%|████▎     | 91/211 [42:26<1:14:33, 37.28s/batch, loss=9.998064]Training:  43%|████▎     | 91/211 [42:29<1:14:33, 37.28s/batch, loss=10.236096]Training:  44%|████▎     | 92/211 [42:29<53:37, 27.04s/batch, loss=10.236096]  Training:  44%|████▎     | 92/211 [42:43<53:37, 27.04s/batch, loss=9.771550] Training:  44%|████▍     | 93/211 [42:43<45:15, 23.01s/batch, loss=9.771550]Training:  44%|████▍     | 93/211 [43:10<45:15, 23.01s/batch, loss=9.901717]Training:  45%|████▍     | 94/211 [43:10<47:31, 24.37s/batch, loss=9.901717]Training:  45%|████▍     | 94/211 [44:17<47:31, 24.37s/batch, loss=10.001982]Training:  45%|████▌     | 95/211 [44:18<1:12:08, 37.31s/batch, loss=10.001982]Training:  45%|████▌     | 95/211 [44:21<1:12:08, 37.31s/batch, loss=9.620409] Training:  45%|████▌     | 96/211 [44:21<51:49, 27.04s/batch, loss=9.620409]  Training:  45%|████▌     | 96/211 [44:33<51:49, 27.04s/batch, loss=10.162580]Training:  46%|████▌     | 97/211 [44:33<42:57, 22.61s/batch, loss=10.162580]Training:  46%|████▌     | 97/211 [44:54<42:57, 22.61s/batch, loss=10.002823]Training:  46%|████▋     | 98/211 [44:54<41:23, 21.98s/batch, loss=10.002823]Training:  46%|████▋     | 98/211 [46:14<41:23, 21.98s/batch, loss=10.145096]Training:  47%|████▋     | 99/211 [46:15<1:14:06, 39.70s/batch, loss=10.145096]Training:  47%|████▋     | 99/211 [46:18<1:14:06, 39.70s/batch, loss=9.951790] Training:  47%|████▋     | 100/211 [46:18<53:11, 28.75s/batch, loss=9.951790] Training:  47%|████▋     | 100/211 [46:21<53:11, 28.75s/batch, loss=10.256790]Training:  48%|████▊     | 101/211 [46:21<38:38, 21.08s/batch, loss=10.256790]Training:  48%|████▊     | 101/211 [46:50<38:38, 21.08s/batch, loss=9.871686] Training:  48%|████▊     | 102/211 [46:50<42:40, 23.49s/batch, loss=9.871686]Training:  48%|████▊     | 102/211 [48:03<42:40, 23.49s/batch, loss=10.188460]Training:  49%|████▉     | 103/211 [48:04<1:09:24, 38.56s/batch, loss=10.188460]Training:  49%|████▉     | 103/211 [48:07<1:09:24, 38.56s/batch, loss=10.146920]Training:  49%|████▉     | 104/211 [48:07<49:48, 27.93s/batch, loss=10.146920]  Training:  49%|████▉     | 104/211 [48:10<49:48, 27.93s/batch, loss=10.135325]Training:  50%|████▉     | 105/211 [48:10<36:12, 20.50s/batch, loss=10.135325]Training:  50%|████▉     | 105/211 [48:38<36:12, 20.50s/batch, loss=10.088708]Training:  50%|█████     | 106/211 [48:38<39:37, 22.65s/batch, loss=10.088708]Training:  50%|█████     | 106/211 [49:51<39:37, 22.65s/batch, loss=9.605942] Training:  51%|█████     | 107/211 [49:51<1:05:41, 37.90s/batch, loss=9.605942]Training:  51%|█████     | 107/211 [49:54<1:05:41, 37.90s/batch, loss=9.494817]Training:  51%|█████     | 108/211 [49:54<47:12, 27.50s/batch, loss=9.494817]  Training:  51%|█████     | 108/211 [49:58<47:12, 27.50s/batch, loss=10.009630]Training:  52%|█████▏    | 109/211 [49:58<34:20, 20.20s/batch, loss=10.009630]Training:  52%|█████▏    | 109/211 [50:25<34:20, 20.20s/batch, loss=10.006670]Training:  52%|█████▏    | 110/211 [50:25<37:31, 22.29s/batch, loss=10.006670]Training:  52%|█████▏    | 110/211 [51:42<37:31, 22.29s/batch, loss=9.977084] Training:  53%|█████▎    | 111/211 [51:43<1:05:06, 39.07s/batch, loss=9.977084]Training:  53%|█████▎    | 111/211 [51:46<1:05:06, 39.07s/batch, loss=9.455924]Training:  53%|█████▎    | 112/211 [51:46<46:44, 28.32s/batch, loss=9.455924]  Training:  53%|█████▎    | 112/211 [51:49<46:44, 28.32s/batch, loss=10.527854]Training:  54%|█████▎    | 113/211 [51:49<33:56, 20.78s/batch, loss=10.527854]Training:  54%|█████▎    | 113/211 [52:12<33:56, 20.78s/batch, loss=10.049721]Training:  54%|█████▍    | 114/211 [52:12<34:40, 21.45s/batch, loss=10.049721]Training:  54%|█████▍    | 114/211 [53:27<34:40, 21.45s/batch, loss=10.057036]Training:  55%|█████▍    | 115/211 [53:28<1:00:05, 37.55s/batch, loss=10.057036]Training:  55%|█████▍    | 115/211 [53:31<1:00:05, 37.55s/batch, loss=9.976849] Training:  55%|█████▍    | 116/211 [53:31<43:06, 27.23s/batch, loss=9.976849]  Training:  55%|█████▍    | 116/211 [53:34<43:06, 27.23s/batch, loss=10.148438]Training:  55%|█████▌    | 117/211 [53:34<31:36, 20.18s/batch, loss=10.148438]Training:  55%|█████▌    | 117/211 [53:54<31:36, 20.18s/batch, loss=10.043670]Training:  56%|█████▌    | 118/211 [53:54<30:58, 19.99s/batch, loss=10.043670]Training:  56%|█████▌    | 118/211 [55:11<30:58, 19.99s/batch, loss=10.319737]Training:  56%|█████▋    | 119/211 [55:11<57:04, 37.22s/batch, loss=10.319737]Training:  56%|█████▋    | 119/211 [55:15<57:04, 37.22s/batch, loss=10.116915]Training:  57%|█████▋    | 120/211 [55:15<40:59, 27.03s/batch, loss=10.116915]Training:  57%|█████▋    | 120/211 [55:18<40:59, 27.03s/batch, loss=10.260238]Training:  57%|█████▋    | 121/211 [55:18<29:49, 19.88s/batch, loss=10.260238]Training:  57%|█████▋    | 121/211 [55:49<29:49, 19.88s/batch, loss=10.376369]Training:  58%|█████▊    | 122/211 [55:49<34:28, 23.24s/batch, loss=10.376369]Training:  58%|█████▊    | 122/211 [57:12<34:28, 23.24s/batch, loss=9.997463] Training:  58%|█████▊    | 123/211 [57:12<1:00:13, 41.06s/batch, loss=9.997463]Training:  58%|█████▊    | 123/211 [57:15<1:00:13, 41.06s/batch, loss=9.831261]Training:  59%|█████▉    | 124/211 [57:15<43:07, 29.74s/batch, loss=9.831261]  Training:  59%|█████▉    | 124/211 [57:18<43:07, 29.74s/batch, loss=10.036950]Training:  59%|█████▉    | 125/211 [57:18<31:12, 21.78s/batch, loss=10.036950]Training:  59%|█████▉    | 125/211 [57:31<31:12, 21.78s/batch, loss=9.740777] Training:  60%|█████▉    | 126/211 [57:31<26:58, 19.05s/batch, loss=9.740777]Training:  60%|█████▉    | 126/211 [59:03<26:58, 19.05s/batch, loss=10.199321]Training:  60%|██████    | 127/211 [59:03<57:28, 41.06s/batch, loss=10.199321]Training:  60%|██████    | 127/211 [59:06<57:28, 41.06s/batch, loss=9.915348] Training:  61%|██████    | 128/211 [59:06<41:06, 29.71s/batch, loss=9.915348]Training:  61%|██████    | 128/211 [59:10<41:06, 29.71s/batch, loss=10.308422]Training:  61%|██████    | 129/211 [59:10<29:43, 21.75s/batch, loss=10.308422]Training:  61%|██████    | 129/211 [59:13<29:43, 21.75s/batch, loss=9.812437] Training:  62%|██████▏   | 130/211 [59:13<21:49, 16.17s/batch, loss=9.812437]Training:  62%|██████▏   | 130/211 [1:00:54<21:49, 16.17s/batch, loss=10.113368]Training:  62%|██████▏   | 131/211 [1:00:54<55:28, 41.60s/batch, loss=10.113368]Training:  62%|██████▏   | 131/211 [1:00:57<55:28, 41.60s/batch, loss=9.869469] Training:  63%|██████▎   | 132/211 [1:00:57<39:34, 30.06s/batch, loss=9.869469]Training:  63%|██████▎   | 132/211 [1:01:00<39:34, 30.06s/batch, loss=9.975030]Training:  63%|██████▎   | 133/211 [1:01:00<28:33, 21.97s/batch, loss=9.975030]Training:  63%|██████▎   | 133/211 [1:01:05<28:33, 21.97s/batch, loss=9.880448]Training:  64%|██████▎   | 134/211 [1:01:05<21:47, 16.99s/batch, loss=9.880448]Training:  64%|██████▎   | 134/211 [1:02:31<21:47, 16.99s/batch, loss=10.191664]Training:  64%|██████▍   | 135/211 [1:02:31<47:42, 37.67s/batch, loss=10.191664]Training:  64%|██████▍   | 135/211 [1:02:34<47:42, 37.67s/batch, loss=10.018322]Training:  64%|██████▍   | 136/211 [1:02:34<34:09, 27.33s/batch, loss=10.018322]Training:  64%|██████▍   | 136/211 [1:02:38<34:09, 27.33s/batch, loss=10.170573]Training:  65%|██████▍   | 137/211 [1:02:38<24:46, 20.08s/batch, loss=10.170573]Training:  65%|██████▍   | 137/211 [1:02:51<24:46, 20.08s/batch, loss=10.008099]Training:  65%|██████▌   | 138/211 [1:02:51<22:07, 18.19s/batch, loss=10.008099]Training:  65%|██████▌   | 138/211 [1:04:14<22:07, 18.19s/batch, loss=9.912902] Training:  66%|██████▌   | 139/211 [1:04:14<45:09, 37.63s/batch, loss=9.912902]Training:  66%|██████▌   | 139/211 [1:04:18<45:09, 37.63s/batch, loss=10.423869]Training:  66%|██████▋   | 140/211 [1:04:18<32:16, 27.28s/batch, loss=10.423869]Training:  66%|██████▋   | 140/211 [1:04:21<32:16, 27.28s/batch, loss=10.138515]Training:  67%|██████▋   | 141/211 [1:04:21<23:23, 20.05s/batch, loss=10.138515]Training:  67%|██████▋   | 141/211 [1:04:40<23:23, 20.05s/batch, loss=10.220149]Training:  67%|██████▋   | 142/211 [1:04:40<22:46, 19.80s/batch, loss=10.220149]Training:  67%|██████▋   | 142/211 [1:05:52<22:46, 19.80s/batch, loss=9.883378] Training:  68%|██████▊   | 143/211 [1:05:53<40:29, 35.72s/batch, loss=9.883378]Training:  68%|██████▊   | 143/211 [1:05:56<40:29, 35.72s/batch, loss=10.030785]Training:  68%|██████▊   | 144/211 [1:05:56<28:59, 25.97s/batch, loss=10.030785]Training:  68%|██████▊   | 144/211 [1:05:59<28:59, 25.97s/batch, loss=10.120188]Training:  69%|██████▊   | 145/211 [1:05:59<21:04, 19.16s/batch, loss=10.120188]Training:  69%|██████▊   | 145/211 [1:06:29<21:04, 19.16s/batch, loss=9.950243] Training:  69%|██████▉   | 146/211 [1:06:29<24:07, 22.27s/batch, loss=9.950243]Training:  69%|██████▉   | 146/211 [1:07:48<24:07, 22.27s/batch, loss=10.304955]Training:  70%|██████▉   | 147/211 [1:07:48<42:00, 39.38s/batch, loss=10.304955]Training:  70%|██████▉   | 147/211 [1:07:51<42:00, 39.38s/batch, loss=10.089828]Training:  70%|███████   | 148/211 [1:07:51<29:56, 28.52s/batch, loss=10.089828]Training:  70%|███████   | 148/211 [1:07:54<29:56, 28.52s/batch, loss=10.584658]Training:  71%|███████   | 149/211 [1:07:54<21:35, 20.89s/batch, loss=10.584658]Training:  71%|███████   | 149/211 [1:08:29<21:35, 20.89s/batch, loss=9.778253] Training:  71%|███████   | 150/211 [1:08:29<25:30, 25.09s/batch, loss=9.778253]Training:  71%|███████   | 150/211 [1:09:32<25:30, 25.09s/batch, loss=9.881128]Training:  72%|███████▏  | 151/211 [1:09:33<36:43, 36.73s/batch, loss=9.881128]Training:  72%|███████▏  | 151/211 [1:09:36<36:43, 36.73s/batch, loss=10.355005]Training:  72%|███████▏  | 152/211 [1:09:36<26:15, 26.70s/batch, loss=10.355005]Training:  72%|███████▏  | 152/211 [1:09:40<26:15, 26.70s/batch, loss=9.450214] Training:  73%|███████▎  | 153/211 [1:09:40<18:57, 19.61s/batch, loss=9.450214]Training:  73%|███████▎  | 153/211 [1:10:21<18:57, 19.61s/batch, loss=10.007742]Training:  73%|███████▎  | 154/211 [1:10:21<24:47, 26.10s/batch, loss=10.007742]Training:  73%|███████▎  | 154/211 [1:11:27<24:47, 26.10s/batch, loss=9.584835] Training:  73%|███████▎  | 155/211 [1:11:27<35:40, 38.23s/batch, loss=9.584835]Training:  73%|███████▎  | 155/211 [1:11:31<35:40, 38.23s/batch, loss=9.793813]Training:  74%|███████▍  | 156/211 [1:11:31<25:26, 27.76s/batch, loss=9.793813]Training:  74%|███████▍  | 156/211 [1:11:34<25:26, 27.76s/batch, loss=9.920134]Training:  74%|███████▍  | 157/211 [1:11:34<18:20, 20.37s/batch, loss=9.920134]Training:  74%|███████▍  | 157/211 [1:12:14<18:20, 20.37s/batch, loss=9.969797]Training:  75%|███████▍  | 158/211 [1:12:14<23:08, 26.20s/batch, loss=9.969797]Training:  75%|███████▍  | 158/211 [1:13:17<23:08, 26.20s/batch, loss=10.173264]Training:  75%|███████▌  | 159/211 [1:13:17<32:23, 37.37s/batch, loss=10.173264]Training:  75%|███████▌  | 159/211 [1:13:20<32:23, 37.37s/batch, loss=9.615941] Training:  76%|███████▌  | 160/211 [1:13:20<23:02, 27.11s/batch, loss=9.615941]Training:  76%|███████▌  | 160/211 [1:13:23<23:02, 27.11s/batch, loss=9.708860]Training:  76%|███████▋  | 161/211 [1:13:23<16:35, 19.92s/batch, loss=9.708860]Training:  76%|███████▋  | 161/211 [1:14:15<16:35, 19.92s/batch, loss=9.871670]Training:  77%|███████▋  | 162/211 [1:14:15<23:57, 29.34s/batch, loss=9.871670]Training:  77%|███████▋  | 162/211 [1:15:07<23:57, 29.34s/batch, loss=10.039166]Training:  77%|███████▋  | 163/211 [1:15:07<28:59, 36.24s/batch, loss=10.039166]Training:  77%|███████▋  | 163/211 [1:15:10<28:59, 36.24s/batch, loss=10.040380]Training:  78%|███████▊  | 164/211 [1:15:10<20:37, 26.33s/batch, loss=10.040380]Training:  78%|███████▊  | 164/211 [1:15:13<20:37, 26.33s/batch, loss=9.720695] Training:  78%|███████▊  | 165/211 [1:15:13<14:51, 19.38s/batch, loss=9.720695]Training:  78%|███████▊  | 165/211 [1:16:02<14:51, 19.38s/batch, loss=9.936625]Training:  79%|███████▊  | 166/211 [1:16:02<21:06, 28.14s/batch, loss=9.936625]Training:  79%|███████▊  | 166/211 [1:17:05<21:06, 28.14s/batch, loss=10.142872]Training:  79%|███████▉  | 167/211 [1:17:06<28:32, 38.93s/batch, loss=10.142872]Training:  79%|███████▉  | 167/211 [1:17:09<28:32, 38.93s/batch, loss=10.213561]Training:  80%|███████▉  | 168/211 [1:17:09<20:12, 28.19s/batch, loss=10.213561]Training:  80%|███████▉  | 168/211 [1:17:12<20:12, 28.19s/batch, loss=9.535416] Training:  80%|████████  | 169/211 [1:17:12<14:27, 20.66s/batch, loss=9.535416]Training:  80%|████████  | 169/211 [1:18:09<14:27, 20.66s/batch, loss=10.184249]Training:  81%|████████  | 170/211 [1:18:09<21:35, 31.59s/batch, loss=10.184249]Training:  81%|████████  | 170/211 [1:19:04<21:35, 31.59s/batch, loss=10.101482]Training:  81%|████████  | 171/211 [1:19:04<25:42, 38.57s/batch, loss=10.101482]Training:  81%|████████  | 171/211 [1:19:07<25:42, 38.57s/batch, loss=9.897917] Training:  82%|████████▏ | 172/211 [1:19:07<18:10, 27.96s/batch, loss=9.897917]Training:  82%|████████▏ | 172/211 [1:19:11<18:10, 27.96s/batch, loss=9.593729]Training:  82%|████████▏ | 173/211 [1:19:11<13:00, 20.55s/batch, loss=9.593729]Training:  82%|████████▏ | 173/211 [1:19:45<13:00, 20.55s/batch, loss=10.215806]Training:  82%|████████▏ | 174/211 [1:19:45<15:08, 24.56s/batch, loss=10.215806]Training:  82%|████████▏ | 174/211 [1:20:51<15:08, 24.56s/batch, loss=9.886729] Training:  83%|████████▎ | 175/211 [1:20:52<22:27, 37.44s/batch, loss=9.886729]Training:  83%|████████▎ | 175/211 [1:20:55<22:27, 37.44s/batch, loss=9.819885]Training:  83%|████████▎ | 176/211 [1:20:55<15:49, 27.14s/batch, loss=9.819885]Training:  83%|████████▎ | 176/211 [1:20:58<15:49, 27.14s/batch, loss=10.095043]Training:  84%|████████▍ | 177/211 [1:20:58<11:18, 19.95s/batch, loss=10.095043]Training:  84%|████████▍ | 177/211 [1:21:39<11:18, 19.95s/batch, loss=9.851875] Training:  84%|████████▍ | 178/211 [1:21:39<14:22, 26.14s/batch, loss=9.851875]Training:  84%|████████▍ | 178/211 [1:22:38<14:22, 26.14s/batch, loss=9.641413]Training:  85%|████████▍ | 179/211 [1:22:39<19:18, 36.22s/batch, loss=9.641413]Training:  85%|████████▍ | 179/211 [1:22:42<19:18, 36.22s/batch, loss=9.939138]Training:  85%|████████▌ | 180/211 [1:22:42<13:36, 26.33s/batch, loss=9.939138]Training:  85%|████████▌ | 180/211 [1:22:45<13:36, 26.33s/batch, loss=9.374670]Training:  86%|████████▌ | 181/211 [1:22:45<09:41, 19.40s/batch, loss=9.374670]Training:  86%|████████▌ | 181/211 [1:23:27<09:41, 19.40s/batch, loss=9.897142]Training:  86%|████████▋ | 182/211 [1:23:27<12:40, 26.23s/batch, loss=9.897142]Training:  86%|████████▋ | 182/211 [1:24:36<12:40, 26.23s/batch, loss=9.873549]Training:  87%|████████▋ | 183/211 [1:24:36<18:08, 38.86s/batch, loss=9.873549]Training:  87%|████████▋ | 183/211 [1:24:39<18:08, 38.86s/batch, loss=9.854139]Training:  87%|████████▋ | 184/211 [1:24:39<12:41, 28.20s/batch, loss=9.854139]Training:  87%|████████▋ | 184/211 [1:24:42<12:41, 28.20s/batch, loss=9.858870]Training:  88%|████████▊ | 185/211 [1:24:42<08:58, 20.70s/batch, loss=9.858870]Training:  88%|████████▊ | 185/211 [1:25:18<08:58, 20.70s/batch, loss=9.594008]Training:  88%|████████▊ | 186/211 [1:25:18<10:32, 25.31s/batch, loss=9.594008]Training:  88%|████████▊ | 186/211 [1:26:18<10:32, 25.31s/batch, loss=9.241778]Training:  89%|████████▊ | 187/211 [1:26:19<14:24, 36.04s/batch, loss=9.241778]Training:  89%|████████▊ | 187/211 [1:26:22<14:24, 36.04s/batch, loss=9.702324]Training:  89%|████████▉ | 188/211 [1:26:22<10:02, 26.18s/batch, loss=9.702324]Training:  89%|████████▉ | 188/211 [1:26:26<10:02, 26.18s/batch, loss=9.736013]Training:  90%|████████▉ | 189/211 [1:26:26<07:04, 19.28s/batch, loss=9.736013]Training:  90%|████████▉ | 189/211 [1:27:12<07:04, 19.28s/batch, loss=10.081250]Training:  90%|█████████ | 190/211 [1:27:12<09:38, 27.56s/batch, loss=10.081250]Training:  90%|█████████ | 190/211 [1:28:09<09:38, 27.56s/batch, loss=9.992622] Training:  91%|█████████ | 191/211 [1:28:09<12:06, 36.31s/batch, loss=9.992622]Training:  91%|█████████ | 191/211 [1:28:12<12:06, 36.31s/batch, loss=9.755955]Training:  91%|█████████ | 192/211 [1:28:12<08:20, 26.36s/batch, loss=9.755955]Training:  91%|█████████ | 192/211 [1:28:16<08:20, 26.36s/batch, loss=9.702816]Training:  91%|█████████▏| 193/211 [1:28:16<05:49, 19.42s/batch, loss=9.702816]Training:  91%|█████████▏| 193/211 [1:29:10<05:49, 19.42s/batch, loss=9.253906]Training:  92%|█████████▏| 194/211 [1:29:10<08:28, 29.93s/batch, loss=9.253906]Training:  92%|█████████▏| 194/211 [1:29:44<08:28, 29.93s/batch, loss=10.044985]Training:  92%|█████████▏| 195/211 [1:29:44<08:19, 31.23s/batch, loss=10.044985]Training:  92%|█████████▏| 195/211 [1:29:48<08:19, 31.23s/batch, loss=9.831858] Training:  93%|█████████▎| 196/211 [1:29:48<05:42, 22.83s/batch, loss=9.831858]Training:  93%|█████████▎| 196/211 [1:29:51<05:42, 22.83s/batch, loss=9.921906]Training:  93%|█████████▎| 197/211 [1:29:51<03:56, 16.91s/batch, loss=9.921906]Training:  93%|█████████▎| 197/211 [1:31:01<03:56, 16.91s/batch, loss=9.981200]Training:  94%|█████████▍| 198/211 [1:31:01<07:07, 32.91s/batch, loss=9.981200]Training:  94%|█████████▍| 198/211 [1:31:34<07:07, 32.91s/batch, loss=9.865279]Training:  94%|█████████▍| 199/211 [1:31:34<06:35, 32.98s/batch, loss=9.865279]Training:  94%|█████████▍| 199/211 [1:31:37<06:35, 32.98s/batch, loss=10.276174]Training:  95%|█████████▍| 200/211 [1:31:37<04:24, 24.05s/batch, loss=10.276174]Training:  95%|█████████▍| 200/211 [1:31:40<04:24, 24.05s/batch, loss=9.756313] Training:  95%|█████████▌| 201/211 [1:31:40<02:57, 17.77s/batch, loss=9.756313]Training:  95%|█████████▌| 201/211 [1:32:54<02:57, 17.77s/batch, loss=9.498598]Training:  96%|█████████▌| 202/211 [1:32:54<05:11, 34.56s/batch, loss=9.498598]Training:  96%|█████████▌| 202/211 [1:33:24<05:11, 34.56s/batch, loss=9.572355]Training:  96%|█████████▌| 203/211 [1:33:24<04:26, 33.28s/batch, loss=9.572355]Training:  96%|█████████▌| 203/211 [1:33:28<04:26, 33.28s/batch, loss=10.059968]Training:  97%|█████████▋| 204/211 [1:33:28<02:49, 24.23s/batch, loss=10.059968]Training:  97%|█████████▋| 204/211 [1:33:31<02:49, 24.23s/batch, loss=9.609309] Training:  97%|█████████▋| 205/211 [1:33:31<01:47, 17.90s/batch, loss=9.609309]Training:  97%|█████████▋| 205/211 [1:34:36<01:47, 17.90s/batch, loss=9.874928]Training:  98%|█████████▊| 206/211 [1:34:36<02:40, 32.10s/batch, loss=9.874928]Training:  98%|█████████▊| 206/211 [1:35:05<02:40, 32.10s/batch, loss=9.721162]Training:  98%|█████████▊| 207/211 [1:35:05<02:05, 31.32s/batch, loss=9.721162]Training:  98%|█████████▊| 207/211 [1:35:09<02:05, 31.32s/batch, loss=9.931974]Training:  99%|█████████▊| 208/211 [1:35:09<01:08, 22.89s/batch, loss=9.931974]Training:  99%|█████████▊| 208/211 [1:35:12<01:08, 22.89s/batch, loss=10.309876]Training:  99%|█████████▉| 209/211 [1:35:12<00:33, 16.99s/batch, loss=10.309876]Training:  99%|█████████▉| 209/211 [1:35:37<00:33, 16.99s/batch, loss=9.891026] Training: 100%|█████████▉| 210/211 [1:35:37<00:19, 19.33s/batch, loss=9.891026]Training: 100%|█████████▉| 210/211 [1:35:37<00:19, 19.33s/batch, loss=9.856959]Training: 100%|██████████| 211/211 [1:35:37<00:00, 13.75s/batch, loss=9.856959]Training: 100%|██████████| 211/211 [1:35:37<00:00, 27.19s/batch, loss=9.856959]
Epoch 8, Train Loss: 10.0367, Val Loss: 9.7851
Training:   0%|          | 0/211 [00:00<?, ?batch/s]Training:   0%|          | 0/211 [01:47<?, ?batch/s, loss=9.569797]Training:   0%|          | 1/211 [01:47<6:17:40, 107.91s/batch, loss=9.569797]Training:   0%|          | 1/211 [01:51<6:17:40, 107.91s/batch, loss=10.172518]Training:   1%|          | 2/211 [01:51<2:41:13, 46.29s/batch, loss=10.172518] Training:   1%|          | 2/211 [01:54<2:41:13, 46.29s/batch, loss=9.815906] Training:   1%|▏         | 3/211 [01:54<1:32:15, 26.61s/batch, loss=9.815906]Training:   1%|▏         | 3/211 [01:57<1:32:15, 26.61s/batch, loss=9.850185]Training:   2%|▏         | 4/211 [01:57<59:56, 17.37s/batch, loss=9.850185]  Training:   2%|▏         | 4/211 [03:21<59:56, 17.37s/batch, loss=9.722368]Training:   2%|▏         | 5/211 [03:21<2:21:56, 41.34s/batch, loss=9.722368]Training:   2%|▏         | 5/211 [03:24<2:21:56, 41.34s/batch, loss=10.124853]Training:   3%|▎         | 6/211 [03:24<1:36:51, 28.35s/batch, loss=10.124853]Training:   3%|▎         | 6/211 [03:27<1:36:51, 28.35s/batch, loss=9.778172] Training:   3%|▎         | 7/211 [03:27<1:08:25, 20.12s/batch, loss=9.778172]Training:   3%|▎         | 7/211 [03:30<1:08:25, 20.12s/batch, loss=9.353144]Training:   4%|▍         | 8/211 [03:30<49:57, 14.76s/batch, loss=9.353144]  Training:   4%|▍         | 8/211 [04:56<49:57, 14.76s/batch, loss=9.493235]Training:   4%|▍         | 9/211 [04:56<2:04:27, 36.97s/batch, loss=9.493235]Training:   4%|▍         | 9/211 [04:59<2:04:27, 36.97s/batch, loss=10.220785]Training:   5%|▍         | 10/211 [04:59<1:28:52, 26.53s/batch, loss=10.220785]Training:   5%|▍         | 10/211 [05:03<1:28:52, 26.53s/batch, loss=9.931401] Training:   5%|▌         | 11/211 [05:03<1:04:36, 19.38s/batch, loss=9.931401]Training:   5%|▌         | 11/211 [05:06<1:04:36, 19.38s/batch, loss=9.734765]Training:   6%|▌         | 12/211 [05:06<47:54, 14.44s/batch, loss=9.734765]  Training:   6%|▌         | 12/211 [06:36<47:54, 14.44s/batch, loss=9.958392]Training:   6%|▌         | 13/211 [06:36<2:03:54, 37.55s/batch, loss=9.958392]Training:   6%|▌         | 13/211 [06:40<2:03:54, 37.55s/batch, loss=9.682392]Training:   7%|▋         | 14/211 [06:40<1:29:11, 27.16s/batch, loss=9.682392]Training:   7%|▋         | 14/211 [06:43<1:29:11, 27.16s/batch, loss=9.849234]Training:   7%|▋         | 15/211 [06:43<1:05:02, 19.91s/batch, loss=9.849234]Training:   7%|▋         | 15/211 [06:46<1:05:02, 19.91s/batch, loss=10.161896]Training:   8%|▊         | 16/211 [06:46<48:21, 14.88s/batch, loss=10.161896]  Training:   8%|▊         | 16/211 [08:22<48:21, 14.88s/batch, loss=9.398974] Training:   8%|▊         | 17/211 [08:23<2:07:43, 39.50s/batch, loss=9.398974]Training:   8%|▊         | 17/211 [08:47<2:07:43, 39.50s/batch, loss=9.752605]Training:   9%|▊         | 18/211 [08:47<1:52:50, 35.08s/batch, loss=9.752605]Training:   9%|▊         | 18/211 [08:51<1:52:50, 35.08s/batch, loss=9.531988]Training:   9%|▉         | 19/211 [08:51<1:21:31, 25.47s/batch, loss=9.531988]Training:   9%|▉         | 19/211 [08:54<1:21:31, 25.47s/batch, loss=9.911458]Training:   9%|▉         | 20/211 [08:54<59:48, 18.79s/batch, loss=9.911458]  Training:   9%|▉         | 20/211 [10:07<59:48, 18.79s/batch, loss=9.423511]Training:  10%|▉         | 21/211 [10:08<1:52:14, 35.44s/batch, loss=9.423511]Training:  10%|▉         | 21/211 [10:29<1:52:14, 35.44s/batch, loss=9.743806]Training:  10%|█         | 22/211 [10:29<1:37:42, 31.02s/batch, loss=9.743806]Training:  10%|█         | 22/211 [10:32<1:37:42, 31.02s/batch, loss=9.913378]Training:  11%|█         | 23/211 [10:32<1:11:05, 22.69s/batch, loss=9.913378]Training:  11%|█         | 23/211 [10:35<1:11:05, 22.69s/batch, loss=10.128012]Training:  11%|█▏        | 24/211 [10:35<52:29, 16.84s/batch, loss=10.128012]  Training:  11%|█▏        | 24/211 [11:58<52:29, 16.84s/batch, loss=10.130060]Training:  12%|█▏        | 25/211 [11:58<1:54:00, 36.77s/batch, loss=10.130060]Training:  12%|█▏        | 25/211 [12:17<1:54:00, 36.77s/batch, loss=9.312215] Training:  12%|█▏        | 26/211 [12:17<1:36:55, 31.43s/batch, loss=9.312215]Training:  12%|█▏        | 26/211 [12:21<1:36:55, 31.43s/batch, loss=10.125634]Training:  13%|█▎        | 27/211 [12:21<1:10:22, 22.95s/batch, loss=10.125634]Training:  13%|█▎        | 27/211 [12:24<1:10:22, 22.95s/batch, loss=9.658891] Training:  13%|█▎        | 28/211 [12:24<52:00, 17.05s/batch, loss=9.658891]  Training:  13%|█▎        | 28/211 [13:42<52:00, 17.05s/batch, loss=9.357271]Training:  14%|█▎        | 29/211 [13:43<1:48:06, 35.64s/batch, loss=9.357271]Training:  14%|█▎        | 29/211 [14:08<1:48:06, 35.64s/batch, loss=9.845233]Training:  14%|█▍        | 30/211 [14:08<1:37:43, 32.40s/batch, loss=9.845233]Training:  14%|█▍        | 30/211 [14:11<1:37:43, 32.40s/batch, loss=10.023561]Training:  15%|█▍        | 31/211 [14:11<1:10:52, 23.62s/batch, loss=10.023561]Training:  15%|█▍        | 31/211 [14:14<1:10:52, 23.62s/batch, loss=9.579316] Training:  15%|█▌        | 32/211 [14:14<52:08, 17.48s/batch, loss=9.579316]  Training:  15%|█▌        | 32/211 [15:36<52:08, 17.48s/batch, loss=9.984583]Training:  16%|█▌        | 33/211 [15:36<1:49:37, 36.95s/batch, loss=9.984583]Training:  16%|█▌        | 33/211 [15:58<1:49:37, 36.95s/batch, loss=9.616651]Training:  16%|█▌        | 34/211 [15:58<1:35:20, 32.32s/batch, loss=9.616651]Training:  16%|█▌        | 34/211 [16:01<1:35:20, 32.32s/batch, loss=9.763520]Training:  17%|█▋        | 35/211 [16:01<1:09:08, 23.57s/batch, loss=9.763520]Training:  17%|█▋        | 35/211 [16:04<1:09:08, 23.57s/batch, loss=10.037024]Training:  17%|█▋        | 36/211 [16:04<50:50, 17.43s/batch, loss=10.037024]  Training:  17%|█▋        | 36/211 [17:35<50:50, 17.43s/batch, loss=9.664807] Training:  18%|█▊        | 37/211 [17:36<1:54:58, 39.65s/batch, loss=9.664807]Training:  18%|█▊        | 37/211 [17:39<1:54:58, 39.65s/batch, loss=9.760043]Training:  18%|█▊        | 38/211 [17:39<1:22:47, 28.71s/batch, loss=9.760043]Training:  18%|█▊        | 38/211 [17:42<1:22:47, 28.71s/batch, loss=9.452507]Training:  18%|█▊        | 39/211 [17:42<1:00:24, 21.07s/batch, loss=9.452507]Training:  18%|█▊        | 39/211 [17:45<1:00:24, 21.07s/batch, loss=9.659864]Training:  19%|█▉        | 40/211 [17:45<44:45, 15.71s/batch, loss=9.659864]  Training:  19%|█▉        | 40/211 [19:19<44:45, 15.71s/batch, loss=9.571651]Training:  19%|█▉        | 41/211 [19:20<1:51:23, 39.32s/batch, loss=9.571651]Training:  19%|█▉        | 41/211 [19:35<1:51:23, 39.32s/batch, loss=9.687566]Training:  20%|█▉        | 42/211 [19:35<1:30:19, 32.07s/batch, loss=9.687566]Training:  20%|█▉        | 42/211 [19:38<1:30:19, 32.07s/batch, loss=9.752111]Training:  20%|██        | 43/211 [19:38<1:05:36, 23.43s/batch, loss=9.752111]Training:  20%|██        | 43/211 [19:41<1:05:36, 23.43s/batch, loss=9.514830]Training:  21%|██        | 44/211 [19:41<48:16, 17.34s/batch, loss=9.514830]  Training:  21%|██        | 44/211 [21:01<48:16, 17.34s/batch, loss=9.445348]Training:  21%|██▏       | 45/211 [21:01<1:39:54, 36.11s/batch, loss=9.445348]Training:  21%|██▏       | 45/211 [21:22<1:39:54, 36.11s/batch, loss=9.610581]Training:  22%|██▏       | 46/211 [21:22<1:26:31, 31.47s/batch, loss=9.610581]Training:  22%|██▏       | 46/211 [21:25<1:26:31, 31.47s/batch, loss=9.732040]Training:  22%|██▏       | 47/211 [21:25<1:02:46, 22.96s/batch, loss=9.732040]Training:  22%|██▏       | 47/211 [21:28<1:02:46, 22.96s/batch, loss=9.845812]Training:  23%|██▎       | 48/211 [21:28<46:12, 17.01s/batch, loss=9.845812]  Training:  23%|██▎       | 48/211 [22:57<46:12, 17.01s/batch, loss=9.701853]Training:  23%|██▎       | 49/211 [22:57<1:44:06, 38.56s/batch, loss=9.701853]Training:  23%|██▎       | 49/211 [23:05<1:44:06, 38.56s/batch, loss=9.600516]Training:  24%|██▎       | 50/211 [23:05<1:18:38, 29.31s/batch, loss=9.600516]Training:  24%|██▎       | 50/211 [23:08<1:18:38, 29.31s/batch, loss=10.048732]Training:  24%|██▍       | 51/211 [23:08<57:14, 21.47s/batch, loss=10.048732]  Training:  24%|██▍       | 51/211 [23:11<57:14, 21.47s/batch, loss=9.973801] Training:  25%|██▍       | 52/211 [23:11<42:19, 15.97s/batch, loss=9.973801]Training:  25%|██▍       | 52/211 [24:24<42:19, 15.97s/batch, loss=9.714871]Training:  25%|██▌       | 53/211 [24:24<1:27:21, 33.17s/batch, loss=9.714871]Training:  25%|██▌       | 53/211 [24:58<1:27:21, 33.17s/batch, loss=9.637656]Training:  26%|██▌       | 54/211 [24:58<1:27:30, 33.44s/batch, loss=9.637656]Training:  26%|██▌       | 54/211 [25:01<1:27:30, 33.44s/batch, loss=9.424399]Training:  26%|██▌       | 55/211 [25:01<1:03:16, 24.34s/batch, loss=9.424399]Training:  26%|██▌       | 55/211 [25:05<1:03:16, 24.34s/batch, loss=9.616829]Training:  27%|██▋       | 56/211 [25:05<46:27, 17.98s/batch, loss=9.616829]  Training:  27%|██▋       | 56/211 [26:06<46:27, 17.98s/batch, loss=10.141726]Training:  27%|██▋       | 57/211 [26:07<1:20:09, 31.23s/batch, loss=10.141726]Training:  27%|██▋       | 57/211 [26:38<1:20:09, 31.23s/batch, loss=9.672778] Training:  27%|██▋       | 58/211 [26:38<1:19:52, 31.32s/batch, loss=9.672778]Training:  27%|██▋       | 58/211 [26:41<1:19:52, 31.32s/batch, loss=9.628979]Training:  28%|██▊       | 59/211 [26:41<57:58, 22.88s/batch, loss=9.628979]  Training:  28%|██▊       | 59/211 [26:45<57:58, 22.88s/batch, loss=9.543563]Training:  28%|██▊       | 60/211 [26:45<42:50, 17.02s/batch, loss=9.543563]Training:  28%|██▊       | 60/211 [27:58<42:50, 17.02s/batch, loss=9.334260]Training:  29%|██▉       | 61/211 [27:58<1:25:02, 34.02s/batch, loss=9.334260]Training:  29%|██▉       | 61/211 [28:25<1:25:02, 34.02s/batch, loss=9.436232]Training:  29%|██▉       | 62/211 [28:25<1:18:50, 31.75s/batch, loss=9.436232]Training:  29%|██▉       | 62/211 [28:28<1:18:50, 31.75s/batch, loss=9.313647]Training:  30%|██▉       | 63/211 [28:28<57:17, 23.23s/batch, loss=9.313647]  Training:  30%|██▉       | 63/211 [28:31<57:17, 23.23s/batch, loss=9.485825]Training:  30%|███       | 64/211 [28:31<42:10, 17.22s/batch, loss=9.485825]Training:  30%|███       | 64/211 [29:45<42:10, 17.22s/batch, loss=9.427602]Training:  31%|███       | 65/211 [29:45<1:23:18, 34.24s/batch, loss=9.427602]Training:  31%|███       | 65/211 [30:08<1:23:18, 34.24s/batch, loss=9.972974]Training:  31%|███▏      | 66/211 [30:08<1:14:40, 30.90s/batch, loss=9.972974]Training:  31%|███▏      | 66/211 [30:12<1:14:40, 30.90s/batch, loss=9.648675]Training:  32%|███▏      | 67/211 [30:12<54:07, 22.55s/batch, loss=9.648675]  Training:  32%|███▏      | 67/211 [30:15<54:07, 22.55s/batch, loss=9.391148]Training:  32%|███▏      | 68/211 [30:15<40:05, 16.82s/batch, loss=9.391148]Training:  32%|███▏      | 68/211 [31:20<40:05, 16.82s/batch, loss=9.853696]Training:  33%|███▎      | 69/211 [31:20<1:14:05, 31.31s/batch, loss=9.853696]Training:  33%|███▎      | 69/211 [31:51<1:14:05, 31.31s/batch, loss=9.753138]Training:  33%|███▎      | 70/211 [31:51<1:13:22, 31.22s/batch, loss=9.753138]Training:  33%|███▎      | 70/211 [31:54<1:13:22, 31.22s/batch, loss=9.424483]Training:  34%|███▎      | 71/211 [31:54<53:11, 22.80s/batch, loss=9.424483]  Training:  34%|███▎      | 71/211 [31:58<53:11, 22.80s/batch, loss=9.592381]Training:  34%|███▍      | 72/211 [31:58<39:13, 16.93s/batch, loss=9.592381]Training:  34%|███▍      | 72/211 [33:00<39:13, 16.93s/batch, loss=9.684642]Training:  35%|███▍      | 73/211 [33:00<1:10:18, 30.57s/batch, loss=9.684642]Training:  35%|███▍      | 73/211 [33:46<1:10:18, 30.57s/batch, loss=9.700982]Training:  35%|███▌      | 74/211 [33:46<1:20:24, 35.22s/batch, loss=9.700982]Training:  35%|███▌      | 74/211 [33:49<1:20:24, 35.22s/batch, loss=9.711999]Training:  36%|███▌      | 75/211 [33:49<58:02, 25.61s/batch, loss=9.711999]  Training:  36%|███▌      | 75/211 [33:53<58:02, 25.61s/batch, loss=9.576019]Training:  36%|███▌      | 76/211 [33:53<42:37, 18.95s/batch, loss=9.576019]Training:  36%|███▌      | 76/211 [34:45<42:37, 18.95s/batch, loss=9.920269]Training:  36%|███▋      | 77/211 [34:45<1:04:37, 28.94s/batch, loss=9.920269]Training:  36%|███▋      | 77/211 [35:36<1:04:37, 28.94s/batch, loss=9.772289]Training:  37%|███▋      | 78/211 [35:36<1:19:14, 35.75s/batch, loss=9.772289]Training:  37%|███▋      | 78/211 [35:40<1:19:14, 35.75s/batch, loss=10.014936]Training:  37%|███▋      | 79/211 [35:40<57:09, 25.98s/batch, loss=10.014936]  Training:  37%|███▋      | 79/211 [35:43<57:09, 25.98s/batch, loss=9.459918] Training:  38%|███▊      | 80/211 [35:43<41:45, 19.13s/batch, loss=9.459918]Training:  38%|███▊      | 80/211 [36:24<41:45, 19.13s/batch, loss=9.420196]Training:  38%|███▊      | 81/211 [36:24<55:39, 25.69s/batch, loss=9.420196]Training:  38%|███▊      | 81/211 [37:21<55:39, 25.69s/batch, loss=9.858210]Training:  39%|███▉      | 82/211 [37:21<1:15:43, 35.22s/batch, loss=9.858210]Training:  39%|███▉      | 82/211 [37:24<1:15:43, 35.22s/batch, loss=9.850858]Training:  39%|███▉      | 83/211 [37:24<54:38, 25.62s/batch, loss=9.850858]  Training:  39%|███▉      | 83/211 [37:28<54:38, 25.62s/batch, loss=9.506737]Training:  40%|███▉      | 84/211 [37:28<39:55, 18.86s/batch, loss=9.506737]Training:  40%|███▉      | 84/211 [38:20<39:55, 18.86s/batch, loss=9.370321]Training:  40%|████      | 85/211 [38:20<1:01:02, 29.07s/batch, loss=9.370321]Training:  40%|████      | 85/211 [39:16<1:01:02, 29.07s/batch, loss=9.530811]Training:  41%|████      | 86/211 [39:17<1:17:38, 37.27s/batch, loss=9.530811]Training:  41%|████      | 86/211 [39:20<1:17:38, 37.27s/batch, loss=9.350657]Training:  41%|████      | 87/211 [39:20<55:51, 27.03s/batch, loss=9.350657]  Training:  41%|████      | 87/211 [39:23<55:51, 27.03s/batch, loss=9.595915]Training:  42%|████▏     | 88/211 [39:23<40:40, 19.84s/batch, loss=9.595915]Training:  42%|████▏     | 88/211 [40:18<40:40, 19.84s/batch, loss=9.686577]Training:  42%|████▏     | 89/211 [40:18<1:02:00, 30.49s/batch, loss=9.686577]Training:  42%|████▏     | 89/211 [41:08<1:02:00, 30.49s/batch, loss=9.774303]Training:  43%|████▎     | 90/211 [41:09<1:13:24, 36.40s/batch, loss=9.774303]Training:  43%|████▎     | 90/211 [41:12<1:13:24, 36.40s/batch, loss=9.820105]Training:  43%|████▎     | 91/211 [41:12<52:54, 26.45s/batch, loss=9.820105]  Training:  43%|████▎     | 91/211 [41:15<52:54, 26.45s/batch, loss=9.651909]Training:  44%|████▎     | 92/211 [41:15<38:33, 19.44s/batch, loss=9.651909]Training:  44%|████▎     | 92/211 [41:54<38:33, 19.44s/batch, loss=9.811761]Training:  44%|████▍     | 93/211 [41:54<50:05, 25.47s/batch, loss=9.811761]Training:  44%|████▍     | 93/211 [42:57<50:05, 25.47s/batch, loss=9.357706]Training:  45%|████▍     | 94/211 [42:57<1:11:28, 36.66s/batch, loss=9.357706]Training:  45%|████▍     | 94/211 [43:00<1:11:28, 36.66s/batch, loss=9.877934]Training:  45%|████▌     | 95/211 [43:00<51:28, 26.62s/batch, loss=9.877934]  Training:  45%|████▌     | 95/211 [43:04<51:28, 26.62s/batch, loss=9.248281]Training:  45%|████▌     | 96/211 [43:04<37:33, 19.59s/batch, loss=9.248281]Training:  45%|████▌     | 96/211 [43:41<37:33, 19.59s/batch, loss=9.783686]Training:  46%|████▌     | 97/211 [43:41<47:08, 24.81s/batch, loss=9.783686]Training:  46%|████▌     | 97/211 [44:42<47:08, 24.81s/batch, loss=9.524835]Training:  46%|████▋     | 98/211 [44:43<1:07:54, 36.05s/batch, loss=9.524835]Training:  46%|████▋     | 98/211 [44:46<1:07:54, 36.05s/batch, loss=9.390756]Training:  47%|████▋     | 99/211 [44:46<48:51, 26.17s/batch, loss=9.390756]  Training:  47%|████▋     | 99/211 [44:49<48:51, 26.17s/batch, loss=9.645659]Training:  47%|████▋     | 100/211 [44:49<35:47, 19.35s/batch, loss=9.645659]Training:  47%|████▋     | 100/211 [45:35<35:47, 19.35s/batch, loss=9.462926]Training:  48%|████▊     | 101/211 [45:35<49:48, 27.16s/batch, loss=9.462926]Training:  48%|████▊     | 101/211 [46:43<49:48, 27.16s/batch, loss=9.519480]Training:  48%|████▊     | 102/211 [46:43<1:11:54, 39.58s/batch, loss=9.519480]Training:  48%|████▊     | 102/211 [46:46<1:11:54, 39.58s/batch, loss=9.909378]Training:  49%|████▉     | 103/211 [46:46<51:33, 28.64s/batch, loss=9.909378]  Training:  49%|████▉     | 103/211 [46:50<51:33, 28.64s/batch, loss=10.117663]Training:  49%|████▉     | 104/211 [46:50<37:28, 21.02s/batch, loss=10.117663]Training:  49%|████▉     | 104/211 [47:21<37:28, 21.02s/batch, loss=9.515288] Training:  50%|████▉     | 105/211 [47:21<42:31, 24.07s/batch, loss=9.515288]Training:  50%|████▉     | 105/211 [48:31<42:31, 24.07s/batch, loss=9.364189]Training:  50%|█████     | 106/211 [48:31<1:06:32, 38.02s/batch, loss=9.364189]Training:  50%|█████     | 106/211 [48:35<1:06:32, 38.02s/batch, loss=9.284500]Training:  51%|█████     | 107/211 [48:35<47:47, 27.57s/batch, loss=9.284500]  Training:  51%|█████     | 107/211 [48:38<47:47, 27.57s/batch, loss=9.921658]Training:  51%|█████     | 108/211 [48:38<34:44, 20.23s/batch, loss=9.921658]Training:  51%|█████     | 108/211 [49:07<34:44, 20.23s/batch, loss=9.772962]Training:  52%|█████▏    | 109/211 [49:07<39:00, 22.95s/batch, loss=9.772962]Training:  52%|█████▏    | 109/211 [50:24<39:00, 22.95s/batch, loss=9.765648]Training:  52%|█████▏    | 110/211 [50:24<1:05:52, 39.13s/batch, loss=9.765648]Training:  52%|█████▏    | 110/211 [50:27<1:05:52, 39.13s/batch, loss=9.590292]Training:  53%|█████▎    | 111/211 [50:27<47:16, 28.37s/batch, loss=9.590292]  Training:  53%|█████▎    | 111/211 [50:30<47:16, 28.37s/batch, loss=9.803344]Training:  53%|█████▎    | 112/211 [50:30<34:17, 20.78s/batch, loss=9.803344]Training:  53%|█████▎    | 112/211 [50:54<34:17, 20.78s/batch, loss=9.301708]Training:  54%|█████▎    | 113/211 [50:54<35:36, 21.80s/batch, loss=9.301708]Training:  54%|█████▎    | 113/211 [52:15<35:36, 21.80s/batch, loss=9.917845]Training:  54%|█████▍    | 114/211 [52:16<1:04:26, 39.86s/batch, loss=9.917845]Training:  54%|█████▍    | 114/211 [52:20<1:04:26, 39.86s/batch, loss=9.659886]Training:  55%|█████▍    | 115/211 [52:20<46:10, 28.86s/batch, loss=9.659886]  Training:  55%|█████▍    | 115/211 [52:23<46:10, 28.86s/batch, loss=9.540741]Training:  55%|█████▍    | 116/211 [52:23<33:33, 21.19s/batch, loss=9.540741]Training:  55%|█████▍    | 116/211 [52:45<33:33, 21.19s/batch, loss=9.449703]Training:  55%|█████▌    | 117/211 [52:45<33:30, 21.39s/batch, loss=9.449703]Training:  55%|█████▌    | 117/211 [54:04<33:30, 21.39s/batch, loss=9.307191]Training:  56%|█████▌    | 118/211 [54:04<1:00:13, 38.85s/batch, loss=9.307191]Training:  56%|█████▌    | 118/211 [54:08<1:00:13, 38.85s/batch, loss=9.558485]Training:  56%|█████▋    | 119/211 [54:08<43:09, 28.15s/batch, loss=9.558485]  Training:  56%|█████▋    | 119/211 [54:11<43:09, 28.15s/batch, loss=8.973354]Training:  57%|█████▋    | 120/211 [54:11<31:19, 20.65s/batch, loss=8.973354]Training:  57%|█████▋    | 120/211 [54:31<31:19, 20.65s/batch, loss=9.490727]Training:  57%|█████▋    | 121/211 [54:31<30:40, 20.45s/batch, loss=9.490727]Training:  57%|█████▋    | 121/211 [55:57<30:40, 20.45s/batch, loss=9.918550]Training:  58%|█████▊    | 122/211 [55:58<59:58, 40.43s/batch, loss=9.918550]Training:  58%|█████▊    | 122/211 [56:01<59:58, 40.43s/batch, loss=9.669163]Training:  58%|█████▊    | 123/211 [56:01<42:53, 29.24s/batch, loss=9.669163]Training:  58%|█████▊    | 123/211 [56:04<42:53, 29.24s/batch, loss=9.389985]Training:  59%|█████▉    | 124/211 [56:04<31:01, 21.39s/batch, loss=9.389985]Training:  59%|█████▉    | 124/211 [56:24<31:01, 21.39s/batch, loss=9.829565]Training:  59%|█████▉    | 125/211 [56:24<30:07, 21.01s/batch, loss=9.829565]Training:  59%|█████▉    | 125/211 [57:50<30:07, 21.01s/batch, loss=9.793290]Training:  60%|█████▉    | 126/211 [57:50<57:29, 40.59s/batch, loss=9.793290]Training:  60%|█████▉    | 126/211 [57:54<57:29, 40.59s/batch, loss=9.066051]Training:  60%|██████    | 127/211 [57:54<41:07, 29.37s/batch, loss=9.066051]Training:  60%|██████    | 127/211 [57:57<41:07, 29.37s/batch, loss=9.637965]Training:  61%|██████    | 128/211 [57:57<29:45, 21.51s/batch, loss=9.637965]Training:  61%|██████    | 128/211 [58:24<29:45, 21.51s/batch, loss=9.917540]Training:  61%|██████    | 129/211 [58:24<31:41, 23.19s/batch, loss=9.917540]Training:  61%|██████    | 129/211 [59:43<31:41, 23.19s/batch, loss=9.750732]Training:  62%|██████▏   | 130/211 [59:43<53:56, 39.96s/batch, loss=9.750732]Training:  62%|██████▏   | 130/211 [59:46<53:56, 39.96s/batch, loss=9.872674]Training:  62%|██████▏   | 131/211 [59:46<38:36, 28.95s/batch, loss=9.872674]Training:  62%|██████▏   | 131/211 [59:49<38:36, 28.95s/batch, loss=9.526270]Training:  63%|██████▎   | 132/211 [59:49<27:55, 21.21s/batch, loss=9.526270]Training:  63%|██████▎   | 132/211 [1:00:20<27:55, 21.21s/batch, loss=9.631607]Training:  63%|██████▎   | 133/211 [1:00:20<31:08, 23.95s/batch, loss=9.631607]Training:  63%|██████▎   | 133/211 [1:01:28<31:08, 23.95s/batch, loss=9.604152]Training:  64%|██████▎   | 134/211 [1:01:28<47:53, 37.32s/batch, loss=9.604152]Training:  64%|██████▎   | 134/211 [1:01:31<47:53, 37.32s/batch, loss=9.633720]Training:  64%|██████▍   | 135/211 [1:01:31<34:18, 27.08s/batch, loss=9.633720]Training:  64%|██████▍   | 135/211 [1:01:34<34:18, 27.08s/batch, loss=8.988374]Training:  64%|██████▍   | 136/211 [1:01:34<24:52, 19.90s/batch, loss=8.988374]Training:  64%|██████▍   | 136/211 [1:02:19<24:52, 19.90s/batch, loss=9.534325]Training:  65%|██████▍   | 137/211 [1:02:19<33:47, 27.39s/batch, loss=9.534325]Training:  65%|██████▍   | 137/211 [1:03:24<33:47, 27.39s/batch, loss=9.778665]Training:  65%|██████▌   | 138/211 [1:03:25<47:15, 38.84s/batch, loss=9.778665]Training:  65%|██████▌   | 138/211 [1:03:28<47:15, 38.84s/batch, loss=9.744478]Training:  66%|██████▌   | 139/211 [1:03:28<33:46, 28.15s/batch, loss=9.744478]Training:  66%|██████▌   | 139/211 [1:03:31<33:46, 28.15s/batch, loss=9.227521]Training:  66%|██████▋   | 140/211 [1:03:31<24:27, 20.67s/batch, loss=9.227521]Training:  66%|██████▋   | 140/211 [1:04:10<24:27, 20.67s/batch, loss=9.275286]Training:  67%|██████▋   | 141/211 [1:04:10<30:27, 26.11s/batch, loss=9.275286]Training:  67%|██████▋   | 141/211 [1:05:18<30:27, 26.11s/batch, loss=9.529788]Training:  67%|██████▋   | 142/211 [1:05:18<44:19, 38.54s/batch, loss=9.529788]Training:  67%|██████▋   | 142/211 [1:05:21<44:19, 38.54s/batch, loss=9.734118]Training:  68%|██████▊   | 143/211 [1:05:21<31:42, 27.97s/batch, loss=9.734118]Training:  68%|██████▊   | 143/211 [1:05:24<31:42, 27.97s/batch, loss=9.509632]Training:  68%|██████▊   | 144/211 [1:05:24<22:57, 20.56s/batch, loss=9.509632]Training:  68%|██████▊   | 144/211 [1:05:53<22:57, 20.56s/batch, loss=9.345232]Training:  69%|██████▊   | 145/211 [1:05:53<25:25, 23.11s/batch, loss=9.345232]Training:  69%|██████▊   | 145/211 [1:07:07<25:25, 23.11s/batch, loss=9.665388]Training:  69%|██████▉   | 146/211 [1:07:07<41:26, 38.25s/batch, loss=9.665388]Training:  69%|██████▉   | 146/211 [1:07:10<41:26, 38.25s/batch, loss=9.621408]Training:  70%|██████▉   | 147/211 [1:07:10<29:36, 27.76s/batch, loss=9.621408]Training:  70%|██████▉   | 147/211 [1:07:13<29:36, 27.76s/batch, loss=9.378265]Training:  70%|███████   | 148/211 [1:07:13<21:22, 20.36s/batch, loss=9.378265]Training:  70%|███████   | 148/211 [1:07:44<21:22, 20.36s/batch, loss=9.722195]Training:  71%|███████   | 149/211 [1:07:44<24:21, 23.58s/batch, loss=9.722195]Training:  71%|███████   | 149/211 [1:08:57<24:21, 23.58s/batch, loss=9.534670]Training:  71%|███████   | 150/211 [1:08:57<39:04, 38.44s/batch, loss=9.534670]Training:  71%|███████   | 150/211 [1:09:01<39:04, 38.44s/batch, loss=9.667046]Training:  72%|███████▏  | 151/211 [1:09:01<27:51, 27.85s/batch, loss=9.667046]Training:  72%|███████▏  | 151/211 [1:09:04<27:51, 27.85s/batch, loss=9.396212]Training:  72%|███████▏  | 152/211 [1:09:04<20:06, 20.46s/batch, loss=9.396212]Training:  72%|███████▏  | 152/211 [1:09:50<20:06, 20.46s/batch, loss=9.771465]Training:  73%|███████▎  | 153/211 [1:09:50<27:16, 28.22s/batch, loss=9.771465]Training:  73%|███████▎  | 153/211 [1:10:46<27:16, 28.22s/batch, loss=9.806211]Training:  73%|███████▎  | 154/211 [1:10:46<34:48, 36.63s/batch, loss=9.806211]Training:  73%|███████▎  | 154/211 [1:10:50<34:48, 36.63s/batch, loss=9.332884]Training:  73%|███████▎  | 155/211 [1:10:50<24:48, 26.59s/batch, loss=9.332884]Training:  73%|███████▎  | 155/211 [1:10:53<24:48, 26.59s/batch, loss=9.487659]Training:  74%|███████▍  | 156/211 [1:10:53<17:57, 19.59s/batch, loss=9.487659]Training:  74%|███████▍  | 156/211 [1:11:35<17:57, 19.59s/batch, loss=9.550823]Training:  74%|███████▍  | 157/211 [1:11:36<23:52, 26.53s/batch, loss=9.550823]Training:  74%|███████▍  | 157/211 [1:12:27<23:52, 26.53s/batch, loss=9.461769]Training:  75%|███████▍  | 158/211 [1:12:27<30:04, 34.04s/batch, loss=9.461769]Training:  75%|███████▍  | 158/211 [1:12:30<30:04, 34.04s/batch, loss=9.721743]Training:  75%|███████▌  | 159/211 [1:12:30<21:28, 24.78s/batch, loss=9.721743]Training:  75%|███████▌  | 159/211 [1:12:33<21:28, 24.78s/batch, loss=9.763926]Training:  76%|███████▌  | 160/211 [1:12:33<15:31, 18.27s/batch, loss=9.763926]Training:  76%|███████▌  | 160/211 [1:13:26<15:31, 18.27s/batch, loss=9.371062]Training:  76%|███████▋  | 161/211 [1:13:26<23:48, 28.56s/batch, loss=9.371062]Training:  76%|███████▋  | 161/211 [1:14:15<23:48, 28.56s/batch, loss=9.590451]Training:  77%|███████▋  | 162/211 [1:14:15<28:24, 34.79s/batch, loss=9.590451]Training:  77%|███████▋  | 162/211 [1:14:18<28:24, 34.79s/batch, loss=9.707293]Training:  77%|███████▋  | 163/211 [1:14:18<20:14, 25.31s/batch, loss=9.707293]Training:  77%|███████▋  | 163/211 [1:14:22<20:14, 25.31s/batch, loss=9.678029]Training:  78%|███████▊  | 164/211 [1:14:22<14:36, 18.65s/batch, loss=9.678029]Training:  78%|███████▊  | 164/211 [1:15:12<14:36, 18.65s/batch, loss=9.582346]Training:  78%|███████▊  | 165/211 [1:15:12<21:40, 28.28s/batch, loss=9.582346]Training:  78%|███████▊  | 165/211 [1:16:06<21:40, 28.28s/batch, loss=9.339420]Training:  79%|███████▊  | 166/211 [1:16:06<26:53, 35.85s/batch, loss=9.339420]Training:  79%|███████▊  | 166/211 [1:16:09<26:53, 35.85s/batch, loss=9.484141]Training:  79%|███████▉  | 167/211 [1:16:09<19:05, 26.04s/batch, loss=9.484141]Training:  79%|███████▉  | 167/211 [1:16:12<19:05, 26.04s/batch, loss=9.304354]Training:  80%|███████▉  | 168/211 [1:16:12<13:46, 19.22s/batch, loss=9.304354]Training:  80%|███████▉  | 168/211 [1:16:50<13:46, 19.22s/batch, loss=9.602104]Training:  80%|████████  | 169/211 [1:16:50<17:17, 24.71s/batch, loss=9.602104]Training:  80%|████████  | 169/211 [1:17:56<17:17, 24.71s/batch, loss=9.489950]Training:  81%|████████  | 170/211 [1:17:57<25:36, 37.48s/batch, loss=9.489950]Training:  81%|████████  | 170/211 [1:18:00<25:36, 37.48s/batch, loss=9.672366]Training:  81%|████████  | 171/211 [1:18:00<18:09, 27.23s/batch, loss=9.672366]Training:  81%|████████  | 171/211 [1:18:04<18:09, 27.23s/batch, loss=9.705470]Training:  82%|████████▏ | 172/211 [1:18:04<13:00, 20.00s/batch, loss=9.705470]Training:  82%|████████▏ | 172/211 [1:18:41<13:00, 20.00s/batch, loss=9.280411]Training:  82%|████████▏ | 173/211 [1:18:41<15:54, 25.13s/batch, loss=9.280411]Training:  82%|████████▏ | 173/211 [1:19:44<15:54, 25.13s/batch, loss=9.818337]Training:  82%|████████▏ | 174/211 [1:19:44<22:36, 36.65s/batch, loss=9.818337]Training:  82%|████████▏ | 174/211 [1:19:47<22:36, 36.65s/batch, loss=9.386489]Training:  83%|████████▎ | 175/211 [1:19:47<15:58, 26.62s/batch, loss=9.386489]Training:  83%|████████▎ | 175/211 [1:19:51<15:58, 26.62s/batch, loss=9.270919]Training:  83%|████████▎ | 176/211 [1:19:51<11:26, 19.62s/batch, loss=9.270919]Training:  83%|████████▎ | 176/211 [1:20:23<11:26, 19.62s/batch, loss=9.543368]Training:  84%|████████▍ | 177/211 [1:20:23<13:15, 23.39s/batch, loss=9.543368]Training:  84%|████████▍ | 177/211 [1:21:27<13:15, 23.39s/batch, loss=9.604862]Training:  84%|████████▍ | 178/211 [1:21:27<19:36, 35.66s/batch, loss=9.604862]Training:  84%|████████▍ | 178/211 [1:21:30<19:36, 35.66s/batch, loss=9.311973]Training:  85%|████████▍ | 179/211 [1:21:30<13:49, 25.91s/batch, loss=9.311973]Training:  85%|████████▍ | 179/211 [1:21:33<13:49, 25.91s/batch, loss=9.472508]Training:  85%|████████▌ | 180/211 [1:21:33<09:51, 19.07s/batch, loss=9.472508]Training:  85%|████████▌ | 180/211 [1:22:15<09:51, 19.07s/batch, loss=9.890649]Training:  86%|████████▌ | 181/211 [1:22:15<12:53, 25.79s/batch, loss=9.890649]Training:  86%|████████▌ | 181/211 [1:23:22<12:53, 25.79s/batch, loss=9.660806]Training:  86%|████████▋ | 182/211 [1:23:23<18:32, 38.36s/batch, loss=9.660806]Training:  86%|████████▋ | 182/211 [1:23:26<18:32, 38.36s/batch, loss=9.793805]Training:  87%|████████▋ | 183/211 [1:23:26<12:58, 27.80s/batch, loss=9.793805]Training:  87%|████████▋ | 183/211 [1:23:29<12:58, 27.80s/batch, loss=9.345165]Training:  87%|████████▋ | 184/211 [1:23:29<09:12, 20.45s/batch, loss=9.345165]Training:  87%|████████▋ | 184/211 [1:24:05<09:12, 20.45s/batch, loss=9.298390]Training:  88%|████████▊ | 185/211 [1:24:05<10:55, 25.22s/batch, loss=9.298390]Training:  88%|████████▊ | 185/211 [1:25:10<10:55, 25.22s/batch, loss=9.622655]Training:  88%|████████▊ | 186/211 [1:25:10<15:23, 36.95s/batch, loss=9.622655]Training:  88%|████████▊ | 186/211 [1:25:13<15:23, 36.95s/batch, loss=9.552691]Training:  89%|████████▊ | 187/211 [1:25:13<10:43, 26.82s/batch, loss=9.552691]Training:  89%|████████▊ | 187/211 [1:25:16<10:43, 26.82s/batch, loss=9.275805]Training:  89%|████████▉ | 188/211 [1:25:16<07:34, 19.74s/batch, loss=9.275805]Training:  89%|████████▉ | 188/211 [1:25:58<07:34, 19.74s/batch, loss=9.240779]Training:  90%|████████▉ | 189/211 [1:25:58<09:41, 26.43s/batch, loss=9.240779]Training:  90%|████████▉ | 189/211 [1:27:06<09:41, 26.43s/batch, loss=9.363937]Training:  90%|█████████ | 190/211 [1:27:06<13:34, 38.79s/batch, loss=9.363937]Training:  90%|█████████ | 190/211 [1:27:09<13:34, 38.79s/batch, loss=9.467531]Training:  91%|█████████ | 191/211 [1:27:09<09:22, 28.10s/batch, loss=9.467531]Training:  91%|█████████ | 191/211 [1:27:12<09:22, 28.10s/batch, loss=9.498622]Training:  91%|█████████ | 192/211 [1:27:12<06:31, 20.62s/batch, loss=9.498622]Training:  91%|█████████ | 192/211 [1:27:41<06:31, 20.62s/batch, loss=9.522125]Training:  91%|█████████▏| 193/211 [1:27:41<06:54, 23.06s/batch, loss=9.522125]Training:  91%|█████████▏| 193/211 [1:28:49<06:54, 23.06s/batch, loss=9.739993]Training:  92%|█████████▏| 194/211 [1:28:50<10:24, 36.76s/batch, loss=9.739993]Training:  92%|█████████▏| 194/211 [1:28:53<10:24, 36.76s/batch, loss=9.205967]Training:  92%|█████████▏| 195/211 [1:28:53<07:07, 26.71s/batch, loss=9.205967]Training:  92%|█████████▏| 195/211 [1:28:56<07:07, 26.71s/batch, loss=9.233148]Training:  93%|█████████▎| 196/211 [1:28:56<04:54, 19.64s/batch, loss=9.233148]Training:  93%|█████████▎| 196/211 [1:29:39<04:54, 19.64s/batch, loss=9.415473]Training:  93%|█████████▎| 197/211 [1:29:39<06:12, 26.61s/batch, loss=9.415473]Training:  93%|█████████▎| 197/211 [1:30:47<06:12, 26.61s/batch, loss=9.387254]Training:  94%|█████████▍| 198/211 [1:30:47<08:26, 38.99s/batch, loss=9.387254]Training:  94%|█████████▍| 198/211 [1:30:50<08:26, 38.99s/batch, loss=9.565321]Training:  94%|█████████▍| 199/211 [1:30:50<05:39, 28.25s/batch, loss=9.565321]Training:  94%|█████████▍| 199/211 [1:30:53<05:39, 28.25s/batch, loss=9.078797]Training:  95%|█████████▍| 200/211 [1:30:53<03:48, 20.75s/batch, loss=9.078797]Training:  95%|█████████▍| 200/211 [1:31:19<03:48, 20.75s/batch, loss=9.688338]Training:  95%|█████████▌| 201/211 [1:31:19<03:42, 22.24s/batch, loss=9.688338]Training:  95%|█████████▌| 201/211 [1:32:35<03:42, 22.24s/batch, loss=9.599002]Training:  96%|█████████▌| 202/211 [1:32:35<05:45, 38.44s/batch, loss=9.599002]Training:  96%|█████████▌| 202/211 [1:32:38<05:45, 38.44s/batch, loss=9.549130]Training:  96%|█████████▌| 203/211 [1:32:38<03:42, 27.87s/batch, loss=9.549130]Training:  96%|█████████▌| 203/211 [1:32:41<03:42, 27.87s/batch, loss=9.565271]Training:  97%|█████████▋| 204/211 [1:32:41<02:23, 20.46s/batch, loss=9.565271]Training:  97%|█████████▋| 204/211 [1:33:09<02:23, 20.46s/batch, loss=9.559502]Training:  97%|█████████▋| 205/211 [1:33:09<02:15, 22.64s/batch, loss=9.559502]Training:  97%|█████████▋| 205/211 [1:33:47<02:15, 22.64s/batch, loss=9.274212]Training:  98%|█████████▊| 206/211 [1:33:48<02:16, 27.34s/batch, loss=9.274212]Training:  98%|█████████▊| 206/211 [1:33:51<02:16, 27.34s/batch, loss=9.627846]Training:  98%|█████████▊| 207/211 [1:33:51<01:20, 20.11s/batch, loss=9.627846]Training:  98%|█████████▊| 207/211 [1:33:54<01:20, 20.11s/batch, loss=9.303936]Training:  99%|█████████▊| 208/211 [1:33:54<00:45, 15.06s/batch, loss=9.303936]Training:  99%|█████████▊| 208/211 [1:34:08<00:45, 15.06s/batch, loss=9.731074]Training:  99%|█████████▉| 209/211 [1:34:08<00:29, 14.76s/batch, loss=9.731074]Training:  99%|█████████▉| 209/211 [1:34:32<00:29, 14.76s/batch, loss=9.585692]Training: 100%|█████████▉| 210/211 [1:34:32<00:17, 17.56s/batch, loss=9.585692]Training: 100%|█████████▉| 210/211 [1:34:33<00:17, 17.56s/batch, loss=10.236058]Training: 100%|██████████| 211/211 [1:34:33<00:00, 12.51s/batch, loss=10.236058]Training: 100%|██████████| 211/211 [1:34:33<00:00, 26.89s/batch, loss=10.236058]
Epoch 9, Train Loss: 9.6172, Val Loss: 9.4331
Training:   0%|          | 0/211 [00:00<?, ?batch/s]Training:   0%|          | 0/211 [01:31<?, ?batch/s, loss=9.167424]Training:   0%|          | 1/211 [01:31<5:20:18, 91.52s/batch, loss=9.167424]Training:   0%|          | 1/211 [01:52<5:20:18, 91.52s/batch, loss=9.653111]Training:   1%|          | 2/211 [01:52<2:54:19, 50.04s/batch, loss=9.653111]Training:   1%|          | 2/211 [01:55<2:54:19, 50.04s/batch, loss=9.197626]Training:   1%|▏         | 3/211 [01:55<1:39:13, 28.62s/batch, loss=9.197626]Training:   1%|▏         | 3/211 [01:58<1:39:13, 28.62s/batch, loss=9.500930]Training:   2%|▏         | 4/211 [01:58<1:04:09, 18.59s/batch, loss=9.500930]Training:   2%|▏         | 4/211 [03:05<1:04:09, 18.59s/batch, loss=9.403098]Training:   2%|▏         | 5/211 [03:06<2:04:20, 36.21s/batch, loss=9.403098]Training:   2%|▏         | 5/211 [03:37<2:04:20, 36.21s/batch, loss=9.230331]Training:   3%|▎         | 6/211 [03:37<1:57:57, 34.53s/batch, loss=9.230331]Training:   3%|▎         | 6/211 [03:40<1:57:57, 34.53s/batch, loss=9.426467]Training:   3%|▎         | 7/211 [03:40<1:22:41, 24.32s/batch, loss=9.426467]Training:   3%|▎         | 7/211 [03:44<1:22:41, 24.32s/batch, loss=9.299187]Training:   4%|▍         | 8/211 [03:44<59:40, 17.64s/batch, loss=9.299187]  Training:   4%|▍         | 8/211 [05:00<59:40, 17.64s/batch, loss=9.136701]Training:   4%|▍         | 9/211 [05:01<2:02:23, 36.35s/batch, loss=9.136701]Training:   4%|▍         | 9/211 [05:28<2:02:23, 36.35s/batch, loss=9.656726]Training:   5%|▍         | 10/211 [05:28<1:51:30, 33.28s/batch, loss=9.656726]Training:   5%|▍         | 10/211 [05:31<1:51:30, 33.28s/batch, loss=9.472957]Training:   5%|▌         | 11/211 [05:31<1:20:20, 24.10s/batch, loss=9.472957]Training:   5%|▌         | 11/211 [05:34<1:20:20, 24.10s/batch, loss=9.300288]Training:   6%|▌         | 12/211 [05:34<58:53, 17.75s/batch, loss=9.300288]  Training:   6%|▌         | 12/211 [06:41<58:53, 17.75s/batch, loss=9.556373]Training:   6%|▌         | 13/211 [06:42<1:48:14, 32.80s/batch, loss=9.556373]Training:   6%|▌         | 13/211 [07:07<1:48:14, 32.80s/batch, loss=9.518087]Training:   7%|▋         | 14/211 [07:07<1:39:54, 30.43s/batch, loss=9.518087]Training:   7%|▋         | 14/211 [07:10<1:39:54, 30.43s/batch, loss=9.286644]Training:   7%|▋         | 15/211 [07:10<1:12:41, 22.25s/batch, loss=9.286644]Training:   7%|▋         | 15/211 [07:16<1:12:41, 22.25s/batch, loss=9.199851]Training:   8%|▊         | 16/211 [07:16<56:29, 17.38s/batch, loss=9.199851]  Training:   8%|▊         | 16/211 [08:25<56:29, 17.38s/batch, loss=9.350271]Training:   8%|▊         | 17/211 [08:25<1:46:07, 32.82s/batch, loss=9.350271]Training:   8%|▊         | 17/211 [08:43<1:46:07, 32.82s/batch, loss=9.219853]Training:   9%|▊         | 18/211 [08:43<1:31:13, 28.36s/batch, loss=9.219853]Training:   9%|▊         | 18/211 [08:46<1:31:13, 28.36s/batch, loss=9.770358]Training:   9%|▉         | 19/211 [08:46<1:06:29, 20.78s/batch, loss=9.770358]Training:   9%|▉         | 19/211 [09:09<1:06:29, 20.78s/batch, loss=9.461701]Training:   9%|▉         | 20/211 [09:09<1:08:22, 21.48s/batch, loss=9.461701]Training:   9%|▉         | 20/211 [10:05<1:08:22, 21.48s/batch, loss=9.432902]Training:  10%|▉         | 21/211 [10:05<1:40:45, 31.82s/batch, loss=9.432902]Training:  10%|▉         | 21/211 [10:23<1:40:45, 31.82s/batch, loss=9.503651]Training:  10%|█         | 22/211 [10:23<1:27:44, 27.85s/batch, loss=9.503651]Training:  10%|█         | 22/211 [10:44<1:27:44, 27.85s/batch, loss=9.376687]Training:  11%|█         | 23/211 [10:44<1:20:12, 25.60s/batch, loss=9.376687]Training:  11%|█         | 23/211 [11:05<1:20:12, 25.60s/batch, loss=9.045706]Training:  11%|█▏        | 24/211 [11:05<1:15:57, 24.37s/batch, loss=9.045706]Training:  11%|█▏        | 24/211 [12:05<1:15:57, 24.37s/batch, loss=9.519239]Training:  12%|█▏        | 25/211 [12:06<1:49:21, 35.28s/batch, loss=9.519239]Training:  12%|█▏        | 25/211 [12:09<1:49:21, 35.28s/batch, loss=9.221152]Training:  12%|█▏        | 26/211 [12:09<1:19:07, 25.66s/batch, loss=9.221152]Training:  12%|█▏        | 26/211 [12:18<1:19:07, 25.66s/batch, loss=9.169702]Training:  13%|█▎        | 27/211 [12:18<1:03:12, 20.61s/batch, loss=9.169702]Training:  13%|█▎        | 27/211 [13:08<1:03:12, 20.61s/batch, loss=9.517062]Training:  13%|█▎        | 28/211 [13:08<1:29:40, 29.40s/batch, loss=9.517062]Training:  13%|█▎        | 28/211 [13:55<1:29:40, 29.40s/batch, loss=9.357257]Training:  14%|█▎        | 29/211 [13:55<1:45:44, 34.86s/batch, loss=9.357257]Training:  14%|█▎        | 29/211 [13:59<1:45:44, 34.86s/batch, loss=9.352559]Training:  14%|█▍        | 30/211 [13:59<1:16:36, 25.40s/batch, loss=9.352559]Training:  14%|█▍        | 30/211 [14:12<1:16:36, 25.40s/batch, loss=9.066859]Training:  15%|█▍        | 31/211 [14:12<1:05:08, 21.71s/batch, loss=9.066859]Training:  15%|█▍        | 31/211 [14:59<1:05:08, 21.71s/batch, loss=9.060047]Training:  15%|█▌        | 32/211 [14:59<1:27:07, 29.20s/batch, loss=9.060047]Training:  15%|█▌        | 32/211 [15:39<1:27:07, 29.20s/batch, loss=9.408732]Training:  16%|█▌        | 33/211 [15:39<1:36:56, 32.68s/batch, loss=9.408732]Training:  16%|█▌        | 33/211 [15:46<1:36:56, 32.68s/batch, loss=8.852703]Training:  16%|█▌        | 34/211 [15:46<1:13:01, 24.75s/batch, loss=8.852703]Training:  16%|█▌        | 34/211 [15:51<1:13:01, 24.75s/batch, loss=9.335998]Training:  17%|█▋        | 35/211 [15:51<55:46, 19.02s/batch, loss=9.335998]  Training:  17%|█▋        | 35/211 [16:48<55:46, 19.02s/batch, loss=9.387298]Training:  17%|█▋        | 36/211 [16:48<1:28:46, 30.44s/batch, loss=9.387298]Training:  17%|█▋        | 36/211 [17:42<1:28:46, 30.44s/batch, loss=9.654548]Training:  18%|█▊        | 37/211 [17:43<1:48:55, 37.56s/batch, loss=9.654548]Training:  18%|█▊        | 37/211 [17:46<1:48:55, 37.56s/batch, loss=9.428354]Training:  18%|█▊        | 38/211 [17:46<1:18:30, 27.23s/batch, loss=9.428354]Training:  18%|█▊        | 38/211 [17:58<1:18:30, 27.23s/batch, loss=8.716658]Training:  18%|█▊        | 39/211 [17:58<1:04:57, 22.66s/batch, loss=8.716658]Training:  18%|█▊        | 39/211 [18:35<1:04:57, 22.66s/batch, loss=9.106514]Training:  19%|█▉        | 40/211 [18:35<1:17:13, 27.09s/batch, loss=9.106514]Training:  19%|█▉        | 40/211 [19:36<1:17:13, 27.09s/batch, loss=9.234554]Training:  19%|█▉        | 41/211 [19:37<1:46:14, 37.50s/batch, loss=9.234554]Training:  19%|█▉        | 41/211 [19:40<1:46:14, 37.50s/batch, loss=9.945658]Training:  20%|█▉        | 42/211 [19:40<1:16:36, 27.20s/batch, loss=9.945658]Training:  20%|█▉        | 42/211 [19:43<1:16:36, 27.20s/batch, loss=8.972637]Training:  20%|██        | 43/211 [19:43<55:58, 19.99s/batch, loss=8.972637]  Training:  20%|██        | 43/211 [20:20<55:58, 19.99s/batch, loss=9.091574]Training:  21%|██        | 44/211 [20:20<1:09:24, 24.94s/batch, loss=9.091574]Training:  21%|██        | 44/211 [21:24<1:09:24, 24.94s/batch, loss=9.482436]Training:  21%|██▏       | 45/211 [21:24<1:41:25, 36.66s/batch, loss=9.482436]Training:  21%|██▏       | 45/211 [21:27<1:41:25, 36.66s/batch, loss=9.436645]Training:  22%|██▏       | 46/211 [21:27<1:13:11, 26.61s/batch, loss=9.436645]Training:  22%|██▏       | 46/211 [21:30<1:13:11, 26.61s/batch, loss=9.535095]Training:  22%|██▏       | 47/211 [21:30<53:33, 19.59s/batch, loss=9.535095]  Training:  22%|██▏       | 47/211 [21:57<53:33, 19.59s/batch, loss=9.567080]Training:  23%|██▎       | 48/211 [21:57<59:07, 21.77s/batch, loss=9.567080]Training:  23%|██▎       | 48/211 [23:09<59:07, 21.77s/batch, loss=9.631291]Training:  23%|██▎       | 49/211 [23:10<1:40:01, 37.05s/batch, loss=9.631291]Training:  23%|██▎       | 49/211 [23:13<1:40:01, 37.05s/batch, loss=9.409161]Training:  24%|██▎       | 50/211 [23:13<1:12:06, 26.87s/batch, loss=9.409161]Training:  24%|██▎       | 50/211 [23:16<1:12:06, 26.87s/batch, loss=9.627408]Training:  24%|██▍       | 51/211 [23:16<52:50, 19.82s/batch, loss=9.627408]  Training:  24%|██▍       | 51/211 [23:43<52:50, 19.82s/batch, loss=9.629780]Training:  25%|██▍       | 52/211 [23:43<57:45, 21.79s/batch, loss=9.629780]Training:  25%|██▍       | 52/211 [25:06<57:45, 21.79s/batch, loss=9.233151]Training:  25%|██▌       | 53/211 [25:07<1:46:44, 40.53s/batch, loss=9.233151]Training:  25%|██▌       | 53/211 [25:10<1:46:44, 40.53s/batch, loss=9.068287]Training:  26%|██▌       | 54/211 [25:10<1:16:48, 29.36s/batch, loss=9.068287]Training:  26%|██▌       | 54/211 [25:13<1:16:48, 29.36s/batch, loss=9.541861]Training:  26%|██▌       | 55/211 [25:13<55:53, 21.50s/batch, loss=9.541861]  Training:  26%|██▌       | 55/211 [25:25<55:53, 21.50s/batch, loss=9.249734]Training:  27%|██▋       | 56/211 [25:25<47:44, 18.48s/batch, loss=9.249734]Training:  27%|██▋       | 56/211 [26:48<47:44, 18.48s/batch, loss=9.387256]Training:  27%|██▋       | 57/211 [26:48<1:37:26, 37.97s/batch, loss=9.387256]Training:  27%|██▋       | 57/211 [26:51<1:37:26, 37.97s/batch, loss=9.371460]Training:  27%|██▋       | 58/211 [26:51<1:10:11, 27.53s/batch, loss=9.371460]Training:  27%|██▋       | 58/211 [26:54<1:10:11, 27.53s/batch, loss=9.524760]Training:  28%|██▊       | 59/211 [26:54<51:13, 20.22s/batch, loss=9.524760]  Training:  28%|██▊       | 59/211 [27:17<51:13, 20.22s/batch, loss=9.592508]Training:  28%|██▊       | 60/211 [27:17<52:44, 20.96s/batch, loss=9.592508]Training:  28%|██▊       | 60/211 [28:32<52:44, 20.96s/batch, loss=9.102834]Training:  29%|██▉       | 61/211 [28:32<1:32:35, 37.04s/batch, loss=9.102834]Training:  29%|██▉       | 61/211 [28:35<1:32:35, 37.04s/batch, loss=9.936234]Training:  29%|██▉       | 62/211 [28:35<1:06:43, 26.87s/batch, loss=9.936234]Training:  29%|██▉       | 62/211 [28:38<1:06:43, 26.87s/batch, loss=9.536038]Training:  30%|██▉       | 63/211 [28:38<48:47, 19.78s/batch, loss=9.536038]  Training:  30%|██▉       | 63/211 [29:00<48:47, 19.78s/batch, loss=9.357746]Training:  30%|███       | 64/211 [29:00<49:59, 20.41s/batch, loss=9.357746]Training:  30%|███       | 64/211 [30:21<49:59, 20.41s/batch, loss=9.565941]Training:  31%|███       | 65/211 [30:22<1:34:22, 38.78s/batch, loss=9.565941]Training:  31%|███       | 65/211 [30:25<1:34:22, 38.78s/batch, loss=9.460030]Training:  31%|███▏      | 66/211 [30:25<1:07:54, 28.10s/batch, loss=9.460030]Training:  31%|███▏      | 66/211 [30:28<1:07:54, 28.10s/batch, loss=9.576912]Training:  32%|███▏      | 67/211 [30:28<49:30, 20.63s/batch, loss=9.576912]  Training:  32%|███▏      | 67/211 [30:44<49:30, 20.63s/batch, loss=9.007699]Training:  32%|███▏      | 68/211 [30:44<45:44, 19.19s/batch, loss=9.007699]Training:  32%|███▏      | 68/211 [32:08<45:44, 19.19s/batch, loss=9.860519]Training:  33%|███▎      | 69/211 [32:09<1:32:05, 38.91s/batch, loss=9.860519]Training:  33%|███▎      | 69/211 [32:12<1:32:05, 38.91s/batch, loss=9.336361]Training:  33%|███▎      | 70/211 [32:12<1:06:13, 28.18s/batch, loss=9.336361]Training:  33%|███▎      | 70/211 [32:15<1:06:13, 28.18s/batch, loss=9.225917]Training:  34%|███▎      | 71/211 [32:15<48:11, 20.65s/batch, loss=9.225917]  Training:  34%|███▎      | 71/211 [32:40<48:11, 20.65s/batch, loss=9.096319]Training:  34%|███▍      | 72/211 [32:40<50:55, 21.99s/batch, loss=9.096319]Training:  34%|███▍      | 72/211 [33:50<50:55, 21.99s/batch, loss=8.941195]Training:  35%|███▍      | 73/211 [33:50<1:23:43, 36.40s/batch, loss=8.941195]Training:  35%|███▍      | 73/211 [33:53<1:23:43, 36.40s/batch, loss=9.410315]Training:  35%|███▌      | 74/211 [33:53<1:00:27, 26.48s/batch, loss=9.410315]Training:  35%|███▌      | 74/211 [33:57<1:00:27, 26.48s/batch, loss=9.191189]Training:  36%|███▌      | 75/211 [33:57<44:13, 19.51s/batch, loss=9.191189]  Training:  36%|███▌      | 75/211 [34:33<44:13, 19.51s/batch, loss=9.309885]Training:  36%|███▌      | 76/211 [34:33<55:12, 24.54s/batch, loss=9.309885]Training:  36%|███▌      | 76/211 [35:41<55:12, 24.54s/batch, loss=9.614558]Training:  36%|███▋      | 77/211 [35:42<1:24:20, 37.77s/batch, loss=9.614558]Training:  36%|███▋      | 77/211 [35:45<1:24:20, 37.77s/batch, loss=9.294114]Training:  37%|███▋      | 78/211 [35:45<1:00:46, 27.42s/batch, loss=9.294114]Training:  37%|███▋      | 78/211 [35:48<1:00:46, 27.42s/batch, loss=9.519672]Training:  37%|███▋      | 79/211 [35:48<44:17, 20.13s/batch, loss=9.519672]  Training:  37%|███▋      | 79/211 [36:20<44:17, 20.13s/batch, loss=9.631449]Training:  38%|███▊      | 80/211 [36:20<51:37, 23.65s/batch, loss=9.631449]Training:  38%|███▊      | 80/211 [37:37<51:37, 23.65s/batch, loss=9.817231]Training:  38%|███▊      | 81/211 [37:37<1:25:59, 39.69s/batch, loss=9.817231]Training:  38%|███▊      | 81/211 [37:40<1:25:59, 39.69s/batch, loss=9.547967]Training:  39%|███▉      | 82/211 [37:40<1:01:48, 28.75s/batch, loss=9.547967]Training:  39%|███▉      | 82/211 [37:44<1:01:48, 28.75s/batch, loss=9.056228]Training:  39%|███▉      | 83/211 [37:44<45:06, 21.14s/batch, loss=9.056228]  Training:  39%|███▉      | 83/211 [38:05<45:06, 21.14s/batch, loss=9.634922]Training:  40%|███▉      | 84/211 [38:05<44:52, 21.20s/batch, loss=9.634922]Training:  40%|███▉      | 84/211 [39:07<44:52, 21.20s/batch, loss=9.163691]Training:  40%|████      | 85/211 [39:08<1:10:51, 33.74s/batch, loss=9.163691]Training:  40%|████      | 85/211 [39:11<1:10:51, 33.74s/batch, loss=9.329178]Training:  41%|████      | 86/211 [39:11<51:12, 24.58s/batch, loss=9.329178]  Training:  41%|████      | 86/211 [39:14<51:12, 24.58s/batch, loss=9.583323]Training:  41%|████      | 87/211 [39:14<37:32, 18.16s/batch, loss=9.583323]Training:  41%|████      | 87/211 [39:44<37:32, 18.16s/batch, loss=9.058760]Training:  42%|████▏     | 88/211 [39:44<44:33, 21.74s/batch, loss=9.058760]Training:  42%|████▏     | 88/211 [40:58<44:33, 21.74s/batch, loss=9.249406]Training:  42%|████▏     | 89/211 [40:58<1:16:07, 37.44s/batch, loss=9.249406]Training:  42%|████▏     | 89/211 [41:02<1:16:07, 37.44s/batch, loss=9.383026]Training:  43%|████▎     | 90/211 [41:02<54:44, 27.15s/batch, loss=9.383026]  Training:  43%|████▎     | 90/211 [41:05<54:44, 27.15s/batch, loss=9.061669]Training:  43%|████▎     | 91/211 [41:05<39:54, 19.96s/batch, loss=9.061669]Training:  43%|████▎     | 91/211 [41:34<39:54, 19.96s/batch, loss=8.973425]Training:  44%|████▎     | 92/211 [41:34<44:54, 22.64s/batch, loss=8.973425]Training:  44%|████▎     | 92/211 [42:40<44:54, 22.64s/batch, loss=9.227533]Training:  44%|████▍     | 93/211 [42:40<1:10:18, 35.75s/batch, loss=9.227533]Training:  44%|████▍     | 93/211 [42:43<1:10:18, 35.75s/batch, loss=9.385716]Training:  45%|████▍     | 94/211 [42:43<50:44, 26.02s/batch, loss=9.385716]  Training:  45%|████▍     | 94/211 [42:48<50:44, 26.02s/batch, loss=8.906227]Training:  45%|████▌     | 95/211 [42:48<37:53, 19.60s/batch, loss=8.906227]Training:  45%|████▌     | 95/211 [43:16<37:53, 19.60s/batch, loss=9.181930]Training:  45%|████▌     | 96/211 [43:16<42:29, 22.17s/batch, loss=9.181930]Training:  45%|████▌     | 96/211 [44:35<42:29, 22.17s/batch, loss=8.883547]Training:  46%|████▌     | 97/211 [44:36<1:14:57, 39.45s/batch, loss=8.883547]Training:  46%|████▌     | 97/211 [44:39<1:14:57, 39.45s/batch, loss=9.168510]Training:  46%|████▋     | 98/211 [44:39<53:56, 28.64s/batch, loss=9.168510]  Training:  46%|████▋     | 98/211 [44:42<53:56, 28.64s/batch, loss=8.890550]Training:  47%|████▋     | 99/211 [44:42<39:10, 20.99s/batch, loss=8.890550]Training:  47%|████▋     | 99/211 [44:59<39:10, 20.99s/batch, loss=9.534987]Training:  47%|████▋     | 100/211 [44:59<36:15, 19.60s/batch, loss=9.534987]Training:  47%|████▋     | 100/211 [46:30<36:15, 19.60s/batch, loss=9.421309]Training:  48%|████▊     | 101/211 [46:31<1:15:38, 41.26s/batch, loss=9.421309]Training:  48%|████▊     | 101/211 [46:34<1:15:38, 41.26s/batch, loss=9.114028]Training:  48%|████▊     | 102/211 [46:34<54:11, 29.83s/batch, loss=9.114028]  Training:  48%|████▊     | 102/211 [46:37<54:11, 29.83s/batch, loss=9.176744]Training:  49%|████▉     | 103/211 [46:37<39:18, 21.84s/batch, loss=9.176744]Training:  49%|████▉     | 103/211 [46:53<39:18, 21.84s/batch, loss=9.389585]Training:  49%|████▉     | 104/211 [46:53<35:47, 20.07s/batch, loss=9.389585]Training:  49%|████▉     | 104/211 [48:21<35:47, 20.07s/batch, loss=9.430602]Training:  50%|████▉     | 105/211 [48:21<1:11:46, 40.63s/batch, loss=9.430602]Training:  50%|████▉     | 105/211 [48:25<1:11:46, 40.63s/batch, loss=9.230264]Training:  50%|█████     | 106/211 [48:25<51:26, 29.40s/batch, loss=9.230264]  Training:  50%|█████     | 106/211 [48:28<51:26, 29.40s/batch, loss=9.591441]Training:  51%|█████     | 107/211 [48:28<37:17, 21.52s/batch, loss=9.591441]Training:  51%|█████     | 107/211 [48:43<37:17, 21.52s/batch, loss=9.591187]Training:  51%|█████     | 108/211 [48:43<33:53, 19.74s/batch, loss=9.591187]Training:  51%|█████     | 108/211 [50:01<33:53, 19.74s/batch, loss=9.140464]Training:  52%|█████▏    | 109/211 [50:01<1:03:13, 37.19s/batch, loss=9.140464]Training:  52%|█████▏    | 109/211 [50:05<1:03:13, 37.19s/batch, loss=9.381918]Training:  52%|█████▏    | 110/211 [50:05<45:30, 27.03s/batch, loss=9.381918]  Training:  52%|█████▏    | 110/211 [50:08<45:30, 27.03s/batch, loss=9.215927]Training:  53%|█████▎    | 111/211 [50:08<33:05, 19.86s/batch, loss=9.215927]Training:  53%|█████▎    | 111/211 [50:25<33:05, 19.86s/batch, loss=9.521472]Training:  53%|█████▎    | 112/211 [50:25<31:18, 18.98s/batch, loss=9.521472]Training:  53%|█████▎    | 112/211 [51:50<31:18, 18.98s/batch, loss=9.301805]Training:  54%|█████▎    | 113/211 [51:50<1:03:38, 38.96s/batch, loss=9.301805]Training:  54%|█████▎    | 113/211 [51:53<1:03:38, 38.96s/batch, loss=9.383125]Training:  54%|█████▍    | 114/211 [51:53<45:38, 28.23s/batch, loss=9.383125]  Training:  54%|█████▍    | 114/211 [51:57<45:38, 28.23s/batch, loss=9.103782]Training:  55%|█████▍    | 115/211 [51:57<33:10, 20.73s/batch, loss=9.103782]Training:  55%|█████▍    | 115/211 [52:15<33:10, 20.73s/batch, loss=9.347957]Training:  55%|█████▍    | 116/211 [52:15<31:42, 20.03s/batch, loss=9.347957]Training:  55%|█████▍    | 116/211 [53:41<31:42, 20.03s/batch, loss=9.279418]Training:  55%|█████▌    | 117/211 [53:41<1:02:31, 39.91s/batch, loss=9.279418]Training:  55%|█████▌    | 117/211 [53:45<1:02:31, 39.91s/batch, loss=9.273471]Training:  56%|█████▌    | 118/211 [53:45<44:45, 28.88s/batch, loss=9.273471]  Training:  56%|█████▌    | 118/211 [53:56<44:45, 28.88s/batch, loss=9.227902]Training:  56%|█████▋    | 119/211 [53:56<36:09, 23.58s/batch, loss=9.227902]Training:  56%|█████▋    | 119/211 [54:27<36:09, 23.58s/batch, loss=9.571563]Training:  57%|█████▋    | 120/211 [54:27<39:17, 25.91s/batch, loss=9.571563]Training:  57%|█████▋    | 120/211 [55:23<39:17, 25.91s/batch, loss=9.567748]Training:  57%|█████▋    | 121/211 [55:24<52:43, 35.15s/batch, loss=9.567748]Training:  57%|█████▋    | 121/211 [55:27<52:43, 35.15s/batch, loss=8.887578]Training:  58%|█████▊    | 122/211 [55:27<37:52, 25.53s/batch, loss=8.887578]Training:  58%|█████▊    | 122/211 [55:45<37:52, 25.53s/batch, loss=9.502371]Training:  58%|█████▊    | 123/211 [55:45<34:16, 23.37s/batch, loss=9.502371]Training:  58%|█████▊    | 123/211 [56:16<34:16, 23.37s/batch, loss=9.477271]Training:  59%|█████▉    | 124/211 [56:16<37:18, 25.73s/batch, loss=9.477271]Training:  59%|█████▉    | 124/211 [57:10<37:18, 25.73s/batch, loss=9.431210]Training:  59%|█████▉    | 125/211 [57:10<48:40, 33.96s/batch, loss=9.431210]Training:  59%|█████▉    | 125/211 [57:13<48:40, 33.96s/batch, loss=8.999789]Training:  60%|█████▉    | 126/211 [57:13<35:01, 24.73s/batch, loss=8.999789]Training:  60%|█████▉    | 126/211 [57:28<35:01, 24.73s/batch, loss=9.482255]Training:  60%|██████    | 127/211 [57:28<30:30, 21.80s/batch, loss=9.482255]Training:  60%|██████    | 127/211 [58:06<30:30, 21.80s/batch, loss=9.870809]Training:  61%|██████    | 128/211 [58:06<36:52, 26.65s/batch, loss=9.870809]Training:  61%|██████    | 128/211 [58:48<36:52, 26.65s/batch, loss=9.754031]Training:  61%|██████    | 129/211 [58:48<42:48, 31.32s/batch, loss=9.754031]Training:  61%|██████    | 129/211 [58:51<42:48, 31.32s/batch, loss=9.398794]Training:  62%|██████▏   | 130/211 [58:51<30:54, 22.90s/batch, loss=9.398794]Training:  62%|██████▏   | 130/211 [59:22<30:54, 22.90s/batch, loss=9.218185]Training:  62%|██████▏   | 131/211 [59:22<33:34, 25.18s/batch, loss=9.218185]Training:  62%|██████▏   | 131/211 [59:56<33:34, 25.18s/batch, loss=9.032356]Training:  63%|██████▎   | 132/211 [59:56<36:44, 27.91s/batch, loss=9.032356]Training:  63%|██████▎   | 132/211 [1:00:40<36:44, 27.91s/batch, loss=9.414909]Training:  63%|██████▎   | 133/211 [1:00:40<42:37, 32.79s/batch, loss=9.414909]Training:  63%|██████▎   | 133/211 [1:00:43<42:37, 32.79s/batch, loss=9.317174]Training:  64%|██████▎   | 134/211 [1:00:43<30:41, 23.91s/batch, loss=9.317174]Training:  64%|██████▎   | 134/211 [1:01:18<30:41, 23.91s/batch, loss=9.013154]Training:  64%|██████▍   | 135/211 [1:01:18<34:23, 27.15s/batch, loss=9.013154]Training:  64%|██████▍   | 135/211 [1:01:50<34:23, 27.15s/batch, loss=9.214429]Training:  64%|██████▍   | 136/211 [1:01:50<35:39, 28.53s/batch, loss=9.214429]Training:  64%|██████▍   | 136/211 [1:02:25<35:39, 28.53s/batch, loss=9.456340]Training:  65%|██████▍   | 137/211 [1:02:25<37:35, 30.48s/batch, loss=9.456340]Training:  65%|██████▍   | 137/211 [1:02:28<37:35, 30.48s/batch, loss=9.204974]Training:  65%|██████▌   | 138/211 [1:02:28<27:09, 22.33s/batch, loss=9.204974]Training:  65%|██████▌   | 138/211 [1:03:07<27:09, 22.33s/batch, loss=9.534252]Training:  66%|██████▌   | 139/211 [1:03:07<32:52, 27.39s/batch, loss=9.534252]Training:  66%|██████▌   | 139/211 [1:03:30<32:52, 27.39s/batch, loss=9.384091]Training:  66%|██████▋   | 140/211 [1:03:30<30:50, 26.06s/batch, loss=9.384091]Training:  66%|██████▋   | 140/211 [1:04:25<30:50, 26.06s/batch, loss=9.399786]Training:  67%|██████▋   | 141/211 [1:04:25<40:32, 34.76s/batch, loss=9.399786]Training:  67%|██████▋   | 141/211 [1:04:29<40:32, 34.76s/batch, loss=9.741742]Training:  67%|██████▋   | 142/211 [1:04:29<29:05, 25.30s/batch, loss=9.741742]Training:  67%|██████▋   | 142/211 [1:04:54<29:05, 25.30s/batch, loss=9.120410]Training:  68%|██████▊   | 143/211 [1:04:54<28:39, 25.28s/batch, loss=9.120410]Training:  68%|██████▊   | 143/211 [1:05:29<28:39, 25.28s/batch, loss=9.085368]Training:  68%|██████▊   | 144/211 [1:05:29<31:40, 28.36s/batch, loss=9.085368]Training:  68%|██████▊   | 144/211 [1:06:28<31:40, 28.36s/batch, loss=9.244961]Training:  69%|██████▊   | 145/211 [1:06:28<41:13, 37.48s/batch, loss=9.244961]Training:  69%|██████▊   | 145/211 [1:06:31<41:13, 37.48s/batch, loss=9.620267]Training:  69%|██████▉   | 146/211 [1:06:31<29:27, 27.19s/batch, loss=9.620267]Training:  69%|██████▉   | 146/211 [1:06:44<29:27, 27.19s/batch, loss=9.483614]Training:  70%|██████▉   | 147/211 [1:06:44<24:24, 22.89s/batch, loss=9.483614]Training:  70%|██████▉   | 147/211 [1:07:20<24:24, 22.89s/batch, loss=9.123009]Training:  70%|███████   | 148/211 [1:07:21<28:16, 26.93s/batch, loss=9.123009]Training:  70%|███████   | 148/211 [1:08:16<28:16, 26.93s/batch, loss=9.132643]Training:  71%|███████   | 149/211 [1:08:16<36:37, 35.44s/batch, loss=9.132643]Training:  71%|███████   | 149/211 [1:08:19<36:37, 35.44s/batch, loss=9.824610]Training:  71%|███████   | 150/211 [1:08:19<26:11, 25.76s/batch, loss=9.824610]Training:  71%|███████   | 150/211 [1:08:25<26:11, 25.76s/batch, loss=9.150360]Training:  72%|███████▏  | 151/211 [1:08:25<19:54, 19.91s/batch, loss=9.150360]Training:  72%|███████▏  | 151/211 [1:09:19<19:54, 19.91s/batch, loss=9.268975]Training:  72%|███████▏  | 152/211 [1:09:19<29:42, 30.22s/batch, loss=9.268975]Training:  72%|███████▏  | 152/211 [1:09:57<29:42, 30.22s/batch, loss=9.293512]Training:  73%|███████▎  | 153/211 [1:09:57<31:25, 32.50s/batch, loss=9.293512]Training:  73%|███████▎  | 153/211 [1:10:00<31:25, 32.50s/batch, loss=8.897566]Training:  73%|███████▎  | 154/211 [1:10:00<22:30, 23.70s/batch, loss=8.897566]Training:  73%|███████▎  | 154/211 [1:10:23<22:30, 23.70s/batch, loss=9.400118]Training:  73%|███████▎  | 155/211 [1:10:23<21:46, 23.34s/batch, loss=9.400118]Training:  73%|███████▎  | 155/211 [1:11:15<21:46, 23.34s/batch, loss=9.410840]Training:  74%|███████▍  | 156/211 [1:11:16<29:28, 32.15s/batch, loss=9.410840]Training:  74%|███████▍  | 156/211 [1:11:44<29:28, 32.15s/batch, loss=9.346491]Training:  74%|███████▍  | 157/211 [1:11:44<27:58, 31.08s/batch, loss=9.346491]Training:  74%|███████▍  | 157/211 [1:11:47<27:58, 31.08s/batch, loss=9.563756]Training:  75%|███████▍  | 158/211 [1:11:47<20:03, 22.70s/batch, loss=9.563756]Training:  75%|███████▍  | 158/211 [1:12:18<20:03, 22.70s/batch, loss=9.069701]Training:  75%|███████▌  | 159/211 [1:12:18<21:38, 24.98s/batch, loss=9.069701]Training:  75%|███████▌  | 159/211 [1:13:13<21:38, 24.98s/batch, loss=9.135949]Training:  76%|███████▌  | 160/211 [1:13:14<29:05, 34.22s/batch, loss=9.135949]Training:  76%|███████▌  | 160/211 [1:13:28<29:05, 34.22s/batch, loss=9.097475]Training:  76%|███████▋  | 161/211 [1:13:28<23:41, 28.43s/batch, loss=9.097475]Training:  76%|███████▋  | 161/211 [1:13:32<23:41, 28.43s/batch, loss=9.409010]Training:  77%|███████▋  | 162/211 [1:13:32<17:02, 20.87s/batch, loss=9.409010]Training:  77%|███████▋  | 162/211 [1:14:10<17:02, 20.87s/batch, loss=9.353022]Training:  77%|███████▋  | 163/211 [1:14:10<20:55, 26.15s/batch, loss=9.353022]Training:  77%|███████▋  | 163/211 [1:15:19<20:55, 26.15s/batch, loss=9.345405]Training:  78%|███████▊  | 164/211 [1:15:19<30:26, 38.86s/batch, loss=9.345405]Training:  78%|███████▊  | 164/211 [1:15:22<30:26, 38.86s/batch, loss=9.052588]Training:  78%|███████▊  | 165/211 [1:15:22<21:34, 28.15s/batch, loss=9.052588]Training:  78%|███████▊  | 165/211 [1:15:25<21:34, 28.15s/batch, loss=9.140294]Training:  79%|███████▊  | 166/211 [1:15:25<15:30, 20.68s/batch, loss=9.140294]Training:  79%|███████▊  | 166/211 [1:15:54<15:30, 20.68s/batch, loss=9.224504]Training:  79%|███████▉  | 167/211 [1:15:54<17:03, 23.26s/batch, loss=9.224504]Training:  79%|███████▉  | 167/211 [1:16:59<17:03, 23.26s/batch, loss=9.388949]Training:  80%|███████▉  | 168/211 [1:16:59<25:33, 35.67s/batch, loss=9.388949]Training:  80%|███████▉  | 168/211 [1:17:10<25:33, 35.67s/batch, loss=9.273111]Training:  80%|████████  | 169/211 [1:17:10<19:44, 28.21s/batch, loss=9.273111]Training:  80%|████████  | 169/211 [1:17:13<19:44, 28.21s/batch, loss=9.347219]Training:  81%|████████  | 170/211 [1:17:13<14:08, 20.69s/batch, loss=9.347219]Training:  81%|████████  | 170/211 [1:17:45<14:08, 20.69s/batch, loss=8.927554]Training:  81%|████████  | 171/211 [1:17:45<16:06, 24.16s/batch, loss=8.927554]Training:  81%|████████  | 171/211 [1:18:48<16:06, 24.16s/batch, loss=8.714680]Training:  82%|████████▏ | 172/211 [1:18:48<23:12, 35.70s/batch, loss=8.714680]Training:  82%|████████▏ | 172/211 [1:18:51<23:12, 35.70s/batch, loss=9.390448]Training:  82%|████████▏ | 173/211 [1:18:51<16:26, 25.96s/batch, loss=9.390448]Training:  82%|████████▏ | 173/211 [1:18:58<16:26, 25.96s/batch, loss=8.928765]Training:  82%|████████▏ | 174/211 [1:18:58<12:24, 20.13s/batch, loss=8.928765]Training:  82%|████████▏ | 174/211 [1:19:39<12:24, 20.13s/batch, loss=8.992235]Training:  83%|████████▎ | 175/211 [1:19:39<15:56, 26.58s/batch, loss=8.992235]Training:  83%|████████▎ | 175/211 [1:20:31<15:56, 26.58s/batch, loss=9.308970]Training:  83%|████████▎ | 176/211 [1:20:32<20:08, 34.52s/batch, loss=9.308970]Training:  83%|████████▎ | 176/211 [1:20:35<20:08, 34.52s/batch, loss=9.564667]Training:  84%|████████▍ | 177/211 [1:20:35<14:13, 25.12s/batch, loss=9.564667]Training:  84%|████████▍ | 177/211 [1:21:04<14:13, 25.12s/batch, loss=9.170676]Training:  84%|████████▍ | 178/211 [1:21:04<14:22, 26.13s/batch, loss=9.170676]Training:  84%|████████▍ | 178/211 [1:21:32<14:22, 26.13s/batch, loss=9.426467]Training:  85%|████████▍ | 179/211 [1:21:32<14:14, 26.69s/batch, loss=9.426467]Training:  85%|████████▍ | 179/211 [1:22:24<14:14, 26.69s/batch, loss=8.925986]Training:  85%|████████▌ | 180/211 [1:22:24<17:44, 34.34s/batch, loss=8.925986]Training:  85%|████████▌ | 180/211 [1:22:27<17:44, 34.34s/batch, loss=8.856853]Training:  86%|████████▌ | 181/211 [1:22:27<12:30, 25.01s/batch, loss=8.856853]Training:  86%|████████▌ | 181/211 [1:22:56<12:30, 25.01s/batch, loss=9.310860]Training:  86%|████████▋ | 182/211 [1:22:56<12:37, 26.13s/batch, loss=9.310860]Training:  86%|████████▋ | 182/211 [1:23:24<12:37, 26.13s/batch, loss=9.379302]Training:  87%|████████▋ | 183/211 [1:23:24<12:30, 26.81s/batch, loss=9.379302]Training:  87%|████████▋ | 183/211 [1:24:25<12:30, 26.81s/batch, loss=9.026008]Training:  87%|████████▋ | 184/211 [1:24:25<16:37, 36.93s/batch, loss=9.026008]Training:  87%|████████▋ | 184/211 [1:24:28<16:37, 36.93s/batch, loss=8.865425]Training:  88%|████████▊ | 185/211 [1:24:28<11:36, 26.80s/batch, loss=8.865425]Training:  88%|████████▊ | 185/211 [1:24:40<11:36, 26.80s/batch, loss=9.106328]Training:  88%|████████▊ | 186/211 [1:24:40<09:19, 22.37s/batch, loss=9.106328]Training:  88%|████████▊ | 186/211 [1:25:24<09:19, 22.37s/batch, loss=9.379813]Training:  89%|████████▊ | 187/211 [1:25:25<11:37, 29.07s/batch, loss=9.379813]Training:  89%|████████▊ | 187/211 [1:26:19<11:37, 29.07s/batch, loss=9.007316]Training:  89%|████████▉ | 188/211 [1:26:19<14:01, 36.59s/batch, loss=9.007316]Training:  89%|████████▉ | 188/211 [1:26:22<14:01, 36.59s/batch, loss=9.235158]Training:  90%|████████▉ | 189/211 [1:26:22<09:44, 26.58s/batch, loss=9.235158]Training:  90%|████████▉ | 189/211 [1:26:25<09:44, 26.58s/batch, loss=9.045401]Training:  90%|█████████ | 190/211 [1:26:25<06:50, 19.55s/batch, loss=9.045401]Training:  90%|█████████ | 190/211 [1:27:11<06:50, 19.55s/batch, loss=9.497441]Training:  91%|█████████ | 191/211 [1:27:11<09:07, 27.36s/batch, loss=9.497441]Training:  91%|█████████ | 191/211 [1:28:18<09:07, 27.36s/batch, loss=8.680328]Training:  91%|█████████ | 192/211 [1:28:18<12:26, 39.28s/batch, loss=8.680328]Training:  91%|█████████ | 192/211 [1:28:21<12:26, 39.28s/batch, loss=9.037368]Training:  91%|█████████▏| 193/211 [1:28:21<08:32, 28.46s/batch, loss=9.037368]Training:  91%|█████████▏| 193/211 [1:28:25<08:32, 28.46s/batch, loss=9.123421]Training:  92%|█████████▏| 194/211 [1:28:25<05:55, 20.89s/batch, loss=9.123421]Training:  92%|█████████▏| 194/211 [1:29:04<05:55, 20.89s/batch, loss=9.505085]Training:  92%|█████████▏| 195/211 [1:29:05<07:10, 26.91s/batch, loss=9.505085]Training:  92%|█████████▏| 195/211 [1:30:09<07:10, 26.91s/batch, loss=9.117111]Training:  93%|█████████▎| 196/211 [1:30:09<09:27, 37.80s/batch, loss=9.117111]Training:  93%|█████████▎| 196/211 [1:30:12<09:27, 37.80s/batch, loss=9.111810]Training:  93%|█████████▎| 197/211 [1:30:12<06:23, 27.42s/batch, loss=9.111810]Training:  93%|█████████▎| 197/211 [1:30:15<06:23, 27.42s/batch, loss=9.413260]Training:  94%|█████████▍| 198/211 [1:30:15<04:21, 20.13s/batch, loss=9.413260]Training:  94%|█████████▍| 198/211 [1:30:53<04:21, 20.13s/batch, loss=9.302846]Training:  94%|█████████▍| 199/211 [1:30:53<05:06, 25.54s/batch, loss=9.302846]Training:  94%|█████████▍| 199/211 [1:31:59<05:06, 25.54s/batch, loss=9.280960]Training:  95%|█████████▍| 200/211 [1:32:00<06:56, 37.82s/batch, loss=9.280960]Training:  95%|█████████▍| 200/211 [1:32:03<06:56, 37.82s/batch, loss=9.298000]Training:  95%|█████████▌| 201/211 [1:32:03<04:34, 27.43s/batch, loss=9.298000]Training:  95%|█████████▌| 201/211 [1:32:06<04:34, 27.43s/batch, loss=8.886463]Training:  96%|█████████▌| 202/211 [1:32:06<03:01, 20.15s/batch, loss=8.886463]Training:  96%|█████████▌| 202/211 [1:32:53<03:01, 20.15s/batch, loss=9.152450]Training:  96%|█████████▌| 203/211 [1:32:53<03:44, 28.12s/batch, loss=9.152450]Training:  96%|█████████▌| 203/211 [1:33:53<03:44, 28.12s/batch, loss=9.348997]Training:  97%|█████████▋| 204/211 [1:33:53<04:24, 37.74s/batch, loss=9.348997]Training:  97%|█████████▋| 204/211 [1:33:56<04:24, 37.74s/batch, loss=8.993608]Training:  97%|█████████▋| 205/211 [1:33:56<02:44, 27.37s/batch, loss=8.993608]Training:  97%|█████████▋| 205/211 [1:33:59<02:44, 27.37s/batch, loss=9.219225]Training:  98%|█████████▊| 206/211 [1:33:59<01:40, 20.12s/batch, loss=9.219225]Training:  98%|█████████▊| 206/211 [1:34:41<01:40, 20.12s/batch, loss=9.169646]Training:  98%|█████████▊| 207/211 [1:34:41<01:46, 26.62s/batch, loss=9.169646]Training:  98%|█████████▊| 207/211 [1:35:20<01:46, 26.62s/batch, loss=9.072819]Training:  99%|█████████▊| 208/211 [1:35:20<01:30, 30.30s/batch, loss=9.072819]Training:  99%|█████████▊| 208/211 [1:35:23<01:30, 30.30s/batch, loss=9.089617]Training:  99%|█████████▉| 209/211 [1:35:23<00:44, 22.09s/batch, loss=9.089617]Training:  99%|█████████▉| 209/211 [1:35:26<00:44, 22.09s/batch, loss=9.572871]Training: 100%|█████████▉| 210/211 [1:35:26<00:16, 16.34s/batch, loss=9.572871]Training: 100%|█████████▉| 210/211 [1:35:27<00:16, 16.34s/batch, loss=9.158492]Training: 100%|██████████| 211/211 [1:35:27<00:00, 11.66s/batch, loss=9.158492]Training: 100%|██████████| 211/211 [1:35:27<00:00, 27.14s/batch, loss=9.158492]
Epoch 10, Train Loss: 9.3051, Val Loss: 9.1672
