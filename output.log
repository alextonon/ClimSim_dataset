nohup: les entrées sont ignorées
/home/alexandre-tonon/deep-learning/ClimSim_dataset/trainin_ssh.py:140: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.
  self.length = self.ds.dims['sample']
Training:   0%|          | 0/421 [00:00<?, ?batch/s]Training:   0%|          | 0/421 [02:14<?, ?batch/s, loss=0.984898]Training:   0%|          | 1/421 [02:14<15:40:11, 134.31s/batch, loss=0.984898]Training:   0%|          | 1/421 [02:27<15:40:11, 134.31s/batch, loss=1.021352]Training:   0%|          | 2/421 [02:27<7:20:21, 63.06s/batch, loss=1.021352]  Training:   0%|          | 2/421 [02:29<7:20:21, 63.06s/batch, loss=1.001522]Training:   1%|          | 3/421 [02:29<4:03:48, 35.00s/batch, loss=1.001522]Training:   1%|          | 3/421 [02:35<4:03:48, 35.00s/batch, loss=0.891630]Training:   1%|          | 4/421 [02:35<2:45:54, 23.87s/batch, loss=0.891630]Training:   1%|          | 4/421 [04:43<2:45:54, 23.87s/batch, loss=0.869831]Training:   1%|          | 5/421 [04:43<7:05:43, 61.40s/batch, loss=0.869831]Training:   1%|          | 5/421 [04:50<7:05:43, 61.40s/batch, loss=0.849955]Training:   1%|▏         | 6/421 [04:50<4:55:53, 42.78s/batch, loss=0.849955]Training:   1%|▏         | 6/421 [04:52<4:55:53, 42.78s/batch, loss=0.785212]Training:   2%|▏         | 7/421 [04:52<3:22:09, 29.30s/batch, loss=0.785212]Training:   2%|▏         | 7/421 [04:56<3:22:09, 29.30s/batch, loss=0.742069]Training:   2%|▏         | 8/421 [04:56<2:26:49, 21.33s/batch, loss=0.742069]Training:   2%|▏         | 8/421 [06:36<2:26:49, 21.33s/batch, loss=0.733573]Training:   2%|▏         | 9/421 [06:36<5:16:49, 46.14s/batch, loss=0.733573]Training:   2%|▏         | 9/421 [07:01<5:16:49, 46.14s/batch, loss=0.712301]Training:   2%|▏         | 10/421 [07:01<4:30:41, 39.52s/batch, loss=0.712301]Training:   2%|▏         | 10/421 [07:05<4:30:41, 39.52s/batch, loss=0.699765]Training:   3%|▎         | 11/421 [07:05<3:15:59, 28.68s/batch, loss=0.699765]Training:   3%|▎         | 11/421 [07:09<3:15:59, 28.68s/batch, loss=0.708942]Training:   3%|▎         | 12/421 [07:09<2:23:12, 21.01s/batch, loss=0.708942]Training:   3%|▎         | 12/421 [09:16<2:23:12, 21.01s/batch, loss=0.694785]Training:   3%|▎         | 13/421 [09:16<6:02:26, 53.30s/batch, loss=0.694785]Training:   3%|▎         | 13/421 [09:18<6:02:26, 53.30s/batch, loss=0.685235]Training:   3%|▎         | 14/421 [09:18<4:15:33, 37.67s/batch, loss=0.685235]Training:   3%|▎         | 14/421 [09:19<4:15:33, 37.67s/batch, loss=0.682497]Training:   4%|▎         | 15/421 [09:19<3:01:16, 26.79s/batch, loss=0.682497]Training:   4%|▎         | 15/421 [09:29<3:01:16, 26.79s/batch, loss=0.697951]Training:   4%|▍         | 16/421 [09:29<2:26:26, 21.70s/batch, loss=0.697951]Training:   4%|▍         | 16/421 [11:38<2:26:26, 21.70s/batch, loss=0.673449]Training:   4%|▍         | 17/421 [11:38<6:01:48, 53.73s/batch, loss=0.673449]Training:   4%|▍         | 17/421 [11:39<6:01:48, 53.73s/batch, loss=0.676338]Training:   4%|▍         | 18/421 [11:39<4:15:42, 38.07s/batch, loss=0.676338]Training:   4%|▍         | 18/421 [11:47<4:15:42, 38.07s/batch, loss=0.678800]Training:   5%|▍         | 19/421 [11:47<3:14:40, 29.06s/batch, loss=0.678800]Training:   5%|▍         | 19/421 [12:03<3:14:40, 29.06s/batch, loss=0.675298]Training:   5%|▍         | 20/421 [12:03<2:47:55, 25.12s/batch, loss=0.675298]Training:   5%|▍         | 20/421 [14:05<2:47:55, 25.12s/batch, loss=0.663680]Training:   5%|▍         | 21/421 [14:05<6:00:38, 54.10s/batch, loss=0.663680]Training:   5%|▍         | 21/421 [14:06<6:00:38, 54.10s/batch, loss=0.659415]Training:   5%|▌         | 22/421 [14:06<4:14:52, 38.33s/batch, loss=0.659415]Training:   5%|▌         | 22/421 [14:36<4:14:52, 38.33s/batch, loss=0.650384]Training:   5%|▌         | 23/421 [14:36<3:57:31, 35.81s/batch, loss=0.650384]Training:   5%|▌         | 23/421 [14:38<3:57:31, 35.81s/batch, loss=0.651017]Training:   6%|▌         | 24/421 [14:38<2:48:53, 25.53s/batch, loss=0.651017]Training:   6%|▌         | 24/421 [16:19<2:48:53, 25.53s/batch, loss=0.640273]Training:   6%|▌         | 25/421 [16:19<5:18:07, 48.20s/batch, loss=0.640273]Training:   6%|▌         | 25/421 [16:29<5:18:07, 48.20s/batch, loss=0.654735]Training:   6%|▌         | 26/421 [16:29<4:02:22, 36.82s/batch, loss=0.654735]Training:   6%|▌         | 26/421 [17:05<4:02:22, 36.82s/batch, loss=0.629389]Training:   6%|▋         | 27/421 [17:05<4:00:29, 36.62s/batch, loss=0.629389]Training:   6%|▋         | 27/421 [17:07<4:00:29, 36.62s/batch, loss=0.615578]Training:   7%|▋         | 28/421 [17:07<2:50:56, 26.10s/batch, loss=0.615578]Training:   7%|▋         | 28/421 [18:43<2:50:56, 26.10s/batch, loss=0.631447]Training:   7%|▋         | 29/421 [18:43<5:06:46, 46.96s/batch, loss=0.631447]Training:   7%|▋         | 29/421 [18:44<5:06:46, 46.96s/batch, loss=0.632277]Training:   7%|▋         | 30/421 [18:44<3:37:25, 33.36s/batch, loss=0.632277]Training:   7%|▋         | 30/421 [19:40<3:37:25, 33.36s/batch, loss=0.606368]Training:   7%|▋         | 31/421 [19:40<4:21:28, 40.23s/batch, loss=0.606368]Training:   7%|▋         | 31/421 [19:42<4:21:28, 40.23s/batch, loss=0.608768]Training:   8%|▊         | 32/421 [19:42<3:05:36, 28.63s/batch, loss=0.608768]Training:   8%|▊         | 32/421 [20:53<3:05:36, 28.63s/batch, loss=0.620199]Training:   8%|▊         | 33/421 [20:53<4:27:33, 41.38s/batch, loss=0.620199]Training:   8%|▊         | 33/421 [21:24<4:27:33, 41.38s/batch, loss=0.612767]Training:   8%|▊         | 34/421 [21:24<4:05:39, 38.09s/batch, loss=0.612767]Training:   8%|▊         | 34/421 [22:15<4:05:39, 38.09s/batch, loss=0.611788]Training:   8%|▊         | 35/421 [22:15<4:30:48, 42.09s/batch, loss=0.611788]Training:   8%|▊         | 35/421 [22:17<4:30:48, 42.09s/batch, loss=0.603222]Training:   9%|▊         | 36/421 [22:17<3:12:05, 29.94s/batch, loss=0.603222]Training:   9%|▊         | 36/421 [23:39<3:12:05, 29.94s/batch, loss=0.618753]Training:   9%|▉         | 37/421 [23:39<4:53:16, 45.82s/batch, loss=0.618753]Training:   9%|▉         | 37/421 [23:41<4:53:16, 45.82s/batch, loss=0.607464]Training:   9%|▉         | 38/421 [23:41<3:27:44, 32.54s/batch, loss=0.607464]Training:   9%|▉         | 38/421 [24:28<3:27:44, 32.54s/batch, loss=0.603220]Training:   9%|▉         | 39/421 [24:28<3:54:41, 36.86s/batch, loss=0.603220]Training:   9%|▉         | 39/421 [24:30<3:54:41, 36.86s/batch, loss=0.582835]Training:  10%|▉         | 40/421 [24:30<2:46:51, 26.28s/batch, loss=0.582835]Training:  10%|▉         | 40/421 [25:57<2:46:51, 26.28s/batch, loss=0.602237]Training:  10%|▉         | 41/421 [25:57<4:42:25, 44.59s/batch, loss=0.602237]Training:  10%|▉         | 41/421 [25:58<4:42:25, 44.59s/batch, loss=0.599262]Training:  10%|▉         | 42/421 [25:58<3:20:11, 31.69s/batch, loss=0.599262]Training:  10%|▉         | 42/421 [27:07<3:20:11, 31.69s/batch, loss=0.595544]Training:  10%|█         | 43/421 [27:07<4:28:54, 42.68s/batch, loss=0.595544]Training:  10%|█         | 43/421 [27:08<4:28:54, 42.68s/batch, loss=0.606119]Training:  10%|█         | 44/421 [27:08<3:10:40, 30.35s/batch, loss=0.606119]Training:  10%|█         | 44/421 [28:00<3:10:40, 30.35s/batch, loss=0.598081]Training:  11%|█         | 45/421 [28:00<3:49:58, 36.70s/batch, loss=0.598081]Training:  11%|█         | 45/421 [28:01<3:49:58, 36.70s/batch, loss=0.575036]Training:  11%|█         | 46/421 [28:01<2:43:25, 26.15s/batch, loss=0.575036]Training:  11%|█         | 46/421 [29:35<2:43:25, 26.15s/batch, loss=0.574763]Training:  11%|█         | 47/421 [29:35<4:49:02, 46.37s/batch, loss=0.574763]Training:  11%|█         | 47/421 [29:36<4:49:02, 46.37s/batch, loss=0.563974]Training:  11%|█▏        | 48/421 [29:36<3:24:38, 32.92s/batch, loss=0.563974]Training:  11%|█▏        | 48/421 [30:45<3:24:38, 32.92s/batch, loss=0.587239]Training:  12%|█▏        | 49/421 [30:45<4:30:09, 43.57s/batch, loss=0.587239]Training:  12%|█▏        | 49/421 [30:46<4:30:09, 43.57s/batch, loss=0.558445]Training:  12%|█▏        | 50/421 [30:46<3:11:27, 30.96s/batch, loss=0.558445]Training:  12%|█▏        | 50/421 [32:00<3:11:27, 30.96s/batch, loss=0.584018]Training:  12%|█▏        | 51/421 [32:00<4:29:28, 43.70s/batch, loss=0.584018]Training:  12%|█▏        | 51/421 [32:01<4:29:28, 43.70s/batch, loss=0.580986]Training:  12%|█▏        | 52/421 [32:01<3:11:00, 31.06s/batch, loss=0.580986]Training:  12%|█▏        | 52/421 [32:59<3:11:00, 31.06s/batch, loss=0.559258]Training:  13%|█▎        | 53/421 [32:59<3:58:49, 38.94s/batch, loss=0.559258]Training:  13%|█▎        | 53/421 [33:00<3:58:49, 38.94s/batch, loss=0.583563]Training:  13%|█▎        | 54/421 [33:00<2:49:38, 27.73s/batch, loss=0.583563]Training:  13%|█▎        | 54/421 [34:10<2:49:38, 27.73s/batch, loss=0.570756]Training:  13%|█▎        | 55/421 [34:10<4:06:36, 40.43s/batch, loss=0.570756]Training:  13%|█▎        | 55/421 [34:12<4:06:36, 40.43s/batch, loss=0.564956]Training:  13%|█▎        | 56/421 [34:12<2:55:09, 28.79s/batch, loss=0.564956]Training:  13%|█▎        | 56/421 [35:17<2:55:09, 28.79s/batch, loss=0.553824]Training:  14%|█▎        | 57/421 [35:17<3:59:53, 39.54s/batch, loss=0.553824]Training:  14%|█▎        | 57/421 [35:18<3:59:53, 39.54s/batch, loss=0.559746]Training:  14%|█▍        | 58/421 [35:18<2:50:22, 28.16s/batch, loss=0.559746]Training:  14%|█▍        | 58/421 [36:33<2:50:22, 28.16s/batch, loss=0.549752]Training:  14%|█▍        | 59/421 [36:33<4:14:25, 42.17s/batch, loss=0.549752]Training:  14%|█▍        | 59/421 [36:35<4:14:25, 42.17s/batch, loss=0.550079]Training:  14%|█▍        | 60/421 [36:35<3:00:34, 30.01s/batch, loss=0.550079]Training:  14%|█▍        | 60/421 [37:58<3:00:34, 30.01s/batch, loss=0.556266]Training:  14%|█▍        | 61/421 [37:58<4:36:29, 46.08s/batch, loss=0.556266]Training:  14%|█▍        | 61/421 [38:00<4:36:29, 46.08s/batch, loss=0.580272]Training:  15%|█▍        | 62/421 [38:00<3:15:47, 32.72s/batch, loss=0.580272]Training:  15%|█▍        | 62/421 [38:47<3:15:47, 32.72s/batch, loss=0.547404]Training:  15%|█▍        | 63/421 [38:47<3:40:05, 36.89s/batch, loss=0.547404]Training:  15%|█▍        | 63/421 [38:51<3:40:05, 36.89s/batch, loss=0.542795]Training:  15%|█▌        | 64/421 [38:51<2:40:59, 27.06s/batch, loss=0.542795]Training:  15%|█▌        | 64/421 [40:12<2:40:59, 27.06s/batch, loss=0.546160]Training:  15%|█▌        | 65/421 [40:12<4:17:34, 43.41s/batch, loss=0.546160]Training:  15%|█▌        | 65/421 [40:14<4:17:34, 43.41s/batch, loss=0.553530]Training:  16%|█▌        | 66/421 [40:14<3:02:41, 30.88s/batch, loss=0.553530]Training:  16%|█▌        | 66/421 [41:03<3:02:41, 30.88s/batch, loss=0.558682]Training:  16%|█▌        | 67/421 [41:03<3:34:22, 36.33s/batch, loss=0.558682]Training:  16%|█▌        | 67/421 [41:38<3:34:22, 36.33s/batch, loss=0.543431]Training:  16%|█▌        | 68/421 [41:38<3:31:31, 35.95s/batch, loss=0.543431]Training:  16%|█▌        | 68/421 [42:14<3:31:31, 35.95s/batch, loss=0.556611]Training:  16%|█▋        | 69/421 [42:14<3:30:47, 35.93s/batch, loss=0.556611]Training:  16%|█▋        | 69/421 [42:20<3:30:47, 35.93s/batch, loss=0.552196]Training:  17%|█▋        | 70/421 [42:20<2:38:24, 27.08s/batch, loss=0.552196]Training:  17%|█▋        | 70/421 [43:16<2:38:24, 27.08s/batch, loss=0.544922]Training:  17%|█▋        | 71/421 [43:16<3:28:51, 35.80s/batch, loss=0.544922]Training:  17%|█▋        | 71/421 [44:01<3:28:51, 35.80s/batch, loss=0.549760]Training:  17%|█▋        | 72/421 [44:01<3:43:46, 38.47s/batch, loss=0.549760]Training:  17%|█▋        | 72/421 [44:41<3:43:46, 38.47s/batch, loss=0.546032]Training:  17%|█▋        | 73/421 [44:41<3:46:13, 39.00s/batch, loss=0.546032]Training:  17%|█▋        | 73/421 [44:50<3:46:13, 39.00s/batch, loss=0.535359]Training:  18%|█▊        | 74/421 [44:50<2:52:27, 29.82s/batch, loss=0.535359]Training:  18%|█▊        | 74/421 [45:34<2:52:27, 29.82s/batch, loss=0.534016]Training:  18%|█▊        | 75/421 [45:34<3:16:39, 34.10s/batch, loss=0.534016]Training:  18%|█▊        | 75/421 [46:34<3:16:39, 34.10s/batch, loss=0.524614]Training:  18%|█▊        | 76/421 [46:34<4:00:23, 41.81s/batch, loss=0.524614]Training:  18%|█▊        | 76/421 [47:26<4:00:23, 41.81s/batch, loss=0.521969]Training:  18%|█▊        | 77/421 [47:26<4:18:11, 45.03s/batch, loss=0.521969]Training:  18%|█▊        | 77/421 [47:43<4:18:11, 45.03s/batch, loss=0.553927]Training:  19%|█▊        | 78/421 [47:43<3:29:45, 36.69s/batch, loss=0.553927]Training:  19%|█▊        | 78/421 [48:08<3:29:45, 36.69s/batch, loss=0.522193]Training:  19%|█▉        | 79/421 [48:08<3:07:43, 32.93s/batch, loss=0.522193]Training:  19%|█▉        | 79/421 [49:00<3:07:43, 32.93s/batch, loss=0.546064]Training:  19%|█▉        | 80/421 [49:00<3:40:47, 38.85s/batch, loss=0.546064]Training:  19%|█▉        | 80/421 [50:07<3:40:47, 38.85s/batch, loss=0.537154]Training:  19%|█▉        | 81/421 [50:07<4:27:27, 47.20s/batch, loss=0.537154]Training:  19%|█▉        | 81/421 [50:08<4:27:27, 47.20s/batch, loss=0.532572]Training:  19%|█▉        | 82/421 [50:08<3:09:16, 33.50s/batch, loss=0.532572]Training:  19%|█▉        | 82/421 [50:11<3:09:16, 33.50s/batch, loss=0.512284]Training:  20%|█▉        | 83/421 [50:11<2:15:37, 24.08s/batch, loss=0.512284]Training:  20%|█▉        | 83/421 [51:35<2:15:37, 24.08s/batch, loss=0.506794]Training:  20%|█▉        | 84/421 [51:35<3:57:22, 42.26s/batch, loss=0.506794]Training:  20%|█▉        | 84/421 [52:28<3:57:22, 42.26s/batch, loss=0.526038]Training:  20%|██        | 85/421 [52:28<4:13:49, 45.33s/batch, loss=0.526038]Training:  20%|██        | 85/421 [52:29<4:13:49, 45.33s/batch, loss=0.530520]Training:  20%|██        | 86/421 [52:29<2:59:45, 32.19s/batch, loss=0.530520]Training:  20%|██        | 86/421 [52:31<2:59:45, 32.19s/batch, loss=0.531398]Training:  21%|██        | 87/421 [52:31<2:08:03, 23.00s/batch, loss=0.531398]Training:  21%|██        | 87/421 [53:54<2:08:03, 23.00s/batch, loss=0.527618]Training:  21%|██        | 88/421 [53:54<3:48:02, 41.09s/batch, loss=0.527618]Training:  21%|██        | 88/421 [55:28<3:48:02, 41.09s/batch, loss=0.519493]Training:  21%|██        | 89/421 [55:28<5:14:28, 56.83s/batch, loss=0.519493]Training:  21%|██        | 89/421 [55:30<5:14:28, 56.83s/batch, loss=0.530383]Training:  21%|██▏       | 90/421 [55:30<3:43:20, 40.48s/batch, loss=0.530383]Training:  21%|██▏       | 90/421 [55:32<3:43:20, 40.48s/batch, loss=0.526790]Training:  22%|██▏       | 91/421 [55:32<2:39:53, 29.07s/batch, loss=0.526790]Training:  22%|██▏       | 91/421 [56:09<2:39:53, 29.07s/batch, loss=0.525541]Training:  22%|██▏       | 92/421 [56:09<2:51:11, 31.22s/batch, loss=0.525541]Training:  22%|██▏       | 92/421 [57:36<2:51:11, 31.22s/batch, loss=0.531987]Training:  22%|██▏       | 93/421 [57:36<4:22:42, 48.06s/batch, loss=0.531987]Training:  22%|██▏       | 93/421 [57:56<4:22:42, 48.06s/batch, loss=0.536344]Training:  22%|██▏       | 94/421 [57:56<3:35:17, 39.50s/batch, loss=0.536344]Training:  22%|██▏       | 94/421 [57:57<3:35:17, 39.50s/batch, loss=0.533148]Training:  23%|██▎       | 95/421 [57:57<2:32:49, 28.13s/batch, loss=0.533148]Training:  23%|██▎       | 95/421 [58:40<2:32:49, 28.13s/batch, loss=0.518560]Training:  23%|██▎       | 96/421 [58:40<2:56:48, 32.64s/batch, loss=0.518560]Training:  23%|██▎       | 96/421 [1:00:18<2:56:48, 32.64s/batch, loss=0.521285]Training:  23%|██▎       | 97/421 [1:00:18<4:40:49, 52.00s/batch, loss=0.521285]Training:  23%|██▎       | 97/421 [1:00:25<4:40:49, 52.00s/batch, loss=0.533182]Training:  23%|██▎       | 98/421 [1:00:25<3:28:10, 38.67s/batch, loss=0.533182]Training:  23%|██▎       | 98/421 [1:00:36<3:28:10, 38.67s/batch, loss=0.529344]Training:  24%|██▎       | 99/421 [1:00:36<2:42:34, 30.29s/batch, loss=0.529344]Training:  24%|██▎       | 99/421 [1:01:48<2:42:34, 30.29s/batch, loss=0.533742]Training:  24%|██▍       | 100/421 [1:01:48<3:48:39, 42.74s/batch, loss=0.533742]Training:  24%|██▍       | 100/421 [1:02:53<3:48:39, 42.74s/batch, loss=0.510428]Training:  24%|██▍       | 101/421 [1:02:53<4:24:01, 49.50s/batch, loss=0.510428]Training:  24%|██▍       | 101/421 [1:02:55<4:24:01, 49.50s/batch, loss=0.523391]Training:  24%|██▍       | 102/421 [1:02:55<3:06:49, 35.14s/batch, loss=0.523391]Training:  24%|██▍       | 102/421 [1:03:05<3:06:49, 35.14s/batch, loss=0.525766]Training:  24%|██▍       | 103/421 [1:03:05<2:26:39, 27.67s/batch, loss=0.525766]Training:  24%|██▍       | 103/421 [1:04:10<2:26:39, 27.67s/batch, loss=0.522117]Training:  25%|██▍       | 104/421 [1:04:10<3:25:10, 38.83s/batch, loss=0.522117]Training:  25%|██▍       | 104/421 [1:05:29<3:25:10, 38.83s/batch, loss=0.532645]Training:  25%|██▍       | 105/421 [1:05:29<4:27:52, 50.86s/batch, loss=0.532645]Training:  25%|██▍       | 105/421 [1:05:30<4:27:52, 50.86s/batch, loss=0.513976]Training:  25%|██▌       | 106/421 [1:05:30<3:09:31, 36.10s/batch, loss=0.513976]Training:  25%|██▌       | 106/421 [1:05:32<3:09:31, 36.10s/batch, loss=0.518258]Training:  25%|██▌       | 107/421 [1:05:32<2:14:40, 25.73s/batch, loss=0.518258]Training:  25%|██▌       | 107/421 [1:06:31<2:14:40, 25.73s/batch, loss=0.531779]Training:  26%|██▌       | 108/421 [1:06:31<3:07:05, 35.86s/batch, loss=0.531779]Training:  26%|██▌       | 108/421 [1:07:46<3:07:05, 35.86s/batch, loss=0.504930]Training:  26%|██▌       | 109/421 [1:07:46<4:06:42, 47.44s/batch, loss=0.504930]Training:  26%|██▌       | 109/421 [1:08:07<4:06:42, 47.44s/batch, loss=0.531878]Training:  26%|██▌       | 110/421 [1:08:07<3:24:27, 39.44s/batch, loss=0.531878]Training:  26%|██▌       | 110/421 [1:08:08<3:24:27, 39.44s/batch, loss=0.500559]Training:  26%|██▋       | 111/421 [1:08:08<2:25:07, 28.09s/batch, loss=0.500559]Training:  26%|██▋       | 111/421 [1:08:59<2:25:07, 28.09s/batch, loss=0.505817]Training:  27%|██▋       | 112/421 [1:08:59<3:00:08, 34.98s/batch, loss=0.505817]Training:  27%|██▋       | 112/421 [1:10:27<3:00:08, 34.98s/batch, loss=0.518686]Training:  27%|██▋       | 113/421 [1:10:27<4:20:20, 50.72s/batch, loss=0.518686]Training:  27%|██▋       | 113/421 [1:10:42<4:20:20, 50.72s/batch, loss=0.504625]Training:  27%|██▋       | 114/421 [1:10:42<3:25:41, 40.20s/batch, loss=0.504625]Training:  27%|██▋       | 114/421 [1:10:44<3:25:41, 40.20s/batch, loss=0.514353]Training:  27%|██▋       | 115/421 [1:10:44<2:25:53, 28.61s/batch, loss=0.514353]Training:  27%|██▋       | 115/421 [1:11:22<2:25:53, 28.61s/batch, loss=0.522538]Training:  28%|██▊       | 116/421 [1:11:22<2:40:29, 31.57s/batch, loss=0.522538]Training:  28%|██▊       | 116/421 [1:13:31<2:40:29, 31.57s/batch, loss=0.522763]Training:  28%|██▊       | 117/421 [1:13:31<5:07:04, 60.61s/batch, loss=0.522763]Training:  28%|██▊       | 117/421 [1:13:41<5:07:04, 60.61s/batch, loss=0.532605]Training:  28%|██▊       | 118/421 [1:13:41<3:49:52, 45.52s/batch, loss=0.532605]Training:  28%|██▊       | 118/421 [1:13:43<3:49:52, 45.52s/batch, loss=0.528384]Training:  28%|██▊       | 119/421 [1:13:43<2:42:55, 32.37s/batch, loss=0.528384]Training:  28%|██▊       | 119/421 [1:13:46<2:42:55, 32.37s/batch, loss=0.522870]Training:  29%|██▊       | 120/421 [1:13:46<1:59:23, 23.80s/batch, loss=0.522870]Training:  29%|██▊       | 120/421 [1:16:09<1:59:23, 23.80s/batch, loss=0.495918]Training:  29%|██▊       | 121/421 [1:16:09<4:56:18, 59.26s/batch, loss=0.495918]Training:  29%|██▊       | 121/421 [1:16:23<4:56:18, 59.26s/batch, loss=0.521153]Training:  29%|██▉       | 122/421 [1:16:23<3:48:13, 45.80s/batch, loss=0.521153]Training:  29%|██▉       | 122/421 [1:16:24<3:48:13, 45.80s/batch, loss=0.515084]Training:  29%|██▉       | 123/421 [1:16:24<2:41:27, 32.51s/batch, loss=0.515084]Training:  29%|██▉       | 123/421 [1:16:26<2:41:27, 32.51s/batch, loss=0.523159]Training:  29%|██▉       | 124/421 [1:16:26<1:55:02, 23.24s/batch, loss=0.523159]Training:  29%|██▉       | 124/421 [1:18:25<1:55:02, 23.24s/batch, loss=0.507689]Training:  30%|██▉       | 125/421 [1:18:25<4:16:36, 52.02s/batch, loss=0.507689]Training:  30%|██▉       | 125/421 [1:18:43<4:16:36, 52.02s/batch, loss=0.512014]Training:  30%|██▉       | 126/421 [1:18:43<3:24:48, 41.66s/batch, loss=0.512014]Training:  30%|██▉       | 126/421 [1:18:44<3:24:48, 41.66s/batch, loss=0.501307]Training:  30%|███       | 127/421 [1:18:44<2:25:12, 29.63s/batch, loss=0.501307]Training:  30%|███       | 127/421 [1:18:46<2:25:12, 29.63s/batch, loss=0.526707]Training:  30%|███       | 128/421 [1:18:46<1:43:33, 21.21s/batch, loss=0.526707]Training:  30%|███       | 128/421 [1:20:38<1:43:33, 21.21s/batch, loss=0.526218]Training:  31%|███       | 129/421 [1:20:38<3:55:55, 48.48s/batch, loss=0.526218]Training:  31%|███       | 129/421 [1:21:15<3:55:55, 48.48s/batch, loss=0.505386]Training:  31%|███       | 130/421 [1:21:15<3:38:14, 45.00s/batch, loss=0.505386]Training:  31%|███       | 130/421 [1:21:16<3:38:14, 45.00s/batch, loss=0.502779]Training:  31%|███       | 131/421 [1:21:16<2:34:32, 31.98s/batch, loss=0.502779]Training:  31%|███       | 131/421 [1:21:18<2:34:32, 31.98s/batch, loss=0.496909]Training:  31%|███▏      | 132/421 [1:21:18<1:50:04, 22.85s/batch, loss=0.496909]Training:  31%|███▏      | 132/421 [1:23:07<1:50:04, 22.85s/batch, loss=0.504611]Training:  32%|███▏      | 133/421 [1:23:07<3:54:09, 48.78s/batch, loss=0.504611]Training:  32%|███▏      | 133/421 [1:23:36<3:54:09, 48.78s/batch, loss=0.521366]Training:  32%|███▏      | 134/421 [1:23:36<3:24:49, 42.82s/batch, loss=0.521366]Training:  32%|███▏      | 134/421 [1:23:38<3:24:49, 42.82s/batch, loss=0.519498]Training:  32%|███▏      | 135/421 [1:23:38<2:25:36, 30.55s/batch, loss=0.519498]Training:  32%|███▏      | 135/421 [1:23:40<2:25:36, 30.55s/batch, loss=0.504209]Training:  32%|███▏      | 136/421 [1:23:40<1:43:46, 21.85s/batch, loss=0.504209]Training:  32%|███▏      | 136/421 [1:25:48<1:43:46, 21.85s/batch, loss=0.513997]Training:  33%|███▎      | 137/421 [1:25:49<4:15:28, 53.97s/batch, loss=0.513997]Training:  33%|███▎      | 137/421 [1:26:27<4:15:28, 53.97s/batch, loss=0.526646]Training:  33%|███▎      | 138/421 [1:26:27<3:52:03, 49.20s/batch, loss=0.526646]Training:  33%|███▎      | 138/421 [1:26:28<3:52:03, 49.20s/batch, loss=0.525607]Training:  33%|███▎      | 139/421 [1:26:28<2:44:00, 34.90s/batch, loss=0.525607]Training:  33%|███▎      | 139/421 [1:26:30<2:44:00, 34.90s/batch, loss=0.507012]Training:  33%|███▎      | 140/421 [1:26:30<1:56:35, 24.89s/batch, loss=0.507012]Training:  33%|███▎      | 140/421 [1:27:45<1:56:35, 24.89s/batch, loss=0.515065]Training:  33%|███▎      | 141/421 [1:27:45<3:06:43, 40.01s/batch, loss=0.515065]Training:  33%|███▎      | 141/421 [1:28:44<3:06:43, 40.01s/batch, loss=0.497080]Training:  34%|███▎      | 142/421 [1:28:44<3:33:04, 45.82s/batch, loss=0.497080]Training:  34%|███▎      | 142/421 [1:28:47<3:33:04, 45.82s/batch, loss=0.492810]Training:  34%|███▍      | 143/421 [1:28:47<2:31:55, 32.79s/batch, loss=0.492810]Training:  34%|███▍      | 143/421 [1:28:49<2:31:55, 32.79s/batch, loss=0.544793]Training:  34%|███▍      | 144/421 [1:28:49<1:49:10, 23.65s/batch, loss=0.544793]Training:  34%|███▍      | 144/421 [1:30:22<1:49:10, 23.65s/batch, loss=0.506127]Training:  34%|███▍      | 145/421 [1:30:22<3:24:27, 44.45s/batch, loss=0.506127]Training:  34%|███▍      | 145/421 [1:30:40<3:24:27, 44.45s/batch, loss=0.498839]Training:  35%|███▍      | 146/421 [1:30:40<2:47:29, 36.54s/batch, loss=0.498839]Training:  35%|███▍      | 146/421 [1:30:42<2:47:29, 36.54s/batch, loss=0.499742]Training:  35%|███▍      | 147/421 [1:30:42<1:58:56, 26.05s/batch, loss=0.499742]Training:  35%|███▍      | 147/421 [1:30:43<1:58:56, 26.05s/batch, loss=0.521630]Training:  35%|███▌      | 148/421 [1:30:43<1:25:01, 18.69s/batch, loss=0.521630]Training:  35%|███▌      | 148/421 [1:32:48<1:25:01, 18.69s/batch, loss=0.515384]Training:  35%|███▌      | 149/421 [1:32:48<3:49:34, 50.64s/batch, loss=0.515384]Training:  35%|███▌      | 149/421 [1:32:50<3:49:34, 50.64s/batch, loss=0.501682]Training:  36%|███▌      | 150/421 [1:32:50<2:42:15, 35.92s/batch, loss=0.501682]Training:  36%|███▌      | 150/421 [1:32:51<2:42:15, 35.92s/batch, loss=0.508487]Training:  36%|███▌      | 151/421 [1:32:51<1:55:13, 25.60s/batch, loss=0.508487]Training:  36%|███▌      | 151/421 [1:32:53<1:55:13, 25.60s/batch, loss=0.508009]Training:  36%|███▌      | 152/421 [1:32:53<1:22:24, 18.38s/batch, loss=0.508009]Training:  36%|███▌      | 152/421 [1:35:05<1:22:24, 18.38s/batch, loss=0.507721]Training:  36%|███▋      | 153/421 [1:35:05<3:55:00, 52.62s/batch, loss=0.507721]Training:  36%|███▋      | 153/421 [1:35:27<3:55:00, 52.62s/batch, loss=0.521188]Training:  37%|███▋      | 154/421 [1:35:27<3:12:33, 43.27s/batch, loss=0.521188]Training:  37%|███▋      | 154/421 [1:35:28<3:12:33, 43.27s/batch, loss=0.503121]Training:  37%|███▋      | 155/421 [1:35:28<2:16:19, 30.75s/batch, loss=0.503121]Training:  37%|███▋      | 155/421 [1:35:30<2:16:19, 30.75s/batch, loss=0.493935]Training:  37%|███▋      | 156/421 [1:35:30<1:37:07, 21.99s/batch, loss=0.493935]Training:  37%|███▋      | 156/421 [1:37:02<1:37:07, 21.99s/batch, loss=0.497814]Training:  37%|███▋      | 157/421 [1:37:02<3:09:40, 43.11s/batch, loss=0.497814]Training:  37%|███▋      | 157/421 [1:37:52<3:09:40, 43.11s/batch, loss=0.508185]Training:  38%|███▊      | 158/421 [1:37:52<3:16:51, 44.91s/batch, loss=0.508185]Training:  38%|███▊      | 158/421 [1:37:53<3:16:51, 44.91s/batch, loss=0.516375]Training:  38%|███▊      | 159/421 [1:37:53<2:19:15, 31.89s/batch, loss=0.516375]Training:  38%|███▊      | 159/421 [1:37:55<2:19:15, 31.89s/batch, loss=0.504047]Training:  38%|███▊      | 160/421 [1:37:55<1:39:05, 22.78s/batch, loss=0.504047]Training:  38%|███▊      | 160/421 [1:39:11<1:39:05, 22.78s/batch, loss=0.499008]Training:  38%|███▊      | 161/421 [1:39:11<2:49:05, 39.02s/batch, loss=0.499008]Training:  38%|███▊      | 161/421 [1:39:53<2:49:05, 39.02s/batch, loss=0.498106]Training:  38%|███▊      | 162/421 [1:39:53<2:51:14, 39.67s/batch, loss=0.498106]Training:  38%|███▊      | 162/421 [1:39:54<2:51:14, 39.67s/batch, loss=0.492853]Training:  39%|███▊      | 163/421 [1:39:54<2:01:29, 28.25s/batch, loss=0.492853]Training:  39%|███▊      | 163/421 [1:39:56<2:01:29, 28.25s/batch, loss=0.503812]Training:  39%|███▉      | 164/421 [1:39:56<1:26:43, 20.25s/batch, loss=0.503812]Training:  39%|███▉      | 164/421 [1:41:07<1:26:43, 20.25s/batch, loss=0.494761]Training:  39%|███▉      | 165/421 [1:41:07<2:31:26, 35.49s/batch, loss=0.494761]Training:  39%|███▉      | 165/421 [1:42:19<2:31:26, 35.49s/batch, loss=0.494629]Training:  39%|███▉      | 166/421 [1:42:19<3:17:59, 46.58s/batch, loss=0.494629]Training:  39%|███▉      | 166/421 [1:42:21<3:17:59, 46.58s/batch, loss=0.495560]Training:  40%|███▉      | 167/421 [1:42:21<2:19:57, 33.06s/batch, loss=0.495560]Training:  40%|███▉      | 167/421 [1:42:22<2:19:57, 33.06s/batch, loss=0.515870]Training:  40%|███▉      | 168/421 [1:42:22<1:39:31, 23.60s/batch, loss=0.515870]Training:  40%|███▉      | 168/421 [1:43:23<1:39:31, 23.60s/batch, loss=0.515944]Training:  40%|████      | 169/421 [1:43:23<2:26:01, 34.77s/batch, loss=0.515944]Training:  40%|████      | 169/421 [1:44:40<2:26:01, 34.77s/batch, loss=0.499694]Training:  40%|████      | 170/421 [1:44:40<3:18:38, 47.49s/batch, loss=0.499694]Training:  40%|████      | 170/421 [1:44:42<3:18:38, 47.49s/batch, loss=0.513827]Training:  41%|████      | 171/421 [1:44:42<2:20:22, 33.69s/batch, loss=0.513827]Training:  41%|████      | 171/421 [1:44:43<2:20:22, 33.69s/batch, loss=0.515788]Training:  41%|████      | 172/421 [1:44:43<1:39:42, 24.03s/batch, loss=0.515788]Training:  41%|████      | 172/421 [1:45:30<1:39:42, 24.03s/batch, loss=0.498995]Training:  41%|████      | 173/421 [1:45:30<2:07:07, 30.75s/batch, loss=0.498995]Training:  41%|████      | 173/421 [1:46:46<2:07:07, 30.75s/batch, loss=0.513826]Training:  41%|████▏     | 174/421 [1:46:46<3:03:07, 44.49s/batch, loss=0.513826]Training:  41%|████▏     | 174/421 [1:46:48<3:03:07, 44.49s/batch, loss=0.520204]Training:  42%|████▏     | 175/421 [1:46:48<2:09:34, 31.61s/batch, loss=0.520204]Training:  42%|████▏     | 175/421 [1:46:49<2:09:34, 31.61s/batch, loss=0.487641]Training:  42%|████▏     | 176/421 [1:46:49<1:32:11, 22.58s/batch, loss=0.487641]Training:  42%|████▏     | 176/421 [1:47:34<1:32:11, 22.58s/batch, loss=0.506149]Training:  42%|████▏     | 177/421 [1:47:34<1:58:16, 29.09s/batch, loss=0.506149]Training:  42%|████▏     | 177/421 [1:49:00<1:58:16, 29.09s/batch, loss=0.518971]Training:  42%|████▏     | 178/421 [1:49:01<3:08:22, 46.51s/batch, loss=0.518971]Training:  42%|████▏     | 178/421 [1:49:03<3:08:22, 46.51s/batch, loss=0.492197]Training:  43%|████▎     | 179/421 [1:49:03<2:13:18, 33.05s/batch, loss=0.492197]Training:  43%|████▎     | 179/421 [1:49:04<2:13:18, 33.05s/batch, loss=0.505470]Training:  43%|████▎     | 180/421 [1:49:04<1:34:45, 23.59s/batch, loss=0.505470]Training:  43%|████▎     | 180/421 [1:49:47<1:34:45, 23.59s/batch, loss=0.503438]Training:  43%|████▎     | 181/421 [1:49:47<1:57:52, 29.47s/batch, loss=0.503438]Training:  43%|████▎     | 181/421 [1:51:27<1:57:52, 29.47s/batch, loss=0.519281]Training:  43%|████▎     | 182/421 [1:51:27<3:21:16, 50.53s/batch, loss=0.519281]Training:  43%|████▎     | 182/421 [1:51:28<3:21:16, 50.53s/batch, loss=0.507077]Training:  43%|████▎     | 183/421 [1:51:28<2:22:08, 35.84s/batch, loss=0.507077]Training:  43%|████▎     | 183/421 [1:51:30<2:22:08, 35.84s/batch, loss=0.501071]Training:  44%|████▎     | 184/421 [1:51:30<1:40:52, 25.54s/batch, loss=0.501071]Training:  44%|████▎     | 184/421 [1:52:26<1:40:52, 25.54s/batch, loss=0.497154]Training:  44%|████▍     | 185/421 [1:52:26<2:16:53, 34.80s/batch, loss=0.497154]Training:  44%|████▍     | 185/421 [1:53:24<2:16:53, 34.80s/batch, loss=0.492254]Training:  44%|████▍     | 186/421 [1:53:24<2:43:11, 41.67s/batch, loss=0.492254]Training:  44%|████▍     | 186/421 [1:53:26<2:43:11, 41.67s/batch, loss=0.491854]Training:  44%|████▍     | 187/421 [1:53:26<1:55:33, 29.63s/batch, loss=0.491854]Training:  44%|████▍     | 187/421 [1:53:27<1:55:33, 29.63s/batch, loss=0.494000]Training:  45%|████▍     | 188/421 [1:53:27<1:22:20, 21.20s/batch, loss=0.494000]Training:  45%|████▍     | 188/421 [1:54:29<1:22:20, 21.20s/batch, loss=0.486605]Training:  45%|████▍     | 189/421 [1:54:29<2:09:21, 33.45s/batch, loss=0.486605]Training:  45%|████▍     | 189/421 [1:55:28<2:09:21, 33.45s/batch, loss=0.493751]Training:  45%|████▌     | 190/421 [1:55:28<2:37:34, 40.93s/batch, loss=0.493751]Training:  45%|████▌     | 190/421 [1:55:29<2:37:34, 40.93s/batch, loss=0.495782]Training:  45%|████▌     | 191/421 [1:55:29<1:51:37, 29.12s/batch, loss=0.495782]Training:  45%|████▌     | 191/421 [1:55:31<1:51:37, 29.12s/batch, loss=0.499165]Training:  46%|████▌     | 192/421 [1:55:31<1:19:33, 20.85s/batch, loss=0.499165]Training:  46%|████▌     | 192/421 [1:56:42<1:19:33, 20.85s/batch, loss=0.492518]Training:  46%|████▌     | 193/421 [1:56:42<2:17:21, 36.15s/batch, loss=0.492518]Training:  46%|████▌     | 193/421 [1:57:33<2:17:21, 36.15s/batch, loss=0.506760]Training:  46%|████▌     | 194/421 [1:57:33<2:33:11, 40.49s/batch, loss=0.506760]Training:  46%|████▌     | 194/421 [1:57:35<2:33:11, 40.49s/batch, loss=0.515157]Training:  46%|████▋     | 195/421 [1:57:35<1:48:32, 28.81s/batch, loss=0.515157]Training:  46%|████▋     | 195/421 [1:57:36<1:48:32, 28.81s/batch, loss=0.509688]Training:  47%|████▋     | 196/421 [1:57:36<1:17:29, 20.66s/batch, loss=0.509688]Training:  47%|████▋     | 196/421 [1:59:08<1:17:29, 20.66s/batch, loss=0.505615]Training:  47%|████▋     | 197/421 [1:59:08<2:36:47, 42.00s/batch, loss=0.505615]Training:  47%|████▋     | 197/421 [1:59:53<2:36:47, 42.00s/batch, loss=0.495749]Training:  47%|████▋     | 198/421 [1:59:53<2:39:20, 42.87s/batch, loss=0.495749]Training:  47%|████▋     | 198/421 [1:59:55<2:39:20, 42.87s/batch, loss=0.495143]Training:  47%|████▋     | 199/421 [1:59:55<1:52:44, 30.47s/batch, loss=0.495143]Training:  47%|████▋     | 199/421 [1:59:56<1:52:44, 30.47s/batch, loss=0.495531]Training:  48%|████▊     | 200/421 [1:59:56<1:20:14, 21.78s/batch, loss=0.495531]Training:  48%|████▊     | 200/421 [2:01:12<1:20:14, 21.78s/batch, loss=0.494775]Training:  48%|████▊     | 201/421 [2:01:12<2:19:04, 37.93s/batch, loss=0.494775]Training:  48%|████▊     | 201/421 [2:02:00<2:19:04, 37.93s/batch, loss=0.493514]Training:  48%|████▊     | 202/421 [2:02:00<2:30:00, 41.10s/batch, loss=0.493514]Training:  48%|████▊     | 202/421 [2:02:02<2:30:00, 41.10s/batch, loss=0.489354]Training:  48%|████▊     | 203/421 [2:02:02<1:46:16, 29.25s/batch, loss=0.489354]Training:  48%|████▊     | 203/421 [2:02:03<1:46:16, 29.25s/batch, loss=0.501879]Training:  48%|████▊     | 204/421 [2:02:03<1:15:45, 20.95s/batch, loss=0.501879]Training:  48%|████▊     | 204/421 [2:03:25<1:15:45, 20.95s/batch, loss=0.499816]Training:  49%|████▊     | 205/421 [2:03:25<2:21:12, 39.22s/batch, loss=0.499816]Training:  49%|████▊     | 205/421 [2:04:20<2:21:12, 39.22s/batch, loss=0.504724]Training:  49%|████▉     | 206/421 [2:04:20<2:36:51, 43.78s/batch, loss=0.504724]Training:  49%|████▉     | 206/421 [2:04:21<2:36:51, 43.78s/batch, loss=0.499802]Training:  49%|████▉     | 207/421 [2:04:21<1:50:59, 31.12s/batch, loss=0.499802]Training:  49%|████▉     | 207/421 [2:04:23<1:50:59, 31.12s/batch, loss=0.494894]Training:  49%|████▉     | 208/421 [2:04:23<1:18:59, 22.25s/batch, loss=0.494894]Training:  49%|████▉     | 208/421 [2:05:40<1:18:59, 22.25s/batch, loss=0.499237]Training:  50%|████▉     | 209/421 [2:05:40<2:16:40, 38.68s/batch, loss=0.499237]Training:  50%|████▉     | 209/421 [2:06:58<2:16:40, 38.68s/batch, loss=0.504586]Training:  50%|████▉     | 210/421 [2:06:58<2:57:55, 50.59s/batch, loss=0.504586]Training:  50%|████▉     | 210/421 [2:07:00<2:57:55, 50.59s/batch, loss=0.476851]Training:  50%|█████     | 211/421 [2:07:00<2:05:36, 35.89s/batch, loss=0.476851]Training:  50%|█████     | 211/421 [2:07:01<2:05:36, 35.89s/batch, loss=0.491484]Training:  50%|█████     | 212/421 [2:07:01<1:29:06, 25.58s/batch, loss=0.491484]Training:  50%|█████     | 212/421 [2:08:01<1:29:06, 25.58s/batch, loss=0.497504]Training:  51%|█████     | 213/421 [2:08:01<2:03:43, 35.69s/batch, loss=0.497504]Training:  51%|█████     | 213/421 [2:08:47<2:03:43, 35.69s/batch, loss=0.483001]Training:  51%|█████     | 214/421 [2:08:47<2:14:02, 38.85s/batch, loss=0.483001]Training:  51%|█████     | 214/421 [2:08:48<2:14:02, 38.85s/batch, loss=0.488865]Training:  51%|█████     | 215/421 [2:08:48<1:34:57, 27.66s/batch, loss=0.488865]Training:  51%|█████     | 215/421 [2:08:50<1:34:57, 27.66s/batch, loss=0.495629]Training:  51%|█████▏    | 216/421 [2:08:50<1:07:42, 19.82s/batch, loss=0.495629]Training:  51%|█████▏    | 216/421 [2:10:31<1:07:42, 19.82s/batch, loss=0.487912]Training:  52%|█████▏    | 217/421 [2:10:31<2:30:09, 44.17s/batch, loss=0.487912]Training:  52%|█████▏    | 217/421 [2:11:28<2:30:09, 44.17s/batch, loss=0.494550]Training:  52%|█████▏    | 218/421 [2:11:28<2:42:21, 47.99s/batch, loss=0.494550]Training:  52%|█████▏    | 218/421 [2:11:29<2:42:21, 47.99s/batch, loss=0.496267]Training:  52%|█████▏    | 219/421 [2:11:29<1:54:40, 34.06s/batch, loss=0.496267]Training:  52%|█████▏    | 219/421 [2:11:31<1:54:40, 34.06s/batch, loss=0.489695]Training:  52%|█████▏    | 220/421 [2:11:31<1:21:24, 24.30s/batch, loss=0.489695]Training:  52%|█████▏    | 220/421 [2:12:44<1:21:24, 24.30s/batch, loss=0.484336]Training:  52%|█████▏    | 221/421 [2:12:44<2:09:42, 38.91s/batch, loss=0.484336]Training:  52%|█████▏    | 221/421 [2:13:32<2:09:42, 38.91s/batch, loss=0.486780]Training:  53%|█████▎    | 222/421 [2:13:32<2:18:31, 41.77s/batch, loss=0.486780]Training:  53%|█████▎    | 222/421 [2:13:34<2:18:31, 41.77s/batch, loss=0.479704]Training:  53%|█████▎    | 223/421 [2:13:34<1:38:03, 29.72s/batch, loss=0.479704]Training:  53%|█████▎    | 223/421 [2:13:35<1:38:03, 29.72s/batch, loss=0.512969]Training:  53%|█████▎    | 224/421 [2:13:35<1:09:50, 21.27s/batch, loss=0.512969]Training:  53%|█████▎    | 224/421 [2:15:24<1:09:50, 21.27s/batch, loss=0.504786]Training:  53%|█████▎    | 225/421 [2:15:24<2:35:20, 47.55s/batch, loss=0.504786]Training:  53%|█████▎    | 225/421 [2:15:26<2:35:20, 47.55s/batch, loss=0.489367]Training:  54%|█████▎    | 226/421 [2:15:26<1:49:40, 33.74s/batch, loss=0.489367]Training:  54%|█████▎    | 226/421 [2:15:27<1:49:40, 33.74s/batch, loss=0.498091]Training:  54%|█████▍    | 227/421 [2:15:27<1:17:49, 24.07s/batch, loss=0.498091]Training:  54%|█████▍    | 227/421 [2:15:29<1:17:49, 24.07s/batch, loss=0.480413]Training:  54%|█████▍    | 228/421 [2:15:29<55:39, 17.30s/batch, loss=0.480413]  Training:  54%|█████▍    | 228/421 [2:17:25<55:39, 17.30s/batch, loss=0.500715]Training:  54%|█████▍    | 229/421 [2:17:25<2:30:39, 47.08s/batch, loss=0.500715]Training:  54%|█████▍    | 229/421 [2:17:36<2:30:39, 47.08s/batch, loss=0.505109]Training:  55%|█████▍    | 230/421 [2:17:36<1:54:38, 36.01s/batch, loss=0.505109]Training:  55%|█████▍    | 230/421 [2:17:37<1:54:38, 36.01s/batch, loss=0.505390]Training:  55%|█████▍    | 231/421 [2:17:37<1:21:16, 25.67s/batch, loss=0.505390]Training:  55%|█████▍    | 231/421 [2:17:39<1:21:16, 25.67s/batch, loss=0.467028]Training:  55%|█████▌    | 232/421 [2:17:39<58:04, 18.44s/batch, loss=0.467028]  Training:  55%|█████▌    | 232/421 [2:19:39<58:04, 18.44s/batch, loss=0.500779]Training:  55%|█████▌    | 233/421 [2:19:39<2:33:44, 49.07s/batch, loss=0.500779]Training:  55%|█████▌    | 233/421 [2:19:52<2:33:44, 49.07s/batch, loss=0.492426]Training:  56%|█████▌    | 234/421 [2:19:52<1:58:57, 38.17s/batch, loss=0.492426]Training:  56%|█████▌    | 234/421 [2:19:53<1:58:57, 38.17s/batch, loss=0.500950]Training:  56%|█████▌    | 235/421 [2:19:53<1:24:13, 27.17s/batch, loss=0.500950]Training:  56%|█████▌    | 235/421 [2:20:05<1:24:13, 27.17s/batch, loss=0.482587]Training:  56%|█████▌    | 236/421 [2:20:05<1:09:32, 22.56s/batch, loss=0.482587]Training:  56%|█████▌    | 236/421 [2:21:59<1:09:32, 22.56s/batch, loss=0.478450]Training:  56%|█████▋    | 237/421 [2:21:59<2:33:14, 49.97s/batch, loss=0.478450]Training:  56%|█████▋    | 237/421 [2:22:08<2:33:14, 49.97s/batch, loss=0.504499]Training:  57%|█████▋    | 238/421 [2:22:08<1:54:55, 37.68s/batch, loss=0.504499]Training:  57%|█████▋    | 238/421 [2:22:10<1:54:55, 37.68s/batch, loss=0.495286]Training:  57%|█████▋    | 239/421 [2:22:10<1:21:23, 26.84s/batch, loss=0.495286]Training:  57%|█████▋    | 239/421 [2:22:12<1:21:23, 26.84s/batch, loss=0.474710]Training:  57%|█████▋    | 240/421 [2:22:12<58:38, 19.44s/batch, loss=0.474710]  Training:  57%|█████▋    | 240/421 [2:24:47<58:38, 19.44s/batch, loss=0.491125]Training:  57%|█████▋    | 241/421 [2:24:47<3:00:36, 60.20s/batch, loss=0.491125]Training:  57%|█████▋    | 241/421 [2:24:49<3:00:36, 60.20s/batch, loss=0.478265]Training:  57%|█████▋    | 242/421 [2:24:49<2:07:05, 42.60s/batch, loss=0.478265]Training:  57%|█████▋    | 242/421 [2:24:50<2:07:05, 42.60s/batch, loss=0.493058]Training:  58%|█████▊    | 243/421 [2:24:50<1:29:50, 30.28s/batch, loss=0.493058]Training:  58%|█████▊    | 243/421 [2:24:52<1:29:50, 30.28s/batch, loss=0.476391]Training:  58%|█████▊    | 244/421 [2:24:52<1:03:54, 21.66s/batch, loss=0.476391]Training:  58%|█████▊    | 244/421 [2:27:04<1:03:54, 21.66s/batch, loss=0.498890]Training:  58%|█████▊    | 245/421 [2:27:04<2:41:05, 54.92s/batch, loss=0.498890]Training:  58%|█████▊    | 245/421 [2:27:06<2:41:05, 54.92s/batch, loss=0.483665]Training:  58%|█████▊    | 246/421 [2:27:06<1:53:28, 38.90s/batch, loss=0.483665]Training:  58%|█████▊    | 246/421 [2:27:07<1:53:28, 38.90s/batch, loss=0.497369]Training:  59%|█████▊    | 247/421 [2:27:07<1:20:18, 27.69s/batch, loss=0.497369]Training:  59%|█████▊    | 247/421 [2:27:09<1:20:18, 27.69s/batch, loss=0.497340]Training:  59%|█████▉    | 248/421 [2:27:09<57:11, 19.84s/batch, loss=0.497340]  Training:  59%|█████▉    | 248/421 [2:29:32<57:11, 19.84s/batch, loss=0.490094]Training:  59%|█████▉    | 249/421 [2:29:32<2:42:53, 56.82s/batch, loss=0.490094]Training:  59%|█████▉    | 249/421 [2:29:34<2:42:53, 56.82s/batch, loss=0.476419]Training:  59%|█████▉    | 250/421 [2:29:34<1:54:38, 40.23s/batch, loss=0.476419]Training:  59%|█████▉    | 250/421 [2:29:35<1:54:38, 40.23s/batch, loss=0.475121]Training:  60%|█████▉    | 251/421 [2:29:35<1:21:04, 28.62s/batch, loss=0.475121]Training:  60%|█████▉    | 251/421 [2:29:37<1:21:04, 28.62s/batch, loss=0.484129]Training:  60%|█████▉    | 252/421 [2:29:37<57:44, 20.50s/batch, loss=0.484129]  Training:  60%|█████▉    | 252/421 [2:31:31<57:44, 20.50s/batch, loss=0.494608]Training:  60%|██████    | 253/421 [2:31:31<2:16:10, 48.64s/batch, loss=0.494608]Training:  60%|██████    | 253/421 [2:31:36<2:16:10, 48.64s/batch, loss=0.493757]Training:  60%|██████    | 254/421 [2:31:36<1:38:59, 35.57s/batch, loss=0.493757]Training:  60%|██████    | 254/421 [2:31:38<1:38:59, 35.57s/batch, loss=0.485962]Training:  61%|██████    | 255/421 [2:31:38<1:10:08, 25.35s/batch, loss=0.485962]Training:  61%|██████    | 255/421 [2:31:39<1:10:08, 25.35s/batch, loss=0.485784]Training:  61%|██████    | 256/421 [2:31:39<50:03, 18.21s/batch, loss=0.485784]  Training:  61%|██████    | 256/421 [2:33:37<50:03, 18.21s/batch, loss=0.483031]Training:  61%|██████    | 257/421 [2:33:37<2:11:40, 48.17s/batch, loss=0.483031]Training:  61%|██████    | 257/421 [2:34:03<2:11:40, 48.17s/batch, loss=0.464993]Training:  61%|██████▏   | 258/421 [2:34:03<1:52:38, 41.46s/batch, loss=0.464993]Training:  61%|██████▏   | 258/421 [2:34:04<1:52:38, 41.46s/batch, loss=0.512394]Training:  62%|██████▏   | 259/421 [2:34:04<1:19:37, 29.49s/batch, loss=0.512394]Training:  62%|██████▏   | 259/421 [2:34:06<1:19:37, 29.49s/batch, loss=0.495390]Training:  62%|██████▏   | 260/421 [2:34:06<56:37, 21.10s/batch, loss=0.495390]  Training:  62%|██████▏   | 260/421 [2:36:02<56:37, 21.10s/batch, loss=0.492427]Training:  62%|██████▏   | 261/421 [2:36:02<2:12:20, 49.63s/batch, loss=0.492427]Training:  62%|██████▏   | 261/421 [2:36:16<2:12:20, 49.63s/batch, loss=0.498711]Training:  62%|██████▏   | 262/421 [2:36:16<1:42:58, 38.86s/batch, loss=0.498711]Training:  62%|██████▏   | 262/421 [2:36:17<1:42:58, 38.86s/batch, loss=0.477261]Training:  62%|██████▏   | 263/421 [2:36:17<1:12:50, 27.66s/batch, loss=0.477261]Training:  62%|██████▏   | 263/421 [2:36:19<1:12:50, 27.66s/batch, loss=0.484183]Training:  63%|██████▎   | 264/421 [2:36:19<51:51, 19.82s/batch, loss=0.484183]  Training:  63%|██████▎   | 264/421 [2:38:24<51:51, 19.82s/batch, loss=0.475773]Training:  63%|██████▎   | 265/421 [2:38:25<2:14:14, 51.63s/batch, loss=0.475773]Training:  63%|██████▎   | 265/421 [2:38:26<2:14:14, 51.63s/batch, loss=0.489835]Training:  63%|██████▎   | 266/421 [2:38:26<1:34:33, 36.60s/batch, loss=0.489835]Training:  63%|██████▎   | 266/421 [2:38:28<1:34:33, 36.60s/batch, loss=0.469949]Training:  63%|██████▎   | 267/421 [2:38:28<1:06:56, 26.08s/batch, loss=0.469949]Training:  63%|██████▎   | 267/421 [2:38:29<1:06:56, 26.08s/batch, loss=0.474666]Training:  64%|██████▎   | 268/421 [2:38:29<47:44, 18.72s/batch, loss=0.474666]  Training:  64%|██████▎   | 268/421 [2:40:40<47:44, 18.72s/batch, loss=0.476291]Training:  64%|██████▍   | 269/421 [2:40:40<2:12:32, 52.32s/batch, loss=0.476291]Training:  64%|██████▍   | 269/421 [2:40:42<2:12:32, 52.32s/batch, loss=0.486449]Training:  64%|██████▍   | 270/421 [2:40:42<1:33:19, 37.08s/batch, loss=0.486449]Training:  64%|██████▍   | 270/421 [2:40:43<1:33:19, 37.08s/batch, loss=0.471018]Training:  64%|██████▍   | 271/421 [2:40:43<1:06:03, 26.43s/batch, loss=0.471018]Training:  64%|██████▍   | 271/421 [2:40:45<1:06:03, 26.43s/batch, loss=0.495023]Training:  65%|██████▍   | 272/421 [2:40:45<47:06, 18.97s/batch, loss=0.495023]  Training:  65%|██████▍   | 272/421 [2:42:49<47:06, 18.97s/batch, loss=0.471592]Training:  65%|██████▍   | 273/421 [2:42:49<2:04:46, 50.59s/batch, loss=0.471592]Training:  65%|██████▍   | 273/421 [2:42:53<2:04:46, 50.59s/batch, loss=0.485136]Training:  65%|██████▌   | 274/421 [2:42:53<1:29:44, 36.63s/batch, loss=0.485136]Training:  65%|██████▌   | 274/421 [2:42:55<1:29:44, 36.63s/batch, loss=0.485067]Training:  65%|██████▌   | 275/421 [2:42:55<1:03:33, 26.12s/batch, loss=0.485067]Training:  65%|██████▌   | 275/421 [2:42:56<1:03:33, 26.12s/batch, loss=0.479448]Training:  66%|██████▌   | 276/421 [2:42:56<45:19, 18.75s/batch, loss=0.479448]  Training:  66%|██████▌   | 276/421 [2:45:24<45:19, 18.75s/batch, loss=0.493373]Training:  66%|██████▌   | 277/421 [2:45:24<2:17:45, 57.40s/batch, loss=0.493373]Training:  66%|██████▌   | 277/421 [2:45:26<2:17:45, 57.40s/batch, loss=0.468512]Training:  66%|██████▌   | 278/421 [2:45:26<1:36:53, 40.66s/batch, loss=0.468512]Training:  66%|██████▌   | 278/421 [2:45:27<1:36:53, 40.66s/batch, loss=0.492907]Training:  66%|██████▋   | 279/421 [2:45:27<1:08:30, 28.94s/batch, loss=0.492907]Training:  66%|██████▋   | 279/421 [2:45:29<1:08:30, 28.94s/batch, loss=0.487226]Training:  67%|██████▋   | 280/421 [2:45:29<48:42, 20.72s/batch, loss=0.487226]  Training:  67%|██████▋   | 280/421 [2:47:36<48:42, 20.72s/batch, loss=0.488625]Training:  67%|██████▋   | 281/421 [2:47:36<2:03:14, 52.82s/batch, loss=0.488625]Training:  67%|██████▋   | 281/421 [2:47:38<2:03:14, 52.82s/batch, loss=0.481091]Training:  67%|██████▋   | 282/421 [2:47:38<1:26:46, 37.46s/batch, loss=0.481091]Training:  67%|██████▋   | 282/421 [2:47:40<1:26:46, 37.46s/batch, loss=0.477036]Training:  67%|██████▋   | 283/421 [2:47:40<1:01:21, 26.68s/batch, loss=0.477036]Training:  67%|██████▋   | 283/421 [2:47:41<1:01:21, 26.68s/batch, loss=0.491776]Training:  67%|██████▋   | 284/421 [2:47:41<43:40, 19.13s/batch, loss=0.491776]  Training:  67%|██████▋   | 284/421 [2:49:46<43:40, 19.13s/batch, loss=0.476525]Training:  68%|██████▊   | 285/421 [2:49:46<1:54:56, 50.71s/batch, loss=0.476525]Training:  68%|██████▊   | 285/421 [2:49:47<1:54:56, 50.71s/batch, loss=0.465621]Training:  68%|██████▊   | 286/421 [2:49:47<1:20:54, 35.96s/batch, loss=0.465621]Training:  68%|██████▊   | 286/421 [2:49:49<1:20:54, 35.96s/batch, loss=0.462843]Training:  68%|██████▊   | 287/421 [2:49:49<57:13, 25.62s/batch, loss=0.462843]  Training:  68%|██████▊   | 287/421 [2:49:50<57:13, 25.62s/batch, loss=0.471552]Training:  68%|██████▊   | 288/421 [2:49:50<40:46, 18.40s/batch, loss=0.471552]Training:  68%|██████▊   | 288/421 [2:51:53<40:46, 18.40s/batch, loss=0.475406]Training:  69%|██████▊   | 289/421 [2:51:53<1:49:45, 49.89s/batch, loss=0.475406]Training:  69%|██████▊   | 289/421 [2:51:55<1:49:45, 49.89s/batch, loss=0.491209]Training:  69%|██████▉   | 290/421 [2:51:55<1:17:15, 35.39s/batch, loss=0.491209]Training:  69%|██████▉   | 290/421 [2:51:57<1:17:15, 35.39s/batch, loss=0.485520]Training:  69%|██████▉   | 291/421 [2:51:57<54:39, 25.23s/batch, loss=0.485520]  Training:  69%|██████▉   | 291/421 [2:51:58<54:39, 25.23s/batch, loss=0.495935]Training:  69%|██████▉   | 292/421 [2:51:58<38:58, 18.13s/batch, loss=0.495935]Training:  69%|██████▉   | 292/421 [2:54:06<38:58, 18.13s/batch, loss=0.476744]Training:  70%|██████▉   | 293/421 [2:54:06<1:48:57, 51.07s/batch, loss=0.476744]Training:  70%|██████▉   | 293/421 [2:54:23<1:48:57, 51.07s/batch, loss=0.493708]Training:  70%|██████▉   | 294/421 [2:54:23<1:26:12, 40.73s/batch, loss=0.493708]Training:  70%|██████▉   | 294/421 [2:54:24<1:26:12, 40.73s/batch, loss=0.488518]Training:  70%|███████   | 295/421 [2:54:24<1:00:49, 28.96s/batch, loss=0.488518]Training:  70%|███████   | 295/421 [2:54:26<1:00:49, 28.96s/batch, loss=0.490380]Training:  70%|███████   | 296/421 [2:54:26<43:10, 20.73s/batch, loss=0.490380]  Training:  70%|███████   | 296/421 [2:56:29<43:10, 20.73s/batch, loss=0.481918]Training:  71%|███████   | 297/421 [2:56:29<1:46:35, 51.58s/batch, loss=0.481918]Training:  71%|███████   | 297/421 [2:56:46<1:46:35, 51.58s/batch, loss=0.483175]Training:  71%|███████   | 298/421 [2:56:46<1:24:21, 41.15s/batch, loss=0.483175]Training:  71%|███████   | 298/421 [2:56:48<1:24:21, 41.15s/batch, loss=0.473784]Training:  71%|███████   | 299/421 [2:56:48<59:30, 29.27s/batch, loss=0.473784]  Training:  71%|███████   | 299/421 [2:56:49<59:30, 29.27s/batch, loss=0.479122]Training:  71%|███████▏  | 300/421 [2:56:49<42:15, 20.95s/batch, loss=0.479122]Training:  71%|███████▏  | 300/421 [2:58:24<42:15, 20.95s/batch, loss=0.497630]Training:  71%|███████▏  | 301/421 [2:58:24<1:26:02, 43.02s/batch, loss=0.497630]Training:  71%|███████▏  | 301/421 [2:58:54<1:26:02, 43.02s/batch, loss=0.475319]Training:  72%|███████▏  | 302/421 [2:58:54<1:17:54, 39.28s/batch, loss=0.475319]Training:  72%|███████▏  | 302/421 [2:58:56<1:17:54, 39.28s/batch, loss=0.484792]Training:  72%|███████▏  | 303/421 [2:58:56<54:58, 27.95s/batch, loss=0.484792]  Training:  72%|███████▏  | 303/421 [2:58:57<54:58, 27.95s/batch, loss=0.492670]Training:  72%|███████▏  | 304/421 [2:58:57<39:04, 20.04s/batch, loss=0.492670]Training:  72%|███████▏  | 304/421 [3:00:55<39:04, 20.04s/batch, loss=0.491060]Training:  72%|███████▏  | 305/421 [3:00:55<1:35:17, 49.29s/batch, loss=0.491060]Training:  72%|███████▏  | 305/421 [3:01:03<1:35:17, 49.29s/batch, loss=0.506665]Training:  73%|███████▎  | 306/421 [3:01:03<1:11:00, 37.05s/batch, loss=0.506665]Training:  73%|███████▎  | 306/421 [3:01:05<1:11:00, 37.05s/batch, loss=0.464254]Training:  73%|███████▎  | 307/421 [3:01:05<50:08, 26.39s/batch, loss=0.464254]  Training:  73%|███████▎  | 307/421 [3:01:06<50:08, 26.39s/batch, loss=0.487357]Training:  73%|███████▎  | 308/421 [3:01:06<35:39, 18.94s/batch, loss=0.487357]Training:  73%|███████▎  | 308/421 [3:02:55<35:39, 18.94s/batch, loss=0.472140]Training:  73%|███████▎  | 309/421 [3:02:55<1:25:27, 45.78s/batch, loss=0.472140]Training:  73%|███████▎  | 309/421 [3:03:21<1:25:27, 45.78s/batch, loss=0.478490]Training:  74%|███████▎  | 310/421 [3:03:21<1:13:37, 39.80s/batch, loss=0.478490]Training:  74%|███████▎  | 310/421 [3:03:22<1:13:37, 39.80s/batch, loss=0.478496]Training:  74%|███████▍  | 311/421 [3:03:22<51:55, 28.32s/batch, loss=0.478496]  Training:  74%|███████▍  | 311/421 [3:03:24<51:55, 28.32s/batch, loss=0.485142]Training:  74%|███████▍  | 312/421 [3:03:24<36:50, 20.28s/batch, loss=0.485142]Training:  74%|███████▍  | 312/421 [3:05:25<36:50, 20.28s/batch, loss=0.464802]Training:  74%|███████▍  | 313/421 [3:05:26<1:31:24, 50.78s/batch, loss=0.464802]Training:  74%|███████▍  | 313/421 [3:05:37<1:31:24, 50.78s/batch, loss=0.484878]Training:  75%|███████▍  | 314/421 [3:05:37<1:09:15, 38.83s/batch, loss=0.484878]Training:  75%|███████▍  | 314/421 [3:05:38<1:09:15, 38.83s/batch, loss=0.469724]Training:  75%|███████▍  | 315/421 [3:05:38<48:49, 27.64s/batch, loss=0.469724]  Training:  75%|███████▍  | 315/421 [3:05:40<48:49, 27.64s/batch, loss=0.484224]Training:  75%|███████▌  | 316/421 [3:05:40<34:39, 19.80s/batch, loss=0.484224]Training:  75%|███████▌  | 316/421 [3:07:24<34:39, 19.80s/batch, loss=0.482777]Training:  75%|███████▌  | 317/421 [3:07:24<1:18:14, 45.14s/batch, loss=0.482777]Training:  75%|███████▌  | 317/421 [3:07:56<1:18:14, 45.14s/batch, loss=0.498679]Training:  76%|███████▌  | 318/421 [3:07:56<1:11:01, 41.38s/batch, loss=0.498679]Training:  76%|███████▌  | 318/421 [3:07:58<1:11:01, 41.38s/batch, loss=0.475288]Training:  76%|███████▌  | 319/421 [3:07:58<50:01, 29.42s/batch, loss=0.475288]  Training:  76%|███████▌  | 319/421 [3:08:00<50:01, 29.42s/batch, loss=0.495464]Training:  76%|███████▌  | 320/421 [3:08:00<35:28, 21.08s/batch, loss=0.495464]Training:  76%|███████▌  | 320/421 [3:09:25<35:28, 21.08s/batch, loss=0.467596]Training:  76%|███████▌  | 321/421 [3:09:25<1:07:18, 40.39s/batch, loss=0.467596]Training:  76%|███████▌  | 321/421 [3:10:15<1:07:18, 40.39s/batch, loss=0.479744]Training:  76%|███████▋  | 322/421 [3:10:15<1:11:09, 43.13s/batch, loss=0.479744]Training:  76%|███████▋  | 322/421 [3:10:16<1:11:09, 43.13s/batch, loss=0.490597]Training:  77%|███████▋  | 323/421 [3:10:16<50:03, 30.65s/batch, loss=0.490597]  Training:  77%|███████▋  | 323/421 [3:10:18<50:03, 30.65s/batch, loss=0.492313]Training:  77%|███████▋  | 324/421 [3:10:18<35:26, 21.92s/batch, loss=0.492313]Training:  77%|███████▋  | 324/421 [3:11:24<35:26, 21.92s/batch, loss=0.491167]Training:  77%|███████▋  | 325/421 [3:11:24<56:29, 35.31s/batch, loss=0.491167]Training:  77%|███████▋  | 325/421 [3:12:18<56:29, 35.31s/batch, loss=0.499703]Training:  77%|███████▋  | 326/421 [3:12:18<1:04:26, 40.70s/batch, loss=0.499703]Training:  77%|███████▋  | 326/421 [3:12:19<1:04:26, 40.70s/batch, loss=0.490466]Training:  78%|███████▊  | 327/421 [3:12:19<45:21, 28.95s/batch, loss=0.490466]  Training:  78%|███████▊  | 327/421 [3:12:21<45:21, 28.95s/batch, loss=0.469421]Training:  78%|███████▊  | 328/421 [3:12:21<32:07, 20.73s/batch, loss=0.469421]Training:  78%|███████▊  | 328/421 [3:13:38<32:07, 20.73s/batch, loss=0.471972]Training:  78%|███████▊  | 329/421 [3:13:38<57:38, 37.60s/batch, loss=0.471972]Training:  78%|███████▊  | 329/421 [3:14:46<57:38, 37.60s/batch, loss=0.471447]Training:  78%|███████▊  | 330/421 [3:14:47<1:11:35, 47.20s/batch, loss=0.471447]Training:  78%|███████▊  | 330/421 [3:14:49<1:11:35, 47.20s/batch, loss=0.481868]Training:  79%|███████▊  | 331/421 [3:14:49<50:17, 33.53s/batch, loss=0.481868]  Training:  79%|███████▊  | 331/421 [3:14:50<50:17, 33.53s/batch, loss=0.496936]Training:  79%|███████▉  | 332/421 [3:14:50<35:29, 23.93s/batch, loss=0.496936]Training:  79%|███████▉  | 332/421 [3:15:24<35:29, 23.93s/batch, loss=0.484692]Training:  79%|███████▉  | 333/421 [3:15:24<39:11, 26.72s/batch, loss=0.484692]Training:  79%|███████▉  | 333/421 [3:16:55<39:11, 26.72s/batch, loss=0.492242]Training:  79%|███████▉  | 334/421 [3:16:55<1:06:55, 46.15s/batch, loss=0.492242]Training:  79%|███████▉  | 334/421 [3:16:57<1:06:55, 46.15s/batch, loss=0.475908]Training:  80%|███████▉  | 335/421 [3:16:57<46:58, 32.77s/batch, loss=0.475908]  Training:  80%|███████▉  | 335/421 [3:16:58<46:58, 32.77s/batch, loss=0.490373]Training:  80%|███████▉  | 336/421 [3:16:58<33:10, 23.42s/batch, loss=0.490373]Training:  80%|███████▉  | 336/421 [3:17:16<33:10, 23.42s/batch, loss=0.503348]Training:  80%|████████  | 337/421 [3:17:16<30:13, 21.58s/batch, loss=0.503348]Training:  80%|████████  | 337/421 [3:19:00<30:13, 21.58s/batch, loss=0.473741]Training:  80%|████████  | 338/421 [3:19:00<1:04:20, 46.51s/batch, loss=0.473741]Training:  80%|████████  | 338/421 [3:19:02<1:04:20, 46.51s/batch, loss=0.479031]Training:  81%|████████  | 339/421 [3:19:02<45:07, 33.01s/batch, loss=0.479031]  Training:  81%|████████  | 339/421 [3:19:03<45:07, 33.01s/batch, loss=0.472636]Training:  81%|████████  | 340/421 [3:19:03<31:49, 23.57s/batch, loss=0.472636]Training:  81%|████████  | 340/421 [3:19:05<31:49, 23.57s/batch, loss=0.473818]Training:  81%|████████  | 341/421 [3:19:05<22:37, 16.97s/batch, loss=0.473818]Training:  81%|████████  | 341/421 [3:21:16<22:37, 16.97s/batch, loss=0.487485]Training:  81%|████████  | 342/421 [3:21:16<1:07:29, 51.27s/batch, loss=0.487485]Training:  81%|████████  | 342/421 [3:21:18<1:07:29, 51.27s/batch, loss=0.488719]Training:  81%|████████▏ | 343/421 [3:21:18<47:15, 36.35s/batch, loss=0.488719]  Training:  81%|████████▏ | 343/421 [3:21:19<47:15, 36.35s/batch, loss=0.465793]Training:  82%|████████▏ | 344/421 [3:21:19<33:14, 25.91s/batch, loss=0.465793]Training:  82%|████████▏ | 344/421 [3:21:21<33:14, 25.91s/batch, loss=0.478363]Training:  82%|████████▏ | 345/421 [3:21:21<23:33, 18.60s/batch, loss=0.478363]Training:  82%|████████▏ | 345/421 [3:23:27<23:33, 18.60s/batch, loss=0.478414]Training:  82%|████████▏ | 346/421 [3:23:27<1:03:31, 50.82s/batch, loss=0.478414]Training:  82%|████████▏ | 346/421 [3:23:28<1:03:31, 50.82s/batch, loss=0.493456]Training:  82%|████████▏ | 347/421 [3:23:28<44:28, 36.05s/batch, loss=0.493456]  Training:  82%|████████▏ | 347/421 [3:23:30<44:28, 36.05s/batch, loss=0.464584]Training:  83%|████████▎ | 348/421 [3:23:30<31:15, 25.69s/batch, loss=0.464584]Training:  83%|████████▎ | 348/421 [3:23:31<31:15, 25.69s/batch, loss=0.476118]Training:  83%|████████▎ | 349/421 [3:23:31<22:08, 18.45s/batch, loss=0.476118]Training:  83%|████████▎ | 349/421 [3:25:38<22:08, 18.45s/batch, loss=0.469105]Training:  83%|████████▎ | 350/421 [3:25:38<1:00:04, 50.77s/batch, loss=0.469105]Training:  83%|████████▎ | 350/421 [3:25:39<1:00:04, 50.77s/batch, loss=0.481112]Training:  83%|████████▎ | 351/421 [3:25:39<42:01, 36.02s/batch, loss=0.481112]  Training:  83%|████████▎ | 351/421 [3:25:41<42:01, 36.02s/batch, loss=0.482104]Training:  84%|████████▎ | 352/421 [3:25:41<29:31, 25.67s/batch, loss=0.482104]Training:  84%|████████▎ | 352/421 [3:25:42<29:31, 25.67s/batch, loss=0.483449]Training:  84%|████████▍ | 353/421 [3:25:42<20:53, 18.43s/batch, loss=0.483449]Training:  84%|████████▍ | 353/421 [3:27:53<20:53, 18.43s/batch, loss=0.478217]Training:  84%|████████▍ | 354/421 [3:27:53<58:20, 52.24s/batch, loss=0.478217]Training:  84%|████████▍ | 354/421 [3:27:55<58:20, 52.24s/batch, loss=0.469488]Training:  84%|████████▍ | 355/421 [3:27:55<40:44, 37.04s/batch, loss=0.469488]Training:  84%|████████▍ | 355/421 [3:27:56<40:44, 37.04s/batch, loss=0.477639]Training:  85%|████████▍ | 356/421 [3:27:56<28:35, 26.39s/batch, loss=0.477639]Training:  85%|████████▍ | 356/421 [3:27:58<28:35, 26.39s/batch, loss=0.489682]Training:  85%|████████▍ | 357/421 [3:27:58<20:12, 18.95s/batch, loss=0.489682]Training:  85%|████████▍ | 357/421 [3:30:25<20:12, 18.95s/batch, loss=0.472030]Training:  85%|████████▌ | 358/421 [3:30:25<1:00:03, 57.20s/batch, loss=0.472030]Training:  85%|████████▌ | 358/421 [3:30:26<1:00:03, 57.20s/batch, loss=0.469824]Training:  85%|████████▌ | 359/421 [3:30:26<41:52, 40.52s/batch, loss=0.469824]  Training:  85%|████████▌ | 359/421 [3:30:28<41:52, 40.52s/batch, loss=0.469800]Training:  86%|████████▌ | 360/421 [3:30:28<29:18, 28.83s/batch, loss=0.469800]Training:  86%|████████▌ | 360/421 [3:30:29<29:18, 28.83s/batch, loss=0.479570]Training:  86%|████████▌ | 361/421 [3:30:29<20:38, 20.63s/batch, loss=0.479570]Training:  86%|████████▌ | 361/421 [3:32:39<20:38, 20.63s/batch, loss=0.477893]Training:  86%|████████▌ | 362/421 [3:32:39<52:23, 53.27s/batch, loss=0.477893]Training:  86%|████████▌ | 362/421 [3:32:40<52:23, 53.27s/batch, loss=0.476726]Training:  86%|████████▌ | 363/421 [3:32:40<36:30, 37.76s/batch, loss=0.476726]Training:  86%|████████▌ | 363/421 [3:32:42<36:30, 37.76s/batch, loss=0.473266]Training:  86%|████████▋ | 364/421 [3:32:42<25:32, 26.89s/batch, loss=0.473266]Training:  86%|████████▋ | 364/421 [3:32:43<25:32, 26.89s/batch, loss=0.475587]Training:  87%|████████▋ | 365/421 [3:32:43<17:59, 19.28s/batch, loss=0.475587]Training:  87%|████████▋ | 365/421 [3:34:32<17:59, 19.28s/batch, loss=0.491459]Training:  87%|████████▋ | 366/421 [3:34:32<42:20, 46.19s/batch, loss=0.491459]Training:  87%|████████▋ | 366/421 [3:34:34<42:20, 46.19s/batch, loss=0.470508]Training:  87%|████████▋ | 367/421 [3:34:34<29:31, 32.81s/batch, loss=0.470508]Training:  87%|████████▋ | 367/421 [3:34:35<29:31, 32.81s/batch, loss=0.478060]Training:  87%|████████▋ | 368/421 [3:34:35<20:42, 23.44s/batch, loss=0.478060]Training:  87%|████████▋ | 368/421 [3:34:37<20:42, 23.44s/batch, loss=0.473124]Training:  88%|████████▊ | 369/421 [3:34:37<14:37, 16.87s/batch, loss=0.473124]Training:  88%|████████▊ | 369/421 [3:36:36<14:37, 16.87s/batch, loss=0.473335]Training:  88%|████████▊ | 370/421 [3:36:36<40:23, 47.51s/batch, loss=0.473335]Training:  88%|████████▊ | 370/421 [3:36:38<40:23, 47.51s/batch, loss=0.482858]Training:  88%|████████▊ | 371/421 [3:36:38<28:06, 33.74s/batch, loss=0.482858]Training:  88%|████████▊ | 371/421 [3:36:39<28:06, 33.74s/batch, loss=0.481204]Training:  88%|████████▊ | 372/421 [3:36:39<19:40, 24.09s/batch, loss=0.481204]Training:  88%|████████▊ | 372/421 [3:36:41<19:40, 24.09s/batch, loss=0.492736]Training:  89%|████████▊ | 373/421 [3:36:41<13:51, 17.33s/batch, loss=0.492736]Training:  89%|████████▊ | 373/421 [3:38:52<13:51, 17.33s/batch, loss=0.473226]Training:  89%|████████▉ | 374/421 [3:38:52<40:18, 51.46s/batch, loss=0.473226]Training:  89%|████████▉ | 374/421 [3:38:53<40:18, 51.46s/batch, loss=0.473946]Training:  89%|████████▉ | 375/421 [3:38:53<27:58, 36.48s/batch, loss=0.473946]Training:  89%|████████▉ | 375/421 [3:38:55<27:58, 36.48s/batch, loss=0.478965]Training:  89%|████████▉ | 376/421 [3:38:55<19:30, 26.01s/batch, loss=0.478965]Training:  89%|████████▉ | 376/421 [3:38:56<19:30, 26.01s/batch, loss=0.478608]Training:  90%|████████▉ | 377/421 [3:38:56<13:40, 18.66s/batch, loss=0.478608]Training:  90%|████████▉ | 377/421 [3:40:53<13:40, 18.66s/batch, loss=0.469362]Training:  90%|████████▉ | 378/421 [3:40:53<34:28, 48.10s/batch, loss=0.469362]Training:  90%|████████▉ | 378/421 [3:40:55<34:28, 48.10s/batch, loss=0.468229]Training:  90%|█████████ | 379/421 [3:40:55<23:54, 34.16s/batch, loss=0.468229]Training:  90%|█████████ | 379/421 [3:40:56<23:54, 34.16s/batch, loss=0.461826]Training:  90%|█████████ | 380/421 [3:40:56<16:39, 24.37s/batch, loss=0.461826]Training:  90%|█████████ | 380/421 [3:40:58<16:39, 24.37s/batch, loss=0.473514]Training:  90%|█████████ | 381/421 [3:40:58<11:40, 17.52s/batch, loss=0.473514]Training:  90%|█████████ | 381/421 [3:42:51<11:40, 17.52s/batch, loss=0.484949]Training:  91%|█████████ | 382/421 [3:42:51<29:56, 46.06s/batch, loss=0.484949]Training:  91%|█████████ | 382/421 [3:42:52<29:56, 46.06s/batch, loss=0.481062]Training:  91%|█████████ | 383/421 [3:42:52<20:42, 32.71s/batch, loss=0.481062]Training:  91%|█████████ | 383/421 [3:42:54<20:42, 32.71s/batch, loss=0.480947]Training:  91%|█████████ | 384/421 [3:42:54<14:24, 23.37s/batch, loss=0.480947]Training:  91%|█████████ | 384/421 [3:42:55<14:24, 23.37s/batch, loss=0.475665]Training:  91%|█████████▏| 385/421 [3:42:55<10:06, 16.85s/batch, loss=0.475665]Training:  91%|█████████▏| 385/421 [3:44:41<10:06, 16.85s/batch, loss=0.467110]Training:  92%|█████████▏| 386/421 [3:44:41<25:24, 43.56s/batch, loss=0.467110]Training:  92%|█████████▏| 386/421 [3:44:43<25:24, 43.56s/batch, loss=0.470490]Training:  92%|█████████▏| 387/421 [3:44:43<17:33, 30.97s/batch, loss=0.470490]Training:  92%|█████████▏| 387/421 [3:44:44<17:33, 30.97s/batch, loss=0.474708]Training:  92%|█████████▏| 388/421 [3:44:44<12:10, 22.14s/batch, loss=0.474708]Training:  92%|█████████▏| 388/421 [3:44:46<12:10, 22.14s/batch, loss=0.496009]Training:  92%|█████████▏| 389/421 [3:44:46<08:30, 15.96s/batch, loss=0.496009]Training:  92%|█████████▏| 389/421 [3:46:25<08:30, 15.96s/batch, loss=0.479301]Training:  93%|█████████▎| 390/421 [3:46:25<21:10, 41.00s/batch, loss=0.479301]Training:  93%|█████████▎| 390/421 [3:46:27<21:10, 41.00s/batch, loss=0.464599]Training:  93%|█████████▎| 391/421 [3:46:27<14:35, 29.17s/batch, loss=0.464599]Training:  93%|█████████▎| 391/421 [3:46:28<14:35, 29.17s/batch, loss=0.475539]Training:  93%|█████████▎| 392/421 [3:46:28<10:05, 20.88s/batch, loss=0.475539]Training:  93%|█████████▎| 392/421 [3:46:30<10:05, 20.88s/batch, loss=0.485335]Training:  93%|█████████▎| 393/421 [3:46:30<07:02, 15.08s/batch, loss=0.485335]Training:  93%|█████████▎| 393/421 [3:48:20<07:02, 15.08s/batch, loss=0.480103]Training:  94%|█████████▎| 394/421 [3:48:20<19:34, 43.49s/batch, loss=0.480103]Training:  94%|█████████▎| 394/421 [3:48:21<19:34, 43.49s/batch, loss=0.468623]Training:  94%|█████████▍| 395/421 [3:48:21<13:23, 30.90s/batch, loss=0.468623]Training:  94%|█████████▍| 395/421 [3:48:23<13:23, 30.90s/batch, loss=0.468522]Training:  94%|█████████▍| 396/421 [3:48:23<09:13, 22.14s/batch, loss=0.468522]Training:  94%|█████████▍| 396/421 [3:48:24<09:13, 22.14s/batch, loss=0.463870]Training:  94%|█████████▍| 397/421 [3:48:24<06:22, 15.95s/batch, loss=0.463870]Training:  94%|█████████▍| 397/421 [3:50:42<06:22, 15.95s/batch, loss=0.465119]Training:  95%|█████████▍| 398/421 [3:50:42<20:04, 52.38s/batch, loss=0.465119]Training:  95%|█████████▍| 398/421 [3:50:43<20:04, 52.38s/batch, loss=0.458526]Training:  95%|█████████▍| 399/421 [3:50:43<13:36, 37.13s/batch, loss=0.458526]Training:  95%|█████████▍| 399/421 [3:50:45<13:36, 37.13s/batch, loss=0.476287]Training:  95%|█████████▌| 400/421 [3:50:45<09:15, 26.46s/batch, loss=0.476287]Training:  95%|█████████▌| 400/421 [3:50:46<09:15, 26.46s/batch, loss=0.482825]Training:  95%|█████████▌| 401/421 [3:50:46<06:19, 18.98s/batch, loss=0.482825]Training:  95%|█████████▌| 401/421 [3:52:53<06:19, 18.98s/batch, loss=0.494152]Training:  95%|█████████▌| 402/421 [3:52:53<16:14, 51.29s/batch, loss=0.494152]Training:  95%|█████████▌| 402/421 [3:52:55<16:14, 51.29s/batch, loss=0.500038]Training:  96%|█████████▌| 403/421 [3:52:55<10:54, 36.38s/batch, loss=0.500038]Training:  96%|█████████▌| 403/421 [3:52:56<10:54, 36.38s/batch, loss=0.499639]Training:  96%|█████████▌| 404/421 [3:52:56<07:20, 25.92s/batch, loss=0.499639]Training:  96%|█████████▌| 404/421 [3:52:58<07:20, 25.92s/batch, loss=0.491140]Training:  96%|█████████▌| 405/421 [3:52:58<04:57, 18.61s/batch, loss=0.491140]Training:  96%|█████████▌| 405/421 [3:55:06<04:57, 18.61s/batch, loss=0.474754]Training:  96%|█████████▋| 406/421 [3:55:06<12:51, 51.42s/batch, loss=0.474754]Training:  96%|█████████▋| 406/421 [3:55:07<12:51, 51.42s/batch, loss=0.472434]Training:  97%|█████████▋| 407/421 [3:55:07<08:30, 36.47s/batch, loss=0.472434]Training:  97%|█████████▋| 407/421 [3:55:09<08:30, 36.47s/batch, loss=0.472618]Training:  97%|█████████▋| 408/421 [3:55:09<05:37, 25.99s/batch, loss=0.472618]Training:  97%|█████████▋| 408/421 [3:55:10<05:37, 25.99s/batch, loss=0.473790]Training:  97%|█████████▋| 409/421 [3:55:10<03:43, 18.66s/batch, loss=0.473790]Training:  97%|█████████▋| 409/421 [3:57:04<03:43, 18.66s/batch, loss=0.467180]Training:  97%|█████████▋| 410/421 [3:57:04<08:39, 47.24s/batch, loss=0.467180]Training:  97%|█████████▋| 410/421 [3:57:06<08:39, 47.24s/batch, loss=0.483291]Training:  98%|█████████▊| 411/421 [3:57:06<05:35, 33.57s/batch, loss=0.483291]Training:  98%|█████████▊| 411/421 [3:57:08<05:35, 33.57s/batch, loss=0.477265]Training:  98%|█████████▊| 412/421 [3:57:08<03:35, 23.96s/batch, loss=0.477265]Training:  98%|█████████▊| 412/421 [3:57:09<03:35, 23.96s/batch, loss=0.461007]Training:  98%|█████████▊| 413/421 [3:57:09<02:17, 17.23s/batch, loss=0.461007]Training:  98%|█████████▊| 413/421 [3:58:56<02:17, 17.23s/batch, loss=0.461598]Training:  98%|█████████▊| 414/421 [3:58:56<05:09, 44.18s/batch, loss=0.461598]Training:  98%|█████████▊| 414/421 [3:58:58<05:09, 44.18s/batch, loss=0.469183]Training:  99%|█████████▊| 415/421 [3:58:58<03:08, 31.40s/batch, loss=0.469183]Training:  99%|█████████▊| 415/421 [3:58:59<03:08, 31.40s/batch, loss=0.468047]Training:  99%|█████████▉| 416/421 [3:58:59<01:52, 22.45s/batch, loss=0.468047]Training:  99%|█████████▉| 416/421 [3:59:01<01:52, 22.45s/batch, loss=0.466975]Training:  99%|█████████▉| 417/421 [3:59:01<01:04, 16.18s/batch, loss=0.466975]Training:  99%|█████████▉| 417/421 [4:00:24<01:04, 16.18s/batch, loss=0.467599]Training:  99%|█████████▉| 418/421 [4:00:24<01:48, 36.24s/batch, loss=0.467599]Training:  99%|█████████▉| 418/421 [4:00:25<01:48, 36.24s/batch, loss=0.480177]Training: 100%|█████████▉| 419/421 [4:00:25<00:51, 25.82s/batch, loss=0.480177]Training: 100%|█████████▉| 419/421 [4:00:27<00:51, 25.82s/batch, loss=0.470042]Training: 100%|█████████▉| 420/421 [4:00:27<00:18, 18.56s/batch, loss=0.470042]Training: 100%|█████████▉| 420/421 [4:00:28<00:18, 18.56s/batch, loss=0.472950]Training: 100%|██████████| 421/421 [4:00:28<00:00, 13.21s/batch, loss=0.472950]Training: 100%|██████████| 421/421 [4:00:28<00:00, 34.27s/batch, loss=0.472950]
Epoch 1, Train Loss: 0.5191, Val Loss: 0.4763
Training:   0%|          | 0/421 [00:00<?, ?batch/s]Training:   0%|          | 0/421 [01:53<?, ?batch/s, loss=0.501088]Training:   0%|          | 1/421 [01:53<13:13:36, 113.37s/batch, loss=0.501088]Training:   0%|          | 1/421 [01:54<13:13:36, 113.37s/batch, loss=0.489676]Training:   0%|          | 2/421 [01:54<5:32:14, 47.58s/batch, loss=0.489676]  Training:   0%|          | 2/421 [01:57<5:32:14, 47.58s/batch, loss=0.485791]Training:   1%|          | 3/421 [01:57<3:08:28, 27.05s/batch, loss=0.485791]Training:   1%|          | 3/421 [02:19<3:08:28, 27.05s/batch, loss=0.469864]Training:   1%|          | 4/421 [02:19<2:53:59, 25.04s/batch, loss=0.469864]Training:   1%|          | 4/421 [04:01<2:53:59, 25.04s/batch, loss=0.473268]Training:   1%|          | 5/421 [04:01<6:06:50, 52.91s/batch, loss=0.473268]Training:   1%|          | 5/421 [04:03<6:06:50, 52.91s/batch, loss=0.460331]Training:   1%|▏         | 6/421 [04:03<4:05:14, 35.46s/batch, loss=0.460331]Training:   1%|▏         | 6/421 [04:04<4:05:14, 35.46s/batch, loss=0.486120]Training:   2%|▏         | 7/421 [04:04<2:48:09, 24.37s/batch, loss=0.486120]Training:   2%|▏         | 7/421 [04:17<2:48:09, 24.37s/batch, loss=0.492239]Training:   2%|▏         | 8/421 [04:17<2:21:48, 20.60s/batch, loss=0.492239]Training:   2%|▏         | 8/421 [06:17<2:21:48, 20.60s/batch, loss=0.481562]Training:   2%|▏         | 9/421 [06:17<5:54:04, 51.56s/batch, loss=0.481562]Training:   2%|▏         | 9/421 [06:18<5:54:04, 51.56s/batch, loss=0.482589]Training:   2%|▏         | 10/421 [06:18<4:07:30, 36.13s/batch, loss=0.482589]Training:   2%|▏         | 10/421 [06:20<4:07:30, 36.13s/batch, loss=0.471349]Training:   3%|▎         | 11/421 [06:20<2:54:36, 25.55s/batch, loss=0.471349]Training:   3%|▎         | 11/421 [06:30<2:54:36, 25.55s/batch, loss=0.476612]Training:   3%|▎         | 12/421 [06:30<2:22:28, 20.90s/batch, loss=0.476612]Training:   3%|▎         | 12/421 [07:54<2:22:28, 20.90s/batch, loss=0.481163]Training:   3%|▎         | 13/421 [07:54<4:31:51, 39.98s/batch, loss=0.481163]Training:   3%|▎         | 13/421 [07:55<4:31:51, 39.98s/batch, loss=0.492905]Training:   3%|▎         | 14/421 [07:55<3:12:25, 28.37s/batch, loss=0.492905]Training:   3%|▎         | 14/421 [08:24<3:12:25, 28.37s/batch, loss=0.481392]Training:   4%|▎         | 15/421 [08:24<3:13:02, 28.53s/batch, loss=0.481392]Training:   4%|▎         | 15/421 [08:29<3:13:02, 28.53s/batch, loss=0.476571]Training:   4%|▍         | 16/421 [08:29<2:23:30, 21.26s/batch, loss=0.476571]Training:   4%|▍         | 16/421 [10:11<2:23:30, 21.26s/batch, loss=0.451134]Training:   4%|▍         | 17/421 [10:11<5:07:10, 45.62s/batch, loss=0.451134]Training:   4%|▍         | 17/421 [10:13<5:07:10, 45.62s/batch, loss=0.465464]Training:   4%|▍         | 18/421 [10:13<3:37:38, 32.40s/batch, loss=0.465464]Training:   4%|▍         | 18/421 [10:38<3:37:38, 32.40s/batch, loss=0.480254]Training:   5%|▍         | 19/421 [10:38<3:22:26, 30.22s/batch, loss=0.480254]Training:   5%|▍         | 19/421 [10:39<3:22:26, 30.22s/batch, loss=0.474990]Training:   5%|▍         | 20/421 [10:39<2:24:30, 21.62s/batch, loss=0.474990]Training:   5%|▍         | 20/421 [12:17<2:24:30, 21.62s/batch, loss=0.463966]Training:   5%|▍         | 21/421 [12:17<4:56:26, 44.47s/batch, loss=0.463966]Training:   5%|▍         | 21/421 [12:19<4:56:26, 44.47s/batch, loss=0.469337]Training:   5%|▌         | 22/421 [12:19<3:30:03, 31.59s/batch, loss=0.469337]Training:   5%|▌         | 22/421 [12:46<3:30:03, 31.59s/batch, loss=0.478167]Training:   5%|▌         | 23/421 [12:46<3:21:50, 30.43s/batch, loss=0.478167]Training:   5%|▌         | 23/421 [12:48<3:21:50, 30.43s/batch, loss=0.456455]Training:   6%|▌         | 24/421 [12:48<2:24:00, 21.76s/batch, loss=0.456455]Training:   6%|▌         | 24/421 [14:28<2:24:00, 21.76s/batch, loss=0.456050]Training:   6%|▌         | 25/421 [14:28<4:58:36, 45.24s/batch, loss=0.456050]Training:   6%|▌         | 25/421 [14:30<4:58:36, 45.24s/batch, loss=0.481780]Training:   6%|▌         | 26/421 [14:30<3:31:48, 32.17s/batch, loss=0.481780]Training:   6%|▌         | 26/421 [15:04<3:31:48, 32.17s/batch, loss=0.477319]Training:   6%|▋         | 27/421 [15:04<3:35:07, 32.76s/batch, loss=0.477319]Training:   6%|▋         | 27/421 [15:05<3:35:07, 32.76s/batch, loss=0.471633]Training:   7%|▋         | 28/421 [15:05<2:33:15, 23.40s/batch, loss=0.471633]Training:   7%|▋         | 28/421 [16:35<2:33:15, 23.40s/batch, loss=0.475191]Training:   7%|▋         | 29/421 [16:35<4:43:42, 43.43s/batch, loss=0.475191]Training:   7%|▋         | 29/421 [16:37<4:43:42, 43.43s/batch, loss=0.474324]Training:   7%|▋         | 30/421 [16:37<3:21:06, 30.86s/batch, loss=0.474324]Training:   7%|▋         | 30/421 [16:47<3:21:06, 30.86s/batch, loss=0.476644]Training:   7%|▋         | 31/421 [16:47<2:40:40, 24.72s/batch, loss=0.476644]Training:   7%|▋         | 31/421 [16:49<2:40:40, 24.72s/batch, loss=0.488291]Training:   8%|▊         | 32/421 [16:49<1:55:10, 17.76s/batch, loss=0.488291]Training:   8%|▊         | 32/421 [18:24<1:55:10, 17.76s/batch, loss=0.474088]Training:   8%|▊         | 33/421 [18:24<4:25:05, 40.99s/batch, loss=0.474088]Training:   8%|▊         | 33/421 [18:26<4:25:05, 40.99s/batch, loss=0.485414]Training:   8%|▊         | 34/421 [18:26<3:08:05, 29.16s/batch, loss=0.485414]Training:   8%|▊         | 34/421 [18:59<3:08:05, 29.16s/batch, loss=0.464088]Training:   8%|▊         | 35/421 [18:59<3:14:55, 30.30s/batch, loss=0.464088]Training:   8%|▊         | 35/421 [19:08<3:14:55, 30.30s/batch, loss=0.466571]Training:   9%|▊         | 36/421 [19:08<2:34:29, 24.08s/batch, loss=0.466571]Training:   9%|▊         | 36/421 [20:25<2:34:29, 24.08s/batch, loss=0.477026]Training:   9%|▉         | 37/421 [20:25<4:15:53, 39.98s/batch, loss=0.477026]Training:   9%|▉         | 37/421 [20:27<4:15:53, 39.98s/batch, loss=0.461194]Training:   9%|▉         | 38/421 [20:27<3:01:37, 28.45s/batch, loss=0.461194]Training:   9%|▉         | 38/421 [20:57<3:01:37, 28.45s/batch, loss=0.467611]Training:   9%|▉         | 39/421 [20:57<3:05:21, 29.11s/batch, loss=0.467611]Training:   9%|▉         | 39/421 [21:20<3:05:21, 29.11s/batch, loss=0.468837]Training:  10%|▉         | 40/421 [21:20<2:51:50, 27.06s/batch, loss=0.468837]Training:  10%|▉         | 40/421 [22:30<2:51:50, 27.06s/batch, loss=0.474836]Training:  10%|▉         | 41/421 [22:30<4:13:24, 40.01s/batch, loss=0.474836]Training:  10%|▉         | 41/421 [22:31<4:13:24, 40.01s/batch, loss=0.445615]Training:  10%|▉         | 42/421 [22:31<2:59:47, 28.46s/batch, loss=0.445615]Training:  10%|▉         | 42/421 [23:04<2:59:47, 28.46s/batch, loss=0.469152]Training:  10%|█         | 43/421 [23:04<3:06:57, 29.68s/batch, loss=0.469152]Training:  10%|█         | 43/421 [23:22<3:06:57, 29.68s/batch, loss=0.477720]Training:  10%|█         | 44/421 [23:22<2:43:44, 26.06s/batch, loss=0.477720]Training:  10%|█         | 44/421 [24:20<2:43:44, 26.06s/batch, loss=0.466202]Training:  11%|█         | 45/421 [24:20<3:43:37, 35.69s/batch, loss=0.466202]Training:  11%|█         | 45/421 [24:24<3:43:37, 35.69s/batch, loss=0.478044]Training:  11%|█         | 46/421 [24:24<2:43:31, 26.16s/batch, loss=0.478044]Training:  11%|█         | 46/421 [24:36<2:43:31, 26.16s/batch, loss=0.483151]Training:  11%|█         | 47/421 [24:36<2:17:03, 21.99s/batch, loss=0.483151]Training:  11%|█         | 47/421 [25:23<2:17:03, 21.99s/batch, loss=0.482148]Training:  11%|█▏        | 48/421 [25:23<3:03:29, 29.51s/batch, loss=0.482148]Training:  11%|█▏        | 48/421 [26:20<3:03:29, 29.51s/batch, loss=0.464421]Training:  12%|█▏        | 49/421 [26:20<3:54:25, 37.81s/batch, loss=0.464421]Training:  12%|█▏        | 49/421 [26:43<3:54:25, 37.81s/batch, loss=0.459781]Training:  12%|█▏        | 50/421 [26:43<3:26:52, 33.46s/batch, loss=0.459781]Training:  12%|█▏        | 50/421 [26:49<3:26:52, 33.46s/batch, loss=0.463506]Training:  12%|█▏        | 51/421 [26:49<2:35:06, 25.15s/batch, loss=0.463506]Training:  12%|█▏        | 51/421 [27:14<2:35:06, 25.15s/batch, loss=0.466394]Training:  12%|█▏        | 52/421 [27:14<2:33:24, 24.94s/batch, loss=0.466394]Training:  12%|█▏        | 52/421 [28:25<2:33:24, 24.94s/batch, loss=0.483845]Training:  13%|█▎        | 53/421 [28:25<3:58:44, 38.93s/batch, loss=0.483845]Training:  13%|█▎        | 53/421 [28:48<3:58:44, 38.93s/batch, loss=0.456708]Training:  13%|█▎        | 54/421 [28:48<3:28:15, 34.05s/batch, loss=0.456708]Training:  13%|█▎        | 54/421 [28:53<3:28:15, 34.05s/batch, loss=0.478092]Training:  13%|█▎        | 55/421 [28:53<2:34:05, 25.26s/batch, loss=0.478092]Training:  13%|█▎        | 55/421 [29:33<2:34:05, 25.26s/batch, loss=0.447239]Training:  13%|█▎        | 56/421 [29:33<3:01:29, 29.83s/batch, loss=0.447239]Training:  13%|█▎        | 56/421 [30:32<3:01:29, 29.83s/batch, loss=0.467182]Training:  14%|█▎        | 57/421 [30:32<3:53:30, 38.49s/batch, loss=0.467182]Training:  14%|█▎        | 57/421 [30:55<3:53:30, 38.49s/batch, loss=0.481331]Training:  14%|█▍        | 58/421 [30:55<3:24:12, 33.75s/batch, loss=0.481331]Training:  14%|█▍        | 58/421 [31:03<3:24:12, 33.75s/batch, loss=0.456094]Training:  14%|█▍        | 59/421 [31:03<2:38:39, 26.30s/batch, loss=0.456094]Training:  14%|█▍        | 59/421 [31:33<2:38:39, 26.30s/batch, loss=0.471340]Training:  14%|█▍        | 60/421 [31:33<2:44:21, 27.32s/batch, loss=0.471340]Training:  14%|█▍        | 60/421 [32:46<2:44:21, 27.32s/batch, loss=0.483761]Training:  14%|█▍        | 61/421 [32:46<4:06:30, 41.08s/batch, loss=0.483761]Training:  14%|█▍        | 61/421 [33:09<4:06:30, 41.08s/batch, loss=0.462232]Training:  15%|█▍        | 62/421 [33:09<3:33:30, 35.68s/batch, loss=0.462232]Training:  15%|█▍        | 62/421 [33:16<3:33:30, 35.68s/batch, loss=0.463780]Training:  15%|█▍        | 63/421 [33:16<2:41:02, 26.99s/batch, loss=0.463780]Training:  15%|█▍        | 63/421 [33:56<2:41:02, 26.99s/batch, loss=0.481757]Training:  15%|█▌        | 64/421 [33:57<3:04:25, 31.00s/batch, loss=0.481757]Training:  15%|█▌        | 64/421 [35:02<3:04:25, 31.00s/batch, loss=0.467973]Training:  15%|█▌        | 65/421 [35:02<4:05:49, 41.43s/batch, loss=0.467973]Training:  15%|█▌        | 65/421 [35:27<4:05:49, 41.43s/batch, loss=0.467874]Training:  16%|█▌        | 66/421 [35:27<3:35:33, 36.43s/batch, loss=0.467874]Training:  16%|█▌        | 66/421 [35:29<3:35:33, 36.43s/batch, loss=0.471674]Training:  16%|█▌        | 67/421 [35:29<2:33:08, 25.96s/batch, loss=0.471674]Training:  16%|█▌        | 67/421 [36:11<2:33:08, 25.96s/batch, loss=0.465184]Training:  16%|█▌        | 68/421 [36:11<3:02:26, 31.01s/batch, loss=0.465184]Training:  16%|█▌        | 68/421 [37:14<3:02:26, 31.01s/batch, loss=0.464800]Training:  16%|█▋        | 69/421 [37:14<3:57:11, 40.43s/batch, loss=0.464800]Training:  16%|█▋        | 69/421 [37:37<3:57:11, 40.43s/batch, loss=0.456391]Training:  17%|█▋        | 70/421 [37:37<3:26:07, 35.23s/batch, loss=0.456391]Training:  17%|█▋        | 70/421 [37:38<3:26:07, 35.23s/batch, loss=0.473627]Training:  17%|█▋        | 71/421 [37:38<2:26:35, 25.13s/batch, loss=0.473627]Training:  17%|█▋        | 71/421 [38:22<2:26:35, 25.13s/batch, loss=0.467759]Training:  17%|█▋        | 72/421 [38:22<2:58:05, 30.62s/batch, loss=0.467759]Training:  17%|█▋        | 72/421 [39:38<2:58:05, 30.62s/batch, loss=0.463073]Training:  17%|█▋        | 73/421 [39:38<4:17:19, 44.37s/batch, loss=0.463073]Training:  17%|█▋        | 73/421 [39:49<4:17:19, 44.37s/batch, loss=0.483188]Training:  18%|█▊        | 74/421 [39:49<3:17:48, 34.20s/batch, loss=0.483188]Training:  18%|█▊        | 74/421 [39:50<3:17:48, 34.20s/batch, loss=0.464189]Training:  18%|█▊        | 75/421 [39:50<2:20:42, 24.40s/batch, loss=0.464189]Training:  18%|█▊        | 75/421 [40:07<2:20:42, 24.40s/batch, loss=0.464746]Training:  18%|█▊        | 76/421 [40:07<2:07:05, 22.10s/batch, loss=0.464746]Training:  18%|█▊        | 76/421 [41:52<2:07:05, 22.10s/batch, loss=0.479269]Training:  18%|█▊        | 77/421 [41:52<4:29:24, 46.99s/batch, loss=0.479269]Training:  18%|█▊        | 77/421 [42:05<4:29:24, 46.99s/batch, loss=0.499328]Training:  19%|█▊        | 78/421 [42:05<3:29:41, 36.68s/batch, loss=0.499328]Training:  19%|█▊        | 78/421 [42:06<3:29:41, 36.68s/batch, loss=0.464334]Training:  19%|█▉        | 79/421 [42:06<2:28:56, 26.13s/batch, loss=0.464334]Training:  19%|█▉        | 79/421 [42:08<2:28:56, 26.13s/batch, loss=0.467747]Training:  19%|█▉        | 80/421 [42:08<1:46:33, 18.75s/batch, loss=0.467747]Training:  19%|█▉        | 80/421 [43:53<1:46:33, 18.75s/batch, loss=0.466945]Training:  19%|█▉        | 81/421 [43:53<4:12:51, 44.62s/batch, loss=0.466945]Training:  19%|█▉        | 81/421 [44:01<4:12:51, 44.62s/batch, loss=0.476361]Training:  19%|█▉        | 82/421 [44:01<3:10:34, 33.73s/batch, loss=0.476361]Training:  19%|█▉        | 82/421 [44:03<3:10:34, 33.73s/batch, loss=0.471409]Training:  20%|█▉        | 83/421 [44:03<2:15:33, 24.06s/batch, loss=0.471409]Training:  20%|█▉        | 83/421 [44:15<2:15:33, 24.06s/batch, loss=0.455521]Training:  20%|█▉        | 84/421 [44:15<1:54:45, 20.43s/batch, loss=0.455521]Training:  20%|█▉        | 84/421 [46:12<1:54:45, 20.43s/batch, loss=0.467339]Training:  20%|██        | 85/421 [46:12<4:38:03, 49.65s/batch, loss=0.467339]Training:  20%|██        | 85/421 [46:27<4:38:03, 49.65s/batch, loss=0.461243]Training:  20%|██        | 86/421 [46:27<3:38:48, 39.19s/batch, loss=0.461243]Training:  20%|██        | 86/421 [46:29<3:38:48, 39.19s/batch, loss=0.477761]Training:  21%|██        | 87/421 [46:29<2:35:25, 27.92s/batch, loss=0.477761]Training:  21%|██        | 87/421 [46:31<2:35:25, 27.92s/batch, loss=0.460557]Training:  21%|██        | 88/421 [46:31<1:52:30, 20.27s/batch, loss=0.460557]Training:  21%|██        | 88/421 [48:27<1:52:30, 20.27s/batch, loss=0.467006]Training:  21%|██        | 89/421 [48:27<4:31:03, 48.99s/batch, loss=0.467006]Training:  21%|██        | 89/421 [48:29<4:31:03, 48.99s/batch, loss=0.489047]Training:  21%|██▏       | 90/421 [48:29<3:11:41, 34.75s/batch, loss=0.489047]Training:  21%|██▏       | 90/421 [48:30<3:11:41, 34.75s/batch, loss=0.462447]Training:  22%|██▏       | 91/421 [48:30<2:16:17, 24.78s/batch, loss=0.462447]Training:  22%|██▏       | 91/421 [48:54<2:16:17, 24.78s/batch, loss=0.472624]Training:  22%|██▏       | 92/421 [48:54<2:14:44, 24.57s/batch, loss=0.472624]Training:  22%|██▏       | 92/421 [50:53<2:14:44, 24.57s/batch, loss=0.478706]Training:  22%|██▏       | 93/421 [50:53<4:47:51, 52.66s/batch, loss=0.478706]Training:  22%|██▏       | 93/421 [50:54<4:47:51, 52.66s/batch, loss=0.478776]Training:  22%|██▏       | 94/421 [50:54<3:23:30, 37.34s/batch, loss=0.478776]Training:  22%|██▏       | 94/421 [50:56<3:23:30, 37.34s/batch, loss=0.472407]Training:  23%|██▎       | 95/421 [50:56<2:24:32, 26.60s/batch, loss=0.472407]Training:  23%|██▎       | 95/421 [51:08<2:24:32, 26.60s/batch, loss=0.465014]Training:  23%|██▎       | 96/421 [51:08<2:00:43, 22.29s/batch, loss=0.465014]Training:  23%|██▎       | 96/421 [53:02<2:00:43, 22.29s/batch, loss=0.454227]Training:  23%|██▎       | 97/421 [53:02<4:29:40, 49.94s/batch, loss=0.454227]Training:  23%|██▎       | 97/421 [53:04<4:29:40, 49.94s/batch, loss=0.455529]Training:  23%|██▎       | 98/421 [53:04<3:10:40, 35.42s/batch, loss=0.455529]Training:  23%|██▎       | 98/421 [53:06<3:10:40, 35.42s/batch, loss=0.485033]Training:  24%|██▎       | 99/421 [53:06<2:15:40, 25.28s/batch, loss=0.485033]Training:  24%|██▎       | 99/421 [53:20<2:15:40, 25.28s/batch, loss=0.466827]Training:  24%|██▍       | 100/421 [53:20<1:58:26, 22.14s/batch, loss=0.466827]Training:  24%|██▍       | 100/421 [55:18<1:58:26, 22.14s/batch, loss=0.466892]Training:  24%|██▍       | 101/421 [55:18<4:31:04, 50.83s/batch, loss=0.466892]Training:  24%|██▍       | 101/421 [55:20<4:31:04, 50.83s/batch, loss=0.468948]Training:  24%|██▍       | 102/421 [55:20<3:11:34, 36.03s/batch, loss=0.468948]Training:  24%|██▍       | 102/421 [55:21<3:11:34, 36.03s/batch, loss=0.452973]Training:  24%|██▍       | 103/421 [55:21<2:16:09, 25.69s/batch, loss=0.452973]Training:  24%|██▍       | 103/421 [55:23<2:16:09, 25.69s/batch, loss=0.452567]Training:  25%|██▍       | 104/421 [55:23<1:37:28, 18.45s/batch, loss=0.452567]Training:  25%|██▍       | 104/421 [56:53<1:37:28, 18.45s/batch, loss=0.470492]Training:  25%|██▍       | 105/421 [56:53<3:30:28, 39.96s/batch, loss=0.470492]Training:  25%|██▍       | 105/421 [56:54<3:30:28, 39.96s/batch, loss=0.470335]Training:  25%|██▌       | 106/421 [56:54<2:29:17, 28.44s/batch, loss=0.470335]Training:  25%|██▌       | 106/421 [56:56<2:29:17, 28.44s/batch, loss=0.467310]Training:  25%|██▌       | 107/421 [56:56<1:47:15, 20.50s/batch, loss=0.467310]Training:  25%|██▌       | 107/421 [57:09<1:47:15, 20.50s/batch, loss=0.471682]Training:  26%|██▌       | 108/421 [57:09<1:33:52, 18.00s/batch, loss=0.471682]Training:  26%|██▌       | 108/421 [58:55<1:33:52, 18.00s/batch, loss=0.475716]Training:  26%|██▌       | 109/421 [58:55<3:51:25, 44.50s/batch, loss=0.475716]Training:  26%|██▌       | 109/421 [58:56<3:51:25, 44.50s/batch, loss=0.484988]Training:  26%|██▌       | 110/421 [58:56<2:43:54, 31.62s/batch, loss=0.484988]Training:  26%|██▌       | 110/421 [58:58<2:43:54, 31.62s/batch, loss=0.477055]Training:  26%|██▋       | 111/421 [58:58<1:56:44, 22.59s/batch, loss=0.477055]Training:  26%|██▋       | 111/421 [59:13<1:56:44, 22.59s/batch, loss=0.465689]Training:  27%|██▋       | 112/421 [59:13<1:44:27, 20.28s/batch, loss=0.465689]Training:  27%|██▋       | 112/421 [1:01:08<1:44:27, 20.28s/batch, loss=0.480550]Training:  27%|██▋       | 113/421 [1:01:09<4:11:51, 49.06s/batch, loss=0.480550]Training:  27%|██▋       | 113/421 [1:01:11<4:11:51, 49.06s/batch, loss=0.456606]Training:  27%|██▋       | 114/421 [1:01:11<2:58:05, 34.81s/batch, loss=0.456606]Training:  27%|██▋       | 114/421 [1:01:12<2:58:05, 34.81s/batch, loss=0.463170]Training:  27%|██▋       | 115/421 [1:01:12<2:06:38, 24.83s/batch, loss=0.463170]Training:  27%|██▋       | 115/421 [1:01:14<2:06:38, 24.83s/batch, loss=0.461527]Training:  28%|██▊       | 116/421 [1:01:14<1:30:53, 17.88s/batch, loss=0.461527]Training:  28%|██▊       | 116/421 [1:03:33<1:30:53, 17.88s/batch, loss=0.464888]Training:  28%|██▊       | 117/421 [1:03:33<4:35:08, 54.31s/batch, loss=0.464888]Training:  28%|██▊       | 117/421 [1:03:35<4:35:08, 54.31s/batch, loss=0.448439]Training:  28%|██▊       | 118/421 [1:03:35<3:14:17, 38.47s/batch, loss=0.448439]Training:  28%|██▊       | 118/421 [1:03:36<3:14:17, 38.47s/batch, loss=0.459120]Training:  28%|██▊       | 119/421 [1:03:36<2:17:52, 27.39s/batch, loss=0.459120]Training:  28%|██▊       | 119/421 [1:03:38<2:17:52, 27.39s/batch, loss=0.462149]Training:  29%|██▊       | 120/421 [1:03:38<1:38:28, 19.63s/batch, loss=0.462149]Training:  29%|██▊       | 120/421 [1:05:49<1:38:28, 19.63s/batch, loss=0.455839]Training:  29%|██▊       | 121/421 [1:05:49<4:26:10, 53.24s/batch, loss=0.455839]Training:  29%|██▊       | 121/421 [1:05:51<4:26:10, 53.24s/batch, loss=0.448436]Training:  29%|██▉       | 122/421 [1:05:51<3:07:59, 37.72s/batch, loss=0.448436]Training:  29%|██▉       | 122/421 [1:05:52<3:07:59, 37.72s/batch, loss=0.454935]Training:  29%|██▉       | 123/421 [1:05:52<2:13:25, 26.87s/batch, loss=0.454935]Training:  29%|██▉       | 123/421 [1:05:54<2:13:25, 26.87s/batch, loss=0.455349]Training:  29%|██▉       | 124/421 [1:05:54<1:35:22, 19.27s/batch, loss=0.455349]Training:  29%|██▉       | 124/421 [1:08:15<1:35:22, 19.27s/batch, loss=0.470309]Training:  30%|██▉       | 125/421 [1:08:15<4:35:23, 55.82s/batch, loss=0.470309]Training:  30%|██▉       | 125/421 [1:08:17<4:35:23, 55.82s/batch, loss=0.469440]Training:  30%|██▉       | 126/421 [1:08:17<3:14:24, 39.54s/batch, loss=0.469440]Training:  30%|██▉       | 126/421 [1:08:18<3:14:24, 39.54s/batch, loss=0.462656]Training:  30%|███       | 127/421 [1:08:18<2:17:57, 28.16s/batch, loss=0.462656]Training:  30%|███       | 127/421 [1:08:20<2:17:57, 28.16s/batch, loss=0.471987]Training:  30%|███       | 128/421 [1:08:20<1:38:36, 20.19s/batch, loss=0.471987]Training:  30%|███       | 128/421 [1:10:36<1:38:36, 20.19s/batch, loss=0.477748]Training:  31%|███       | 129/421 [1:10:36<4:27:05, 54.88s/batch, loss=0.477748]Training:  31%|███       | 129/421 [1:10:37<4:27:05, 54.88s/batch, loss=0.457304]Training:  31%|███       | 130/421 [1:10:37<3:08:31, 38.87s/batch, loss=0.457304]Training:  31%|███       | 130/421 [1:10:39<3:08:31, 38.87s/batch, loss=0.467916]Training:  31%|███       | 131/421 [1:10:39<2:13:43, 27.67s/batch, loss=0.467916]Training:  31%|███       | 131/421 [1:10:40<2:13:43, 27.67s/batch, loss=0.464710]Training:  31%|███▏      | 132/421 [1:10:40<1:35:32, 19.84s/batch, loss=0.464710]Training:  31%|███▏      | 132/421 [1:12:51<1:35:32, 19.84s/batch, loss=0.462412]Training:  32%|███▏      | 133/421 [1:12:51<4:14:10, 52.95s/batch, loss=0.462412]Training:  32%|███▏      | 133/421 [1:12:52<4:14:10, 52.95s/batch, loss=0.455746]Training:  32%|███▏      | 134/421 [1:12:52<2:59:34, 37.54s/batch, loss=0.455746]Training:  32%|███▏      | 134/421 [1:12:54<2:59:34, 37.54s/batch, loss=0.482981]Training:  32%|███▏      | 135/421 [1:12:54<2:07:27, 26.74s/batch, loss=0.482981]Training:  32%|███▏      | 135/421 [1:12:55<2:07:27, 26.74s/batch, loss=0.460670]Training:  32%|███▏      | 136/421 [1:12:55<1:31:06, 19.18s/batch, loss=0.460670]Training:  32%|███▏      | 136/421 [1:15:12<1:31:06, 19.18s/batch, loss=0.478287]Training:  33%|███▎      | 137/421 [1:15:12<4:17:16, 54.35s/batch, loss=0.478287]Training:  33%|███▎      | 137/421 [1:15:13<4:17:16, 54.35s/batch, loss=0.468194]Training:  33%|███▎      | 138/421 [1:15:13<3:01:38, 38.51s/batch, loss=0.468194]Training:  33%|███▎      | 138/421 [1:15:15<3:01:38, 38.51s/batch, loss=0.477549]Training:  33%|███▎      | 139/421 [1:15:15<2:08:51, 27.42s/batch, loss=0.477549]Training:  33%|███▎      | 139/421 [1:15:16<2:08:51, 27.42s/batch, loss=0.477365]Training:  33%|███▎      | 140/421 [1:15:16<1:32:03, 19.66s/batch, loss=0.477365]Training:  33%|███▎      | 140/421 [1:17:19<1:32:03, 19.66s/batch, loss=0.457279]Training:  33%|███▎      | 141/421 [1:17:19<3:56:22, 50.65s/batch, loss=0.457279]Training:  33%|███▎      | 141/421 [1:17:21<3:56:22, 50.65s/batch, loss=0.447375]Training:  34%|███▎      | 142/421 [1:17:21<2:46:58, 35.91s/batch, loss=0.447375]Training:  34%|███▎      | 142/421 [1:17:22<2:46:58, 35.91s/batch, loss=0.446736]Training:  34%|███▍      | 143/421 [1:17:22<1:58:36, 25.60s/batch, loss=0.446736]Training:  34%|███▍      | 143/421 [1:17:24<1:58:36, 25.60s/batch, loss=0.463136]Training:  34%|███▍      | 144/421 [1:17:24<1:24:55, 18.40s/batch, loss=0.463136]Training:  34%|███▍      | 144/421 [1:19:18<1:24:55, 18.40s/batch, loss=0.442089]Training:  34%|███▍      | 145/421 [1:19:18<3:37:05, 47.19s/batch, loss=0.442089]Training:  34%|███▍      | 145/421 [1:19:20<3:37:05, 47.19s/batch, loss=0.472708]Training:  35%|███▍      | 146/421 [1:19:20<2:33:36, 33.51s/batch, loss=0.472708]Training:  35%|███▍      | 146/421 [1:19:21<2:33:36, 33.51s/batch, loss=0.469113]Training:  35%|███▍      | 147/421 [1:19:21<1:49:19, 23.94s/batch, loss=0.469113]Training:  35%|███▍      | 147/421 [1:19:23<1:49:19, 23.94s/batch, loss=0.467366]Training:  35%|███▌      | 148/421 [1:19:23<1:18:18, 17.21s/batch, loss=0.467366]Training:  35%|███▌      | 148/421 [1:21:23<1:18:18, 17.21s/batch, loss=0.462940]Training:  35%|███▌      | 149/421 [1:21:23<3:38:33, 48.21s/batch, loss=0.462940]Training:  35%|███▌      | 149/421 [1:21:25<3:38:33, 48.21s/batch, loss=0.472308]Training:  36%|███▌      | 150/421 [1:21:25<2:34:30, 34.21s/batch, loss=0.472308]Training:  36%|███▌      | 150/421 [1:21:27<2:34:30, 34.21s/batch, loss=0.474235]Training:  36%|███▌      | 151/421 [1:21:27<1:49:51, 24.41s/batch, loss=0.474235]Training:  36%|███▌      | 151/421 [1:21:28<1:49:51, 24.41s/batch, loss=0.469079]Training:  36%|███▌      | 152/421 [1:21:28<1:18:39, 17.54s/batch, loss=0.469079]Training:  36%|███▌      | 152/421 [1:24:04<1:18:39, 17.54s/batch, loss=0.464456]Training:  36%|███▋      | 153/421 [1:24:04<4:23:25, 58.97s/batch, loss=0.464456]Training:  36%|███▋      | 153/421 [1:24:05<4:23:25, 58.97s/batch, loss=0.469035]Training:  37%|███▋      | 154/421 [1:24:05<3:05:56, 41.78s/batch, loss=0.469035]Training:  37%|███▋      | 154/421 [1:24:07<3:05:56, 41.78s/batch, loss=0.460946]Training:  37%|███▋      | 155/421 [1:24:07<2:11:43, 29.71s/batch, loss=0.460946]Training:  37%|███▋      | 155/421 [1:24:08<2:11:43, 29.71s/batch, loss=0.470997]Training:  37%|███▋      | 156/421 [1:24:08<1:33:51, 21.25s/batch, loss=0.470997]Training:  37%|███▋      | 156/421 [1:26:20<1:33:51, 21.25s/batch, loss=0.483299]Training:  37%|███▋      | 157/421 [1:26:20<3:59:14, 54.37s/batch, loss=0.483299]Training:  37%|███▋      | 157/421 [1:26:22<3:59:14, 54.37s/batch, loss=0.464664]Training:  38%|███▊      | 158/421 [1:26:22<2:48:50, 38.52s/batch, loss=0.464664]Training:  38%|███▊      | 158/421 [1:26:23<2:48:50, 38.52s/batch, loss=0.469375]Training:  38%|███▊      | 159/421 [1:26:23<1:59:43, 27.42s/batch, loss=0.469375]Training:  38%|███▊      | 159/421 [1:26:25<1:59:43, 27.42s/batch, loss=0.462558]Training:  38%|███▊      | 160/421 [1:26:25<1:25:29, 19.65s/batch, loss=0.462558]Training:  38%|███▊      | 160/421 [1:28:44<1:25:29, 19.65s/batch, loss=0.460811]Training:  38%|███▊      | 161/421 [1:28:44<4:00:11, 55.43s/batch, loss=0.460811]Training:  38%|███▊      | 161/421 [1:28:45<4:00:11, 55.43s/batch, loss=0.456328]Training:  38%|███▊      | 162/421 [1:28:45<2:49:27, 39.26s/batch, loss=0.456328]Training:  38%|███▊      | 162/421 [1:28:47<2:49:27, 39.26s/batch, loss=0.476021]Training:  39%|███▊      | 163/421 [1:28:47<2:00:10, 27.95s/batch, loss=0.476021]Training:  39%|███▊      | 163/421 [1:28:48<2:00:10, 27.95s/batch, loss=0.471470]Training:  39%|███▉      | 164/421 [1:28:48<1:25:44, 20.02s/batch, loss=0.471470]Training:  39%|███▉      | 164/421 [1:31:14<1:25:44, 20.02s/batch, loss=0.470953]Training:  39%|███▉      | 165/421 [1:31:14<4:05:50, 57.62s/batch, loss=0.470953]Training:  39%|███▉      | 165/421 [1:31:15<4:05:50, 57.62s/batch, loss=0.473312]Training:  39%|███▉      | 166/421 [1:31:15<2:53:24, 40.80s/batch, loss=0.473312]Training:  39%|███▉      | 166/421 [1:31:17<2:53:24, 40.80s/batch, loss=0.466561]Training:  40%|███▉      | 167/421 [1:31:17<2:02:52, 29.03s/batch, loss=0.466561]Training:  40%|███▉      | 167/421 [1:31:18<2:02:52, 29.03s/batch, loss=0.454910]Training:  40%|███▉      | 168/421 [1:31:18<1:27:38, 20.79s/batch, loss=0.454910]Training:  40%|███▉      | 168/421 [1:33:20<1:27:38, 20.79s/batch, loss=0.475305]Training:  40%|████      | 169/421 [1:33:20<3:34:13, 51.01s/batch, loss=0.475305]Training:  40%|████      | 169/421 [1:33:21<3:34:13, 51.01s/batch, loss=0.449217]Training:  40%|████      | 170/421 [1:33:21<2:31:21, 36.18s/batch, loss=0.449217]Training:  40%|████      | 170/421 [1:33:23<2:31:21, 36.18s/batch, loss=0.462542]Training:  41%|████      | 171/421 [1:33:23<1:47:27, 25.79s/batch, loss=0.462542]Training:  41%|████      | 171/421 [1:33:24<1:47:27, 25.79s/batch, loss=0.461910]Training:  41%|████      | 172/421 [1:33:24<1:16:56, 18.54s/batch, loss=0.461910]Training:  41%|████      | 172/421 [1:35:03<1:16:56, 18.54s/batch, loss=0.458559]Training:  41%|████      | 173/421 [1:35:03<2:55:58, 42.57s/batch, loss=0.458559]Training:  41%|████      | 173/421 [1:35:05<2:55:58, 42.57s/batch, loss=0.469806]Training:  41%|████▏     | 174/421 [1:35:05<2:04:37, 30.27s/batch, loss=0.469806]Training:  41%|████▏     | 174/421 [1:35:06<2:04:37, 30.27s/batch, loss=0.436860]Training:  42%|████▏     | 175/421 [1:35:06<1:28:47, 21.66s/batch, loss=0.436860]Training:  42%|████▏     | 175/421 [1:35:08<1:28:47, 21.66s/batch, loss=0.472087]Training:  42%|████▏     | 176/421 [1:35:08<1:03:46, 15.62s/batch, loss=0.472087]Training:  42%|████▏     | 176/421 [1:37:10<1:03:46, 15.62s/batch, loss=0.476844]Training:  42%|████▏     | 177/421 [1:37:10<3:13:54, 47.68s/batch, loss=0.476844]Training:  42%|████▏     | 177/421 [1:37:12<3:13:54, 47.68s/batch, loss=0.468244]Training:  42%|████▏     | 178/421 [1:37:12<2:17:06, 33.85s/batch, loss=0.468244]Training:  42%|████▏     | 178/421 [1:37:13<2:17:06, 33.85s/batch, loss=0.452896]Training:  43%|████▎     | 179/421 [1:37:13<1:37:27, 24.16s/batch, loss=0.452896]Training:  43%|████▎     | 179/421 [1:37:15<1:37:27, 24.16s/batch, loss=0.464384]Training:  43%|████▎     | 180/421 [1:37:15<1:09:50, 17.39s/batch, loss=0.464384]Training:  43%|████▎     | 180/421 [1:39:16<1:09:50, 17.39s/batch, loss=0.464671]Training:  43%|████▎     | 181/421 [1:39:16<3:13:35, 48.40s/batch, loss=0.464671]Training:  43%|████▎     | 181/421 [1:39:17<3:13:35, 48.40s/batch, loss=0.459590]Training:  43%|████▎     | 182/421 [1:39:17<2:16:51, 34.36s/batch, loss=0.459590]Training:  43%|████▎     | 182/421 [1:39:19<2:16:51, 34.36s/batch, loss=0.472282]Training:  43%|████▎     | 183/421 [1:39:19<1:37:14, 24.51s/batch, loss=0.472282]Training:  43%|████▎     | 183/421 [1:39:20<1:37:14, 24.51s/batch, loss=0.471393]Training:  44%|████▎     | 184/421 [1:39:20<1:09:35, 17.62s/batch, loss=0.471393]Training:  44%|████▎     | 184/421 [1:41:24<1:09:35, 17.62s/batch, loss=0.459587]Training:  44%|████▍     | 185/421 [1:41:24<3:13:53, 49.30s/batch, loss=0.459587]Training:  44%|████▍     | 185/421 [1:41:25<3:13:53, 49.30s/batch, loss=0.482013]Training:  44%|████▍     | 186/421 [1:41:25<2:16:58, 34.97s/batch, loss=0.482013]Training:  44%|████▍     | 186/421 [1:41:27<2:16:58, 34.97s/batch, loss=0.455228]Training:  44%|████▍     | 187/421 [1:41:27<1:37:15, 24.94s/batch, loss=0.455228]Training:  44%|████▍     | 187/421 [1:41:28<1:37:15, 24.94s/batch, loss=0.483154]Training:  45%|████▍     | 188/421 [1:41:28<1:09:37, 17.93s/batch, loss=0.483154]Training:  45%|████▍     | 188/421 [1:43:23<1:09:37, 17.93s/batch, loss=0.466087]Training:  45%|████▍     | 189/421 [1:43:23<3:01:41, 46.99s/batch, loss=0.466087]Training:  45%|████▍     | 189/421 [1:43:25<3:01:41, 46.99s/batch, loss=0.476407]Training:  45%|████▌     | 190/421 [1:43:25<2:08:25, 33.36s/batch, loss=0.476407]Training:  45%|████▌     | 190/421 [1:43:26<2:08:25, 33.36s/batch, loss=0.478900]Training:  45%|████▌     | 191/421 [1:43:26<1:31:15, 23.81s/batch, loss=0.478900]Training:  45%|████▌     | 191/421 [1:43:28<1:31:15, 23.81s/batch, loss=0.458791]Training:  46%|████▌     | 192/421 [1:43:28<1:05:22, 17.13s/batch, loss=0.458791]Training:  46%|████▌     | 192/421 [1:45:19<1:05:22, 17.13s/batch, loss=0.471732]Training:  46%|████▌     | 193/421 [1:45:19<2:52:33, 45.41s/batch, loss=0.471732]Training:  46%|████▌     | 193/421 [1:45:21<2:52:33, 45.41s/batch, loss=0.461826]Training:  46%|████▌     | 194/421 [1:45:21<2:02:00, 32.25s/batch, loss=0.461826]Training:  46%|████▌     | 194/421 [1:45:22<2:02:00, 32.25s/batch, loss=0.456938]Training:  46%|████▋     | 195/421 [1:45:22<1:26:44, 23.03s/batch, loss=0.456938]Training:  46%|████▋     | 195/421 [1:45:24<1:26:44, 23.03s/batch, loss=0.475706]Training:  47%|████▋     | 196/421 [1:45:24<1:02:10, 16.58s/batch, loss=0.475706]Training:  47%|████▋     | 196/421 [1:47:13<1:02:10, 16.58s/batch, loss=0.449597]Training:  47%|████▋     | 197/421 [1:47:13<2:45:12, 44.25s/batch, loss=0.449597]Training:  47%|████▋     | 197/421 [1:47:14<2:45:12, 44.25s/batch, loss=0.471108]Training:  47%|████▋     | 198/421 [1:47:14<1:56:54, 31.46s/batch, loss=0.471108]Training:  47%|████▋     | 198/421 [1:47:16<1:56:54, 31.46s/batch, loss=0.480554]Training:  47%|████▋     | 199/421 [1:47:16<1:23:09, 22.48s/batch, loss=0.480554]Training:  47%|████▋     | 199/421 [1:47:17<1:23:09, 22.48s/batch, loss=0.468342]Training:  48%|████▊     | 200/421 [1:47:17<59:42, 16.21s/batch, loss=0.468342]  Training:  48%|████▊     | 200/421 [1:49:07<59:42, 16.21s/batch, loss=0.470799]Training:  48%|████▊     | 201/421 [1:49:07<2:42:18, 44.27s/batch, loss=0.470799]Training:  48%|████▊     | 201/421 [1:49:08<2:42:18, 44.27s/batch, loss=0.471751]Training:  48%|████▊     | 202/421 [1:49:08<1:54:46, 31.45s/batch, loss=0.471751]Training:  48%|████▊     | 202/421 [1:49:10<1:54:46, 31.45s/batch, loss=0.465617]Training:  48%|████▊     | 203/421 [1:49:10<1:21:39, 22.47s/batch, loss=0.465617]Training:  48%|████▊     | 203/421 [1:49:12<1:21:39, 22.47s/batch, loss=0.474303]Training:  48%|████▊     | 204/421 [1:49:12<58:34, 16.20s/batch, loss=0.474303]  Training:  48%|████▊     | 204/421 [1:51:36<58:34, 16.20s/batch, loss=0.457612]Training:  49%|████▊     | 205/421 [1:51:36<3:17:02, 54.73s/batch, loss=0.457612]Training:  49%|████▊     | 205/421 [1:51:38<3:17:02, 54.73s/batch, loss=0.449726]Training:  49%|████▉     | 206/421 [1:51:38<2:18:56, 38.77s/batch, loss=0.449726]Training:  49%|████▉     | 206/421 [1:51:39<2:18:56, 38.77s/batch, loss=0.465725]Training:  49%|████▉     | 207/421 [1:51:39<1:38:25, 27.60s/batch, loss=0.465725]Training:  49%|████▉     | 207/421 [1:51:41<1:38:25, 27.60s/batch, loss=0.453596]Training:  49%|████▉     | 208/421 [1:51:41<1:10:13, 19.78s/batch, loss=0.453596]Training:  49%|████▉     | 208/421 [1:53:59<1:10:13, 19.78s/batch, loss=0.454544]Training:  50%|████▉     | 209/421 [1:53:59<3:15:24, 55.30s/batch, loss=0.454544]Training:  50%|████▉     | 209/421 [1:54:01<3:15:24, 55.30s/batch, loss=0.452445]Training:  50%|████▉     | 210/421 [1:54:01<2:17:48, 39.19s/batch, loss=0.452445]Training:  50%|████▉     | 210/421 [1:54:02<2:17:48, 39.19s/batch, loss=0.479887]Training:  50%|█████     | 211/421 [1:54:02<1:37:38, 27.90s/batch, loss=0.479887]Training:  50%|█████     | 211/421 [1:54:04<1:37:38, 27.90s/batch, loss=0.465539]Training:  50%|█████     | 212/421 [1:54:04<1:09:37, 19.99s/batch, loss=0.465539]Training:  50%|█████     | 212/421 [1:55:44<1:09:37, 19.99s/batch, loss=0.447269]Training:  51%|█████     | 213/421 [1:55:44<2:33:19, 44.23s/batch, loss=0.447269]Training:  51%|█████     | 213/421 [1:55:46<2:33:19, 44.23s/batch, loss=0.475398]Training:  51%|█████     | 214/421 [1:55:46<1:48:23, 31.42s/batch, loss=0.475398]Training:  51%|█████     | 214/421 [1:55:48<1:48:23, 31.42s/batch, loss=0.457074]Training:  51%|█████     | 215/421 [1:55:48<1:17:07, 22.46s/batch, loss=0.457074]Training:  51%|█████     | 215/421 [1:55:49<1:17:07, 22.46s/batch, loss=0.455696]Training:  51%|█████▏    | 216/421 [1:55:49<55:16, 16.18s/batch, loss=0.455696]  