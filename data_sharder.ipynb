{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "822a56c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ClimSimNumpySharder:\n",
    "    def __init__(self):\n",
    "        # Configuration of Variables (The 557/128 architecture)\n",
    "        self.input_profiles = ['state_t', 'state_q0001', 'state_q0002', 'state_q0003', 'state_u', 'state_v', 'pbuf_ozone', 'pbuf_CH4', 'pbuf_N2O']\n",
    "        self.input_scalars = ['state_ps', 'pbuf_SOLIN', 'pbuf_LHFLX', 'pbuf_SHFLX', 'pbuf_TAUX', 'pbuf_TAUY', 'cam_in_ALDIF', 'cam_in_ALDIR', 'cam_in_ASDIF', 'cam_in_ASDIR', 'cam_in_ICEFRAC', 'cam_in_LANDFRAC', 'cam_in_LWUP', 'cam_in_OCNFRAC', 'cam_in_SNOWHICE', 'cam_in_SNOWHLAND', 'pbuf_COSZRS']\n",
    "        \n",
    "        self.target_profiles = ['state_t', 'state_q0001'] \n",
    "        self.target_scalars = ['cam_out_NETSW', 'cam_out_FLWDS', 'cam_out_PRECC', 'cam_out_PRECSC', 'cam_out_SOLL', 'cam_out_SOLLD', 'cam_out_SOLS', 'cam_out_SOLSD']\n",
    "\n",
    "        # Build Internal Mappings\n",
    "        self.input_indices, self.total_input_dim = self._build_index_map(self.input_profiles, self.input_scalars)\n",
    "        self.target_indices, self.total_target_dim = self._build_index_map(self.target_profiles, self.target_scalars)\n",
    "\n",
    "    def _build_index_map(self, profiles, scalars):\n",
    "        mapping = {}\n",
    "        curr = 0\n",
    "        for p in profiles:\n",
    "            mapping[p] = {\"start\": curr, \"end\": curr + 60}\n",
    "            curr += 60\n",
    "        for s in scalars:\n",
    "            mapping[s] = {\"start\": curr, \"end\": curr + 1}\n",
    "            curr += 1\n",
    "        return mapping, curr\n",
    "\n",
    "    def create_shards(self, mli_paths, mlo_paths, output_dir, shard_size=100):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        all_input_means, all_input_sq_means = [], []\n",
    "        num_files = len(mli_paths)\n",
    "\n",
    "        for shard_idx, start_i in enumerate(range(0, num_files, shard_size)):\n",
    "            X_shard, Y_shard = [], []\n",
    "            end_i = min(start_i + shard_size, num_files)\n",
    "            \n",
    "            for mli, mlo in tqdm(zip(mli_paths[start_i:end_i], mlo_paths[start_i:end_i]), \n",
    "                                 total=end_i-start_i, desc=f\"Shard {shard_idx}\"):\n",
    "                try:\n",
    "                    with xr.open_dataset(mli) as ds_in, xr.open_dataset(mlo) as ds_out:\n",
    "                        # Vectorized stacking\n",
    "                        X_file = np.hstack([ds_in[v].values.T if v in self.input_profiles else ds_in[v].values.reshape(-1, 1) for v in self.input_profiles + self.input_scalars])\n",
    "                        Y_file = np.hstack([ds_out[v].values.T if v in self.target_profiles else ds_out[v].values.reshape(-1, 1) for v in self.target_profiles + self.target_scalars])\n",
    "                        X_shard.append(X_file)\n",
    "                        Y_shard.append(Y_file)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {mli}: {e}\")\n",
    "\n",
    "            # vstack rows (384 * shard_size, features)\n",
    "            X_final = np.vstack(X_shard).astype(np.float32)\n",
    "            Y_final = np.vstack(Y_shard).astype(np.float32)\n",
    "\n",
    "            # Accumulate statistics\n",
    "            all_input_means.append(np.mean(X_final, axis=0))\n",
    "            all_input_sq_means.append(np.mean(X_final**2, axis=0))\n",
    "\n",
    "            np.save(os.path.join(output_dir, f\"X_shard_{shard_idx}.npy\"), X_final)\n",
    "            np.save(os.path.join(output_dir, f\"Y_shard_{shard_idx}.npy\"), Y_final)\n",
    "\n",
    "        # Save Final Metadata\n",
    "        final_mean = np.mean(all_input_means, axis=0)\n",
    "        final_std = np.sqrt(np.mean(all_input_sq_means, axis=0) - final_mean**2)\n",
    "        \n",
    "        metadata = {\n",
    "            \"input_indices\": self.input_indices,\n",
    "            \"target_indices\": self.target_indices,\n",
    "            \"input_mean\": final_mean.tolist(),\n",
    "            \"input_std\": final_std.tolist(),\n",
    "            \"total_input_dim\": self.total_input_dim,\n",
    "            \"total_target_dim\": self.total_target_dim\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(output_dir, \"metadata.json\"), \"w\") as f:\n",
    "            json.dump(metadata, f, indent=4)\n",
    "        print(f\"Done! Metadata saved to {output_dir}/metadata.json\")\n",
    "\n",
    "    @staticmethod\n",
    "    def get_variable(data, var_name, mapping):\n",
    "        \"\"\"Helper to extract a variable from a loaded numpy shard or torch tensor.\"\"\"\n",
    "        if var_name not in mapping:\n",
    "            raise ValueError(f\"Variable {var_name} not found in mapping.\")\n",
    "        start = mapping[var_name]['start']\n",
    "        end = mapping[var_name]['end']\n",
    "        return data[..., start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0098aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_folders(path):\n",
    "    data_folders = os.listdir(path)\n",
    "    data_folders.sort()\n",
    "\n",
    "    print(f\"Found {len(data_folders)} data folders.\")\n",
    "\n",
    "    mli_samples = []\n",
    "    mlo_samples = []\n",
    "    for dir_name in data_folders:\n",
    "        files = os.listdir(os.path.join(path, dir_name))\n",
    "        for f in files:\n",
    "            if f.split('.')[1] == 'mli':\n",
    "                mli_samples.append(os.path.join(path, dir_name, f))\n",
    "            elif f.split('.')[1] == 'mlo':\n",
    "                mlo_samples.append(os.path.join(path, dir_name, f))\n",
    "    \n",
    "    return mli_samples, mlo_samples\n",
    "\n",
    "def read_sample(file_path):\n",
    "    return xr.open_dataset(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a072f412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 data folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shard 0: 100%|██████████| 1000/1000 [01:36<00:00, 10.41it/s]\n",
      "/tmp/ipykernel_38338/903987435.py:59: RuntimeWarning: overflow encountered in square\n",
      "  all_input_sq_means.append(np.mean(X_final**2, axis=0))\n",
      "Shard 1: 100%|██████████| 1000/1000 [01:36<00:00, 10.35it/s]\n",
      "/tmp/ipykernel_38338/903987435.py:59: RuntimeWarning: overflow encountered in square\n",
      "  all_input_sq_means.append(np.mean(X_final**2, axis=0))\n",
      "Shard 2: 100%|██████████| 1000/1000 [01:37<00:00, 10.21it/s]\n",
      "/tmp/ipykernel_38338/903987435.py:59: RuntimeWarning: overflow encountered in square\n",
      "  all_input_sq_means.append(np.mean(X_final**2, axis=0))\n",
      "Shard 3: 100%|██████████| 1000/1000 [01:39<00:00, 10.10it/s]\n",
      "/tmp/ipykernel_38338/903987435.py:59: RuntimeWarning: overflow encountered in square\n",
      "  all_input_sq_means.append(np.mean(X_final**2, axis=0))\n",
      "Shard 4: 100%|██████████| 1000/1000 [01:38<00:00, 10.19it/s]\n",
      "/tmp/ipykernel_38338/903987435.py:59: RuntimeWarning: overflow encountered in square\n",
      "  all_input_sq_means.append(np.mean(X_final**2, axis=0))\n",
      "Shard 5: 100%|██████████| 1000/1000 [01:39<00:00, 10.06it/s]\n",
      "/tmp/ipykernel_38338/903987435.py:59: RuntimeWarning: overflow encountered in square\n",
      "  all_input_sq_means.append(np.mean(X_final**2, axis=0))\n",
      "Shard 6: 100%|██████████| 1000/1000 [01:39<00:00, 10.05it/s]\n",
      "/tmp/ipykernel_38338/903987435.py:59: RuntimeWarning: overflow encountered in square\n",
      "  all_input_sq_means.append(np.mean(X_final**2, axis=0))\n",
      "Shard 7: 100%|██████████| 1000/1000 [01:38<00:00, 10.12it/s]\n",
      "/tmp/ipykernel_38338/903987435.py:59: RuntimeWarning: overflow encountered in square\n",
      "  all_input_sq_means.append(np.mean(X_final**2, axis=0))\n",
      "Shard 8: 100%|██████████| 1000/1000 [01:39<00:00, 10.08it/s]\n",
      "/tmp/ipykernel_38338/903987435.py:59: RuntimeWarning: overflow encountered in square\n",
      "  all_input_sq_means.append(np.mean(X_final**2, axis=0))\n",
      "Shard 9: 100%|██████████| 1000/1000 [01:39<00:00, 10.06it/s]\n",
      "/tmp/ipykernel_38338/903987435.py:59: RuntimeWarning: overflow encountered in square\n",
      "  all_input_sq_means.append(np.mean(X_final**2, axis=0))\n",
      "Shard 10: 100%|██████████| 872/872 [01:26<00:00, 10.05it/s]\n",
      "/tmp/ipykernel_38338/903987435.py:59: RuntimeWarning: overflow encountered in square\n",
      "  all_input_sq_means.append(np.mean(X_final**2, axis=0))\n",
      "/tmp/ipykernel_38338/903987435.py:66: RuntimeWarning: overflow encountered in square\n",
      "  final_std = np.sqrt(np.mean(all_input_sq_means, axis=0) - final_mean**2)\n",
      "/tmp/ipykernel_38338/903987435.py:66: RuntimeWarning: invalid value encountered in subtract\n",
      "  final_std = np.sqrt(np.mean(all_input_sq_means, axis=0) - final_mean**2)\n",
      "/tmp/ipykernel_38338/903987435.py:66: RuntimeWarning: invalid value encountered in sqrt\n",
      "  final_std = np.sqrt(np.mean(all_input_sq_means, axis=0) - final_mean**2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Metadata saved to ClimSimLowResShards/metadata.json\n"
     ]
    }
   ],
   "source": [
    "mli_samples, mlo_samples = get_data_folders(\"ClimSim_low-res/train/\")\n",
    "\n",
    "sharder = ClimSimNumpySharder()\n",
    "sharder.create_shards(mli_samples, mlo_samples, \"ClimSimLowResShards\", shard_size=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pie_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
