{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51a5194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "import torch\n",
    "\n",
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LOW_RES_SAMPLE_PATH = \"ClimSim_low-res/train/\"\n",
    "LOW_RES_GRID_PATH = \"ClimSim_low-res/ClimSim_low-res_grid-info.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89aef713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_folders(path):\n",
    "    data_folders = os.listdir(path)\n",
    "    data_folders.sort()\n",
    "\n",
    "    mli_samples = []\n",
    "    mlo_samples = []\n",
    "    for dir_name in data_folders:\n",
    "        files = os.listdir(os.path.join(path, dir_name))\n",
    "        for f in files:\n",
    "            if f.split('.')[1] == 'mli':\n",
    "                mli_samples.append(os.path.join(path, dir_name, f))\n",
    "            elif f.split('.')[1] == 'mlo':\n",
    "                mlo_samples.append(os.path.join(path, dir_name, f))\n",
    "    \n",
    "    return mli_samples, mlo_samples\n",
    "\n",
    "def read_sample(file_path):\n",
    "    return xr.open_dataset(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7b4d701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of MLI samples: 10872\n",
      "Number of MLO samples: 10872\n"
     ]
    }
   ],
   "source": [
    "mli_samples, mlo_samples = get_data_folders(LOW_RES_SAMPLE_PATH)\n",
    "\n",
    "print(f\"Number of MLI samples: {len(mli_samples)}\")\n",
    "print(f\"Number of MLO samples: {len(mlo_samples)}\")\n",
    "\n",
    "grid = xr.open_dataset(LOW_RES_GRID_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "546cf04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class ClimSimMLP(nn.Module):\n",
    "    def __init__(self, input_dim=556):\n",
    "        super(ClimSimMLP, self).__init__()\n",
    "        \n",
    "        # Hidden Layers: [768, 640, 512, 640, 640]\n",
    "        self.layer1 = nn.Linear(input_dim, 768)\n",
    "        self.layer2 = nn.Linear(768, 640)\n",
    "        self.layer3 = nn.Linear(640, 512)\n",
    "        self.layer4 = nn.Linear(512, 640)\n",
    "        self.layer5 = nn.Linear(640, 640)\n",
    "        \n",
    "\n",
    "        self.last_hidden = nn.Linear(640, 128)\n",
    "        \n",
    "        # --- Output Heads ---\n",
    "        # 120 tendencies (Linear) + 8 surface variables (ReLU)\n",
    "        self.head_tendencies = nn.Linear(128, 120)\n",
    "        self.head_surface = nn.Linear(128, 8)\n",
    "        \n",
    "        # LeakyReLU alpha=0.15\n",
    "        self.activation = nn.LeakyReLU(0.15)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through the 5 main hidden layers\n",
    "        x = self.activation(self.layer1(x))\n",
    "        x = self.activation(self.layer2(x))\n",
    "        x = self.activation(self.layer3(x))\n",
    "        x = self.activation(self.layer4(x))\n",
    "        x = self.activation(self.layer5(x))\n",
    "        \n",
    "        # Pass through the fixed 128 layer\n",
    "        x = self.activation(self.last_hidden(x))\n",
    "        \n",
    "        # Output 1: Tendencies (Linear activation)\n",
    "        out_linear = self.head_tendencies(x)\n",
    "        \n",
    "        # Output 2: Surface variables (ReLU activation)\n",
    "        out_relu = F.relu(self.head_surface(x))\n",
    "        \n",
    "        # Concatenate along the feature dimension (dim=1)\n",
    "        return torch.cat([out_linear, out_relu], dim=1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    for inputs, targets in dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        batch_size = inputs.size(0)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_samples += batch_size\n",
    "\n",
    "    average_loss = total_loss / total_samples\n",
    "    return average_loss\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=\"Training\", unit=\"batch\")\n",
    "\n",
    "    for inputs, targets in pbar:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_size = inputs.size(0)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_samples += batch_size\n",
    "        \n",
    "        # Update progress bar description with current loss\n",
    "        pbar.set_postfix({\"loss\": f\"{loss.item():.6f}\"})\n",
    "\n",
    "    return total_loss / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312aa5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class ClimSimMultiShardDataset(Dataset):\n",
    "    def __init__(self, shard_dir, shard_indices, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            shard_dir (str): Folder where .npy files are stored.\n",
    "            shard_indices (list): List of integers [0, 1, 2...] identifying shards.\n",
    "            transform (callable): Normalizer/Standardizer.\n",
    "        \"\"\"\n",
    "        self.shard_dir = shard_dir\n",
    "        self.shard_indices = shard_indices\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.x_files = [os.path.join(shard_dir, f\"X_shard_{i}.npy\") for i in shard_indices]\n",
    "        self.y_files = [os.path.join(shard_dir, f\"Y_shard_{i}.npy\") for i in shard_indices]\n",
    "        \n",
    "        # 1. Map out the shards without loading them into memory\n",
    "        self.shard_lengths = []\n",
    "        for f in self.x_files:\n",
    "            # We open the header only to get the shape\n",
    "            temp_x = np.load(f, mmap_mode='r')\n",
    "            self.shard_lengths.append(temp_x.shape[0])\n",
    "            del temp_x\n",
    "            \n",
    "        self.cumulative_lengths = np.cumsum(self.shard_lengths)\n",
    "        self.total_size = self.cumulative_lengths[-1]\n",
    "        \n",
    "        # 2. Keep handles to the memory-mapped arrays\n",
    "        self.x_shards = [np.load(f, mmap_mode='r') for f in self.x_files]\n",
    "        self.y_shards = [np.load(f, mmap_mode='r') for f in self.y_files]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 3. Figure out which shard 'idx' belongs to\n",
    "        shard_idx = np.searchsorted(self.cumulative_lengths, idx, side='right')\n",
    "        \n",
    "        # 4. Calculate the local index within that specific shard\n",
    "        if shard_idx == 0:\n",
    "            local_idx = idx\n",
    "        else:\n",
    "            local_idx = idx - self.cumulative_lengths[shard_idx - 1]\n",
    "            \n",
    "        # 5. Extract and copy to memory\n",
    "        x = torch.from_numpy(self.x_shards[shard_idx][local_idx].copy()).float()\n",
    "        y = torch.from_numpy(self.y_shards[shard_idx][local_idx].copy()).float()\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "            \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d44ae816",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2880\n",
    "N_EPOCHS = 10\n",
    "INPUT_DIM = len(selected_levelized_features) * grid.sizes[\"lev\"]\n",
    "\n",
    "model = ClimSimMLP(input_dim=INPUT_DIM)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ef62f675",
   "metadata": {},
   "outputs": [],
   "source": [
    "mli_files, mlo_files = get_data_folders(LOW_RES_SAMPLE_PATH)\n",
    "\n",
    "mli_files = mli_files[:3]\n",
    "mlo_files = mlo_files[:3]\n",
    "\n",
    "(train_mli_files, train_mlo_files), (test_mli_files, test_mlo_files) = ClimSimDataset.train_test_split(mli_files, mlo_files)\n",
    "\n",
    "train = ClimSimDataset(train_mli_files, train_mlo_files, selected_levelized_features, target)\n",
    "test = ClimSimDataset(test_mli_files, test_mlo_files, selected_levelized_features, target)\n",
    "\n",
    "batch_size = 2880 # It's dataset_size/8 which is 48 columns\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e27f9892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x138240 and 360x768)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[108]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_EPOCHS):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     train_loss = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     val_loss = evaluate_model(model, test_loader, criterion, device=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 78\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, dataloader, optimizer, criterion, device)\u001b[39m\n\u001b[32m     75\u001b[39m inputs, targets = inputs.to(device), targets.to(device)\n\u001b[32m     77\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m loss = criterion(outputs, targets)\n\u001b[32m     80\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pie_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pie_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mClimSimMLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     30\u001b[39m     \u001b[38;5;66;03m# Pass through the 5 main hidden layers\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.activation(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     32\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.activation(\u001b[38;5;28mself\u001b[39m.layer2(x))\n\u001b[32m     33\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.activation(\u001b[38;5;28mself\u001b[39m.layer3(x))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pie_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pie_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pie_env/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (2x138240 and 360x768)"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device=\"cpu\")\n",
    "    val_loss = evaluate_model(model, test_loader, criterion, device=\"cpu\")\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bd1bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = np.load(\"ClimSimLowResShards/X_shard_0.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e75f264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 data folders.\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pie_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
